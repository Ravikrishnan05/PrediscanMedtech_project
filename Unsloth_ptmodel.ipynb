{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "691a563e6352460485aebd193c1dea13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e63127351f7844a9877e563576c09d46",
              "IPY_MODEL_497403c755614dc6a78d1ac565c0fcfd",
              "IPY_MODEL_b20cf3bfb69b43d69b92cb3b764c1537"
            ],
            "layout": "IPY_MODEL_af329f57e5664d8bb07b7833bb43f85c"
          }
        },
        "e63127351f7844a9877e563576c09d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f5b1fe3fc984ce79347daabdbed9849",
            "placeholder": "​",
            "style": "IPY_MODEL_8334130850a64dba8111928f84110962",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "497403c755614dc6a78d1ac565c0fcfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37e6bb2cbccc4b95b9d3cba0e2d978f1",
            "max": 90558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01fd78dc354e4e44b0b26363e7a4872d",
            "value": 90558
          }
        },
        "b20cf3bfb69b43d69b92cb3b764c1537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89c9e0a1687f45c6a471299a01c08cbf",
            "placeholder": "​",
            "style": "IPY_MODEL_b0570efcf36e4b93892395762a8fdae2",
            "value": " 90.6k/90.6k [00:00&lt;00:00, 2.06MB/s]"
          }
        },
        "af329f57e5664d8bb07b7833bb43f85c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f5b1fe3fc984ce79347daabdbed9849": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8334130850a64dba8111928f84110962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37e6bb2cbccc4b95b9d3cba0e2d978f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01fd78dc354e4e44b0b26363e7a4872d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89c9e0a1687f45c6a471299a01c08cbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0570efcf36e4b93892395762a8fdae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62a5f0e90628451db1288a0b32677180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_068fe1c4233a48f19190b1dd56213ca5",
              "IPY_MODEL_2a1ff2a30ee94ffa9932271eda6e4721",
              "IPY_MODEL_27b3b051a28e446cad71eba241ade2a8"
            ],
            "layout": "IPY_MODEL_9722e9bc08fd4e5b855bf93acafb4e43"
          }
        },
        "068fe1c4233a48f19190b1dd56213ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd8145d5dea3438a8946af3aaafb2720",
            "placeholder": "​",
            "style": "IPY_MODEL_4861bcfa1dc646c4a489d93eac552ad6",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "2a1ff2a30ee94ffa9932271eda6e4721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_125665f07abe496c9f5eee138e429af9",
            "max": 4961251752,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cdf155f28c3d49dc983910a2d36b73a6",
            "value": 4961251279
          }
        },
        "27b3b051a28e446cad71eba241ade2a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0e3c596b7b74384895b2ef3a0fab673",
            "placeholder": "​",
            "style": "IPY_MODEL_0e81618847c647e584cf6157c70c8aec",
            "value": " 4.96G/4.96G [00:35&lt;00:00, 586MB/s]"
          }
        },
        "9722e9bc08fd4e5b855bf93acafb4e43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd8145d5dea3438a8946af3aaafb2720": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4861bcfa1dc646c4a489d93eac552ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "125665f07abe496c9f5eee138e429af9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdf155f28c3d49dc983910a2d36b73a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0e3c596b7b74384895b2ef3a0fab673": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e81618847c647e584cf6157c70c8aec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "532c1499f6994e85a0f56e5f84113ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61aad554ae80420dae8a4ed0d43b6b98",
              "IPY_MODEL_38b4e8707df240a9b33a58181da2f7fa",
              "IPY_MODEL_bd65e9e73f364684a70c192cb12efbe1"
            ],
            "layout": "IPY_MODEL_ef73e4bb296d4cd594ff1b143ea6762a"
          }
        },
        "61aad554ae80420dae8a4ed0d43b6b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce0589351ce8457abff1c3ffc1f82aa4",
            "placeholder": "​",
            "style": "IPY_MODEL_d0039a5c81764190a86acc42ae75024b",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "38b4e8707df240a9b33a58181da2f7fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64f850ee5eb34fd19b31802fc0418702",
            "max": 3639026128,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbeef8ebf94f466f90fb5d222040552e",
            "value": 3639025781
          }
        },
        "bd65e9e73f364684a70c192cb12efbe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c057873bb9734eb1a1c76b8307cba50b",
            "placeholder": "​",
            "style": "IPY_MODEL_5f38fd44bf3c4bf99fc7c0f9db2eccce",
            "value": " 3.64G/3.64G [00:26&lt;00:00, 83.6MB/s]"
          }
        },
        "ef73e4bb296d4cd594ff1b143ea6762a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce0589351ce8457abff1c3ffc1f82aa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0039a5c81764190a86acc42ae75024b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64f850ee5eb34fd19b31802fc0418702": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbeef8ebf94f466f90fb5d222040552e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c057873bb9734eb1a1c76b8307cba50b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f38fd44bf3c4bf99fc7c0f9db2eccce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ce2d4369e354c90af3d368c97bdc298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_553d478825b441f59f0f3db403e22c88",
              "IPY_MODEL_9782a253427f4cdcaafa564aaf1a7ab0",
              "IPY_MODEL_b61659c63f41429f99c31d595b2a1c39"
            ],
            "layout": "IPY_MODEL_d522f5975f8649388a2cdfd2fc699d03"
          }
        },
        "553d478825b441f59f0f3db403e22c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19aa5b2e5b9d4a35b3c63428ece34cc2",
            "placeholder": "​",
            "style": "IPY_MODEL_7eeba66e23124a41a08662006c3e062b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "9782a253427f4cdcaafa564aaf1a7ab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84eaf468dcb846e4aa257c566eeab272",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af10503d00194e3a96fd621bcf935542",
            "value": 2
          }
        },
        "b61659c63f41429f99c31d595b2a1c39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0a956d4b54c458d9e07eb0e0ce62770",
            "placeholder": "​",
            "style": "IPY_MODEL_a6256ce3d83b4719aff95d75ca5b1c00",
            "value": " 2/2 [00:46&lt;00:00, 22.66s/it]"
          }
        },
        "d522f5975f8649388a2cdfd2fc699d03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19aa5b2e5b9d4a35b3c63428ece34cc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eeba66e23124a41a08662006c3e062b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84eaf468dcb846e4aa257c566eeab272": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af10503d00194e3a96fd621bcf935542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0a956d4b54c458d9e07eb0e0ce62770": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6256ce3d83b4719aff95d75ca5b1c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2431257f80f44abead42464dcc8a05c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee4c3dbae2024ac494f420fa93088e89",
              "IPY_MODEL_e14dbbbf963b4846955c1352d984faef",
              "IPY_MODEL_71fc6d5802714bde8126c4c5e49605a3"
            ],
            "layout": "IPY_MODEL_4437ef52e1954c9295471c8e2be03a87"
          }
        },
        "ee4c3dbae2024ac494f420fa93088e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05646ace0137483198a397d7a3fc985a",
            "placeholder": "​",
            "style": "IPY_MODEL_3892d6296e9a4394bdbeb58e6789679c",
            "value": "generation_config.json: 100%"
          }
        },
        "e14dbbbf963b4846955c1352d984faef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af0977b72be04e7a869a8c9c9ba642a2",
            "max": 133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01a604f599ef40939861719db73097b1",
            "value": 133
          }
        },
        "71fc6d5802714bde8126c4c5e49605a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74d0f7db585f47758a6b460e84cb7582",
            "placeholder": "​",
            "style": "IPY_MODEL_225c3ab3629a4cd2b253c5d7713bb790",
            "value": " 133/133 [00:00&lt;00:00, 9.65kB/s]"
          }
        },
        "4437ef52e1954c9295471c8e2be03a87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05646ace0137483198a397d7a3fc985a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3892d6296e9a4394bdbeb58e6789679c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af0977b72be04e7a869a8c9c9ba642a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01a604f599ef40939861719db73097b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74d0f7db585f47758a6b460e84cb7582": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "225c3ab3629a4cd2b253c5d7713bb790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f2bad2a3eff40b3b270b143c1f6ccb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2afd62336209494281516ee99bac7a61",
              "IPY_MODEL_b88158e143bd42e580f26ca8284b9483",
              "IPY_MODEL_d5bca391466540c9ba809218bba33d53"
            ],
            "layout": "IPY_MODEL_3ffbf6006f03469d901313d83286698c"
          }
        },
        "2afd62336209494281516ee99bac7a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27ab60c341654786b1d8589ee3afb2f4",
            "placeholder": "​",
            "style": "IPY_MODEL_956144dbd97b496cac4a37f260270aa1",
            "value": "processor_config.json: 100%"
          }
        },
        "b88158e143bd42e580f26ca8284b9483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af264cdb2ebd49c99db74e01b78d9108",
            "max": 70,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c89c1eb5beef440c8ecea770576c59b8",
            "value": 70
          }
        },
        "d5bca391466540c9ba809218bba33d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7832dc66587444558f4df04bc147676a",
            "placeholder": "​",
            "style": "IPY_MODEL_adafb018430b4fa4b6e1f64e98285794",
            "value": " 70.0/70.0 [00:00&lt;00:00, 6.76kB/s]"
          }
        },
        "3ffbf6006f03469d901313d83286698c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27ab60c341654786b1d8589ee3afb2f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "956144dbd97b496cac4a37f260270aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af264cdb2ebd49c99db74e01b78d9108": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c89c1eb5beef440c8ecea770576c59b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7832dc66587444558f4df04bc147676a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adafb018430b4fa4b6e1f64e98285794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b206c29bc9447898cc93c5702154819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4c923fe41af480f80266a57a1c1ccda",
              "IPY_MODEL_7f4d71db79314cee9ef922087c0965a7",
              "IPY_MODEL_b8ead4dd9b684bceb85d860153eb6b18"
            ],
            "layout": "IPY_MODEL_6b490bdcfcf44662a5ba02c07d50cf66"
          }
        },
        "d4c923fe41af480f80266a57a1c1ccda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4fe54bb67d64c3e99cd12b03f7295a8",
            "placeholder": "​",
            "style": "IPY_MODEL_8c49ea9001114dcd800c73254488264d",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "7f4d71db79314cee9ef922087c0965a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90c8fab0a2334fa7af9b7ffe055b054b",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8949dcdb6ee42369e9a1ef313c874f7",
            "value": 570
          }
        },
        "b8ead4dd9b684bceb85d860153eb6b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49c72031375941d08179d11ec3bd106e",
            "placeholder": "​",
            "style": "IPY_MODEL_d77ea93025c64642ae70a45b9ec66b0d",
            "value": " 570/570 [00:00&lt;00:00, 62.2kB/s]"
          }
        },
        "6b490bdcfcf44662a5ba02c07d50cf66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4fe54bb67d64c3e99cd12b03f7295a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c49ea9001114dcd800c73254488264d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90c8fab0a2334fa7af9b7ffe055b054b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8949dcdb6ee42369e9a1ef313c874f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49c72031375941d08179d11ec3bd106e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d77ea93025c64642ae70a45b9ec66b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62c54636ccd840b48160e1c833eec054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2a998d4a2f9405b86d907e4e10d50ad",
              "IPY_MODEL_ceceb043609d4886b71e29e90da28244",
              "IPY_MODEL_095100f1e81448659ba12e7f8e39fe69"
            ],
            "layout": "IPY_MODEL_82e6479d04ee4b9d82577610d8373a9f"
          }
        },
        "a2a998d4a2f9405b86d907e4e10d50ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abb44724bf50499b9ec6830935a509db",
            "placeholder": "​",
            "style": "IPY_MODEL_f37e4ebbee3842269bc4d4a4156f925c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ceceb043609d4886b71e29e90da28244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f13288e2c26c4b7cbb3f3b4f2b57336b",
            "max": 1155389,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2373845b731a4d359a46c62d785c29c5",
            "value": 1155389
          }
        },
        "095100f1e81448659ba12e7f8e39fe69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31c316a0964e43fba92098df0bf50039",
            "placeholder": "​",
            "style": "IPY_MODEL_1ec29bb8d63a4e7e9a1ff847d39cd13b",
            "value": " 1.16M/1.16M [00:00&lt;00:00, 2.63MB/s]"
          }
        },
        "82e6479d04ee4b9d82577610d8373a9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abb44724bf50499b9ec6830935a509db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f37e4ebbee3842269bc4d4a4156f925c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f13288e2c26c4b7cbb3f3b4f2b57336b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2373845b731a4d359a46c62d785c29c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31c316a0964e43fba92098df0bf50039": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ec29bb8d63a4e7e9a1ff847d39cd13b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "417b4214eddb4055a0dcffc88c08cd2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61d1a4efa9a449ff854f0738af985638",
              "IPY_MODEL_4a16fa86870949b29fdddc8a05e773d3",
              "IPY_MODEL_37a28c83aa1a4700bac8dcd2deefceaa"
            ],
            "layout": "IPY_MODEL_b7f26f8673014d4f9683d134854fc088"
          }
        },
        "61d1a4efa9a449ff854f0738af985638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3cc9f7a90e14586b30d58a53d26ca98",
            "placeholder": "​",
            "style": "IPY_MODEL_ac7fd53e47744a92941c0a627a7781c5",
            "value": "tokenizer.model: 100%"
          }
        },
        "4a16fa86870949b29fdddc8a05e773d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de1ee7d8849545dc9abd81009587a5e9",
            "max": 4689074,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb020d8de9ab490f87d976017f5c6251",
            "value": 4689074
          }
        },
        "37a28c83aa1a4700bac8dcd2deefceaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8637639681c741ca9f97472fe4d39e4d",
            "placeholder": "​",
            "style": "IPY_MODEL_f4fa3b5373794ac782a0ff0ade2a6b63",
            "value": " 4.69M/4.69M [00:00&lt;00:00, 122MB/s]"
          }
        },
        "b7f26f8673014d4f9683d134854fc088": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3cc9f7a90e14586b30d58a53d26ca98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac7fd53e47744a92941c0a627a7781c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de1ee7d8849545dc9abd81009587a5e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb020d8de9ab490f87d976017f5c6251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8637639681c741ca9f97472fe4d39e4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4fa3b5373794ac782a0ff0ade2a6b63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d15e35c12e0491fb26e92b8147e4820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9b7b55d3c1e4fe891ce8f5a6f60ad34",
              "IPY_MODEL_5a02d660ae8c49c6837e15b06f77f241",
              "IPY_MODEL_045013c68d674b7fa2fa19c1097ace1e"
            ],
            "layout": "IPY_MODEL_0adf342e6dd040638dc5a7b7ed5280ac"
          }
        },
        "f9b7b55d3c1e4fe891ce8f5a6f60ad34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_242f7843f19f489cb5dc7602d3f8c90e",
            "placeholder": "​",
            "style": "IPY_MODEL_36b050618f3c4312837f9d1d18530f26",
            "value": "tokenizer.json: 100%"
          }
        },
        "5a02d660ae8c49c6837e15b06f77f241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3aab8d0159294483bf720f669e976827",
            "max": 33384570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ab9336a6b304752acdd2a8a32b2aca6",
            "value": 33384570
          }
        },
        "045013c68d674b7fa2fa19c1097ace1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33982ab93dfa4a0a8f08797588b49911",
            "placeholder": "​",
            "style": "IPY_MODEL_0edbcc8835f04fa6a5c359a6a7ae86f6",
            "value": " 33.4M/33.4M [00:00&lt;00:00, 97.2MB/s]"
          }
        },
        "0adf342e6dd040638dc5a7b7ed5280ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "242f7843f19f489cb5dc7602d3f8c90e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36b050618f3c4312837f9d1d18530f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3aab8d0159294483bf720f669e976827": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ab9336a6b304752acdd2a8a32b2aca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33982ab93dfa4a0a8f08797588b49911": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0edbcc8835f04fa6a5c359a6a7ae86f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8231a484bf0e4ace9b57a598ddc300c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_904be891149148128b342a3c464d4c58",
              "IPY_MODEL_01eee35e587e4ff7a15b39057d550e37",
              "IPY_MODEL_9ab946b2ec3d4ff9bf5cfe3b553c193a"
            ],
            "layout": "IPY_MODEL_d454d4370f074e6d805d888ff5a20713"
          }
        },
        "904be891149148128b342a3c464d4c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b870834889047d6804efa7cf581d36a",
            "placeholder": "​",
            "style": "IPY_MODEL_ca63d6ade2e648eca271aa92ad7c86cd",
            "value": "added_tokens.json: 100%"
          }
        },
        "01eee35e587e4ff7a15b39057d550e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7c0697f4b104cb98e407a345c756a3d",
            "max": 35,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a97102043b45470bb77af0e50b106e46",
            "value": 35
          }
        },
        "9ab946b2ec3d4ff9bf5cfe3b553c193a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b14b7e4248c4a58af2bdf9740b70029",
            "placeholder": "​",
            "style": "IPY_MODEL_23a349dbdd9f4411bb03475d31bf63da",
            "value": " 35.0/35.0 [00:00&lt;00:00, 4.34kB/s]"
          }
        },
        "d454d4370f074e6d805d888ff5a20713": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b870834889047d6804efa7cf581d36a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca63d6ade2e648eca271aa92ad7c86cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7c0697f4b104cb98e407a345c756a3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a97102043b45470bb77af0e50b106e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b14b7e4248c4a58af2bdf9740b70029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23a349dbdd9f4411bb03475d31bf63da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6e1b8760fd04053b222461d9a141d6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ceb28f643a1649ac93ebabf54d5a1b6c",
              "IPY_MODEL_e8912505ce9f47cf8cb39544679b56e2",
              "IPY_MODEL_9cbb1b3a1bf54f78a40b5959988a1b67"
            ],
            "layout": "IPY_MODEL_deec6480ebe94136a3f48aaf2f442d2f"
          }
        },
        "ceb28f643a1649ac93ebabf54d5a1b6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55a982e80ad84f89b3818be1a4b07b15",
            "placeholder": "​",
            "style": "IPY_MODEL_14a0940cf02d4022928c440e51d756bc",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "e8912505ce9f47cf8cb39544679b56e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3024497255804f4ba4bdacf2eeac5323",
            "max": 662,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65f6e07542a14d68a091e6f980e89127",
            "value": 662
          }
        },
        "9cbb1b3a1bf54f78a40b5959988a1b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ff11d6515734ee6a03ff3f30f3c1e18",
            "placeholder": "​",
            "style": "IPY_MODEL_10a2e17402b140968ec05c0bea421202",
            "value": " 662/662 [00:00&lt;00:00, 47.9kB/s]"
          }
        },
        "deec6480ebe94136a3f48aaf2f442d2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55a982e80ad84f89b3818be1a4b07b15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14a0940cf02d4022928c440e51d756bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3024497255804f4ba4bdacf2eeac5323": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65f6e07542a14d68a091e6f980e89127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ff11d6515734ee6a03ff3f30f3c1e18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10a2e17402b140968ec05c0bea421202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ravikrishnan05/PrediscanMedtech_project/blob/main/Unsloth_ptmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4A4G9LfFoEEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1432e7e4-48b4-4588-eda4-5ff354dd0c94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Unsloth for Colab environment...\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (24.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (1.11.1.4)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: flash-attn in /usr/local/lib/python3.11/dist-packages (2.7.4.post1)\n",
            "Requirement already satisfied: xformers in /usr/local/lib/python3.11/dist-packages (0.0.30)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.18.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.0)\n",
            "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-_k6506q4/unsloth_531427091b904556b786c1c5efce533c\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-_k6506q4/unsloth_531427091b904556b786c1c5efce533c\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit 8c432a9d52a735f66fe1d3bcdfc0b2b0dc271a2e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# To run this, press \"Runtime\" and press \"Run all\" on a free Tesla T4 Google Colab instance!\n",
        "\n",
        "#    Join Discord if you need help + ⭐ Star us on Github ⭐\n",
        "# To install Unsloth on your own computer, follow the installation instructions on our Github page here.\n",
        "\n",
        "# You will learn how to do data prep, how to train, how to run the model, & how to save it\n",
        "\n",
        "# News\n",
        "# Unsloth now supports Text-to-Speech (TTS) models. Read our guide here.\n",
        "\n",
        "# Read our Qwen3 Guide and check out our new Dynamic 2.0 quants which outperforms other quantization methods!\n",
        "\n",
        "# Visit our docs for all our model uploads and notebooks.\n",
        "\n",
        "# To run this, press \"Runtime\" and press \"Run all\" on a free Tesla T4 Google Colab instance!\n",
        "# %%capture # Use %%capture to hide pip outputs if desired\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    print(\"Installing Unsloth for local environment...\")\n",
        "    !pip install \"unsloth[colab-new]@git+https://github.com/unslothai/unsloth.git\"\n",
        "else:\n",
        "    print(\"Installing Unsloth for Colab environment...\")\n",
        "    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n",
        "    !pip install --no-deps \"unsloth[colab-new]@git+https://github.com/unslothai/unsloth.git\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 0.2: Additional Library Installations\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\nInstalling additional libraries for data processing and DICOM handling...\")\n",
        "!pip install -q pydicom pandas opencv-python Pillow scikit-learn matplotlib seaborn \"huggingface_hub>=0.23.0\" \"hf_transfer>=0.1.6\" \"datasets>=2.16.0\" sentencepiece protobuf\n",
        "\n",
        "# Install unsloth_zoo\n",
        "print(\"\\nInstalling unsloth_zoo...\")\n",
        "!pip install unsloth_zoo"
      ],
      "metadata": {
        "id": "fhJQhFboqc1U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71039148-3c2d-45b7-9e83-27e5bf6bfd5c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Installing additional libraries for data processing and DICOM handling...\n",
            "\n",
            "Installing unsloth_zoo...\n",
            "Requirement already satisfied: unsloth_zoo in /usr/local/lib/python3.11/dist-packages (2025.5.11)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (2.6.0+cu124)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (3.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (24.2)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.9.24)\n",
            "Requirement already satisfied: transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,>=4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (4.52.3)\n",
            "Requirement already satisfied: datasets>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (3.6.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (2.0.2)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (1.7.0)\n",
            "Requirement already satisfied: trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.18.1)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.15.2)\n",
            "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (3.20.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.32.2)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.1.9)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (25.1.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (11.2.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (2024.11.6)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.19.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth_zoo) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth_zoo) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth_zoo) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth_zoo) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth_zoo) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth_zoo) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth_zoo) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth_zoo) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth_zoo) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.30.0->unsloth_zoo) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.30.0->unsloth_zoo) (1.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->unsloth_zoo) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,>=4.51.3->unsloth_zoo) (0.21.1)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth_zoo) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth_zoo) (13.9.4)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth_zoo) (1.7.2)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth_zoo) (4.4.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.4.1->unsloth_zoo) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.4.1->unsloth_zoo) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.4.1->unsloth_zoo) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.4.1->unsloth_zoo) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth_zoo) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth_zoo) (2.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->unsloth_zoo) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth_zoo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth_zoo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth_zoo) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (1.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth_zoo) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.4.1->unsloth_zoo) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unsloth FastModel supports loading nearly any model now! This includes Vision and Text models!\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Cell 0.3: Unsloth Model Loading\n",
        "# -----------------------------------------------------------------------------\n",
        "from unsloth import FastLanguageModel # Changed from FastModel to FastLanguageModel as per recent Unsloth examples for language models\n",
        "import torch"
      ],
      "metadata": {
        "id": "aTMppuNfrAxl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c59fc839-62f4-47c2-d300-3e4a67cb5a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.6.0+cu124)\n",
            "    Python  3.11.12 (you have 3.11.12)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: MODEL SELECTION FOR YOUR TASK\n",
        "# The model \"unsloth/gemma-3-4b-it\" is a TEXT-BASED instruct model.\n",
        "# Your original code used MedGemma, a VISION-LANGUAGE model, and processed images.\n",
        "# If your task involves processing images to predict LDL, you MUST select a vision-language model.\n",
        "# Examples:\n",
        "#   - Search for Unsloth-quantized vision models: https://huggingface.co/unsloth\n",
        "#   - Try loading a standard HF vision model (e.g., \"google/medgemma-4b-pt\", \"llava-hf/llava-1.5-7b-hf\", \"microsoft/phi-3-vision-128k-instruct\")\n",
        "#     FastLanguageModel might support them. If so, set `finetune_vision_layers = True` in the PEFT setup.\n",
        "# For this example, we'll use the text model from the Unsloth template.\n",
        "# You will need to adapt your data processing (especially image handling in the Dataset)\n",
        "# if you use a text model for a vision task, or change the model_name.\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "# --- Model Selection ---\n",
        "# We are focusing on MedGemma for vision-based LDL prediction.\n",
        "selected_model_name = \"google/medgemma-4b-pt\"\n",
        "\n",
        "print(f\"Attempting to load model: {selected_model_name}\")\n",
        "# When loading a multimodal model like MedGemma, FastLanguageModel handles it.\n",
        "# The 'tokenizer' returned will be a multimodal processor (e.g., GemmaProcessor)\n",
        "# which contains both the image_processor and the text_tokenizer.\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=selected_model_name,\n",
        "    max_seq_length=2048,  # Max sequence length for the language model part (less critical for pure vision regression)\n",
        "    dtype=None,           # Autodetect\n",
        "    load_in_4bit=True,    # Enable 4-bit quantization for memory efficiency\n",
        "    # token = \"hf_...\",   # Use if the model is gated\n",
        ")\n",
        "print(f\"Model {selected_model_name} loaded successfully.\")\n",
        "print(f\"Tokenizer type: {type(tokenizer)}\")\n",
        "\n",
        "# --- Verify Image Processor and Get Vision Feature Dimension ---\n",
        "# For MedGemma, the tokenizer is a GemmaProcessor which should have an 'image_processor'\n",
        "if hasattr(tokenizer, 'image_processor') and tokenizer.image_processor is not None:\n",
        "    print(\"Image processor found in tokenizer.\")\n",
        "    # The vision tower configuration is part of the main model's config for MedGemma\n",
        "    if hasattr(model.config, 'vision_config'):\n",
        "        vision_config = model.config.vision_config\n",
        "        # The vision feature dimension is typically 'hidden_size' of the vision_config\n",
        "        # For SigLIP (MedGemma's vision tower), it's usually referred to as hidden_size.\n",
        "        vision_feature_dim = vision_config.hidden_size\n",
        "        print(f\"Detected vision feature dimension from model.config.vision_config: {vision_feature_dim}\")\n",
        "    else:\n",
        "        print(\"ERROR: model.config.vision_config not found. Cannot determine vision_feature_dim automatically.\")\n",
        "        # Fallback: Try to inspect the vision_tower directly if it exists on the base model\n",
        "        # This path might be needed if Unsloth wraps the model differently.\n",
        "        base_model_ref = model.model if hasattr(model, 'model') else model\n",
        "        if hasattr(base_model_ref, 'vision_tower') and hasattr(base_model_ref.vision_tower, 'config'):\n",
        "            vision_feature_dim = base_model_ref.vision_tower.config.hidden_size\n",
        "            print(f\"Detected vision feature dimension from base_model.vision_tower.config: {vision_feature_dim}\")\n",
        "        else:\n",
        "            vision_feature_dim = None\n",
        "            print(\"ERROR: Could not access vision_tower.config. Manually inspect 'model' object and set vision_feature_dim.\")\n",
        "            print(\"Model structure:\", model) # Helps in debugging\n",
        "else:\n",
        "    print(\"ERROR: No image_processor found in the tokenizer. This is unexpected for MedGemma.\")\n",
        "    vision_feature_dim = None\n",
        "\n",
        "if vision_feature_dim is None:\n",
        "    print(\"CRITICAL ERROR: vision_feature_dim could not be determined. Regression head cannot be initialized correctly.\")\n",
        "    # You might need to manually set it based on MedGemma's architecture if auto-detection fails.\n",
        "    # For medgemma-4b-pt, the vision feature dimension (SigLIP-L/16) is 1024.\n",
        "    vision_feature_dim = 1152 # Example: Manually set if necessary\n",
        "    print(f\"Attempting to use manually set vision_feature_dim: {vision_feature_dim}\")\n",
        "\n",
        "# Note: For vision models, the 'tokenizer' might be a composite object\n",
        "# or you might access an image processor via `model.processor` or `tokenizer.image_processor`.\n",
        "# This depends on how Unsloth handles vision models."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802,
          "referenced_widgets": [
            "691a563e6352460485aebd193c1dea13",
            "e63127351f7844a9877e563576c09d46",
            "497403c755614dc6a78d1ac565c0fcfd",
            "b20cf3bfb69b43d69b92cb3b764c1537",
            "af329f57e5664d8bb07b7833bb43f85c",
            "6f5b1fe3fc984ce79347daabdbed9849",
            "8334130850a64dba8111928f84110962",
            "37e6bb2cbccc4b95b9d3cba0e2d978f1",
            "01fd78dc354e4e44b0b26363e7a4872d",
            "89c9e0a1687f45c6a471299a01c08cbf",
            "b0570efcf36e4b93892395762a8fdae2",
            "62a5f0e90628451db1288a0b32677180",
            "068fe1c4233a48f19190b1dd56213ca5",
            "2a1ff2a30ee94ffa9932271eda6e4721",
            "27b3b051a28e446cad71eba241ade2a8",
            "9722e9bc08fd4e5b855bf93acafb4e43",
            "fd8145d5dea3438a8946af3aaafb2720",
            "4861bcfa1dc646c4a489d93eac552ad6",
            "125665f07abe496c9f5eee138e429af9",
            "cdf155f28c3d49dc983910a2d36b73a6",
            "d0e3c596b7b74384895b2ef3a0fab673",
            "0e81618847c647e584cf6157c70c8aec",
            "532c1499f6994e85a0f56e5f84113ffa",
            "61aad554ae80420dae8a4ed0d43b6b98",
            "38b4e8707df240a9b33a58181da2f7fa",
            "bd65e9e73f364684a70c192cb12efbe1",
            "ef73e4bb296d4cd594ff1b143ea6762a",
            "ce0589351ce8457abff1c3ffc1f82aa4",
            "d0039a5c81764190a86acc42ae75024b",
            "64f850ee5eb34fd19b31802fc0418702",
            "dbeef8ebf94f466f90fb5d222040552e",
            "c057873bb9734eb1a1c76b8307cba50b",
            "5f38fd44bf3c4bf99fc7c0f9db2eccce",
            "4ce2d4369e354c90af3d368c97bdc298",
            "553d478825b441f59f0f3db403e22c88",
            "9782a253427f4cdcaafa564aaf1a7ab0",
            "b61659c63f41429f99c31d595b2a1c39",
            "d522f5975f8649388a2cdfd2fc699d03",
            "19aa5b2e5b9d4a35b3c63428ece34cc2",
            "7eeba66e23124a41a08662006c3e062b",
            "84eaf468dcb846e4aa257c566eeab272",
            "af10503d00194e3a96fd621bcf935542",
            "f0a956d4b54c458d9e07eb0e0ce62770",
            "a6256ce3d83b4719aff95d75ca5b1c00",
            "2431257f80f44abead42464dcc8a05c6",
            "ee4c3dbae2024ac494f420fa93088e89",
            "e14dbbbf963b4846955c1352d984faef",
            "71fc6d5802714bde8126c4c5e49605a3",
            "4437ef52e1954c9295471c8e2be03a87",
            "05646ace0137483198a397d7a3fc985a",
            "3892d6296e9a4394bdbeb58e6789679c",
            "af0977b72be04e7a869a8c9c9ba642a2",
            "01a604f599ef40939861719db73097b1",
            "74d0f7db585f47758a6b460e84cb7582",
            "225c3ab3629a4cd2b253c5d7713bb790",
            "9f2bad2a3eff40b3b270b143c1f6ccb1",
            "2afd62336209494281516ee99bac7a61",
            "b88158e143bd42e580f26ca8284b9483",
            "d5bca391466540c9ba809218bba33d53",
            "3ffbf6006f03469d901313d83286698c",
            "27ab60c341654786b1d8589ee3afb2f4",
            "956144dbd97b496cac4a37f260270aa1",
            "af264cdb2ebd49c99db74e01b78d9108",
            "c89c1eb5beef440c8ecea770576c59b8",
            "7832dc66587444558f4df04bc147676a",
            "adafb018430b4fa4b6e1f64e98285794",
            "5b206c29bc9447898cc93c5702154819",
            "d4c923fe41af480f80266a57a1c1ccda",
            "7f4d71db79314cee9ef922087c0965a7",
            "b8ead4dd9b684bceb85d860153eb6b18",
            "6b490bdcfcf44662a5ba02c07d50cf66",
            "d4fe54bb67d64c3e99cd12b03f7295a8",
            "8c49ea9001114dcd800c73254488264d",
            "90c8fab0a2334fa7af9b7ffe055b054b",
            "a8949dcdb6ee42369e9a1ef313c874f7",
            "49c72031375941d08179d11ec3bd106e",
            "d77ea93025c64642ae70a45b9ec66b0d",
            "62c54636ccd840b48160e1c833eec054",
            "a2a998d4a2f9405b86d907e4e10d50ad",
            "ceceb043609d4886b71e29e90da28244",
            "095100f1e81448659ba12e7f8e39fe69",
            "82e6479d04ee4b9d82577610d8373a9f",
            "abb44724bf50499b9ec6830935a509db",
            "f37e4ebbee3842269bc4d4a4156f925c",
            "f13288e2c26c4b7cbb3f3b4f2b57336b",
            "2373845b731a4d359a46c62d785c29c5",
            "31c316a0964e43fba92098df0bf50039",
            "1ec29bb8d63a4e7e9a1ff847d39cd13b",
            "417b4214eddb4055a0dcffc88c08cd2d",
            "61d1a4efa9a449ff854f0738af985638",
            "4a16fa86870949b29fdddc8a05e773d3",
            "37a28c83aa1a4700bac8dcd2deefceaa",
            "b7f26f8673014d4f9683d134854fc088",
            "c3cc9f7a90e14586b30d58a53d26ca98",
            "ac7fd53e47744a92941c0a627a7781c5",
            "de1ee7d8849545dc9abd81009587a5e9",
            "fb020d8de9ab490f87d976017f5c6251",
            "8637639681c741ca9f97472fe4d39e4d",
            "f4fa3b5373794ac782a0ff0ade2a6b63",
            "9d15e35c12e0491fb26e92b8147e4820",
            "f9b7b55d3c1e4fe891ce8f5a6f60ad34",
            "5a02d660ae8c49c6837e15b06f77f241",
            "045013c68d674b7fa2fa19c1097ace1e",
            "0adf342e6dd040638dc5a7b7ed5280ac",
            "242f7843f19f489cb5dc7602d3f8c90e",
            "36b050618f3c4312837f9d1d18530f26",
            "3aab8d0159294483bf720f669e976827",
            "4ab9336a6b304752acdd2a8a32b2aca6",
            "33982ab93dfa4a0a8f08797588b49911",
            "0edbcc8835f04fa6a5c359a6a7ae86f6",
            "8231a484bf0e4ace9b57a598ddc300c1",
            "904be891149148128b342a3c464d4c58",
            "01eee35e587e4ff7a15b39057d550e37",
            "9ab946b2ec3d4ff9bf5cfe3b553c193a",
            "d454d4370f074e6d805d888ff5a20713",
            "7b870834889047d6804efa7cf581d36a",
            "ca63d6ade2e648eca271aa92ad7c86cd",
            "d7c0697f4b104cb98e407a345c756a3d",
            "a97102043b45470bb77af0e50b106e46",
            "0b14b7e4248c4a58af2bdf9740b70029",
            "23a349dbdd9f4411bb03475d31bf63da",
            "a6e1b8760fd04053b222461d9a141d6f",
            "ceb28f643a1649ac93ebabf54d5a1b6c",
            "e8912505ce9f47cf8cb39544679b56e2",
            "9cbb1b3a1bf54f78a40b5959988a1b67",
            "deec6480ebe94136a3f48aaf2f442d2f",
            "55a982e80ad84f89b3818be1a4b07b15",
            "14a0940cf02d4022928c440e51d756bc",
            "3024497255804f4ba4bdacf2eeac5323",
            "65f6e07542a14d68a091e6f980e89127",
            "5ff11d6515734ee6a03ff3f30f3c1e18",
            "10a2e17402b140968ec05c0bea421202"
          ]
        },
        "id": "6CH2bYyCacJB",
        "outputId": "0fac4d06-51c4-428c-bb82-5a3158ffcbfd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.6.0+cu124)\n",
            "    Python  3.11.12 (you have 3.11.12)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "Attempting to load model: google/medgemma-4b-pt\n",
            "==((====))==  Unsloth 2025.5.10: Fast Gemma3 patching. Transformers: 4.52.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: Using float16 precision for gemma3 won't work! Using float32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/90.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "691a563e6352460485aebd193c1dea13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62a5f0e90628451db1288a0b32677180"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.64G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "532c1499f6994e85a0f56e5f84113ffa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ce2d4369e354c90af3d368c97bdc298"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/133 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2431257f80f44abead42464dcc8a05c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "processor_config.json:   0%|          | 0.00/70.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f2bad2a3eff40b3b270b143c1f6ccb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b206c29bc9447898cc93c5702154819"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62c54636ccd840b48160e1c833eec054"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "417b4214eddb4055a0dcffc88c08cd2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d15e35c12e0491fb26e92b8147e4820"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8231a484bf0e4ace9b57a598ddc300c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6e1b8760fd04053b222461d9a141d6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model google/medgemma-4b-pt loaded successfully.\n",
            "Tokenizer type: <class 'transformers.models.gemma3.processing_gemma3.Gemma3Processor'>\n",
            "Image processor found in tokenizer.\n",
            "Detected vision feature dimension from model.config.vision_config: 1152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After loading the model with Unsloth:\n",
        "# The actual path might be model.model.vision_tower if PEFT wraps it further\n",
        "base_medgemma_model = model.model if hasattr(model, 'model') else model # Access base model if PEFT wrapped\n",
        "\n",
        "if hasattr(base_medgemma_model, 'vision_tower') and hasattr(base_medgemma_model.vision_tower, 'config'):\n",
        "    vision_config = base_medgemma_model.vision_tower.config\n",
        "    vision_feature_dim = vision_config.hidden_size\n",
        "    print(f\"Detected vision feature dimension: {vision_feature_dim}\")\n",
        "    # Now define your regression head separately or as part of a wrapper\n",
        "    # regression_head = torch.nn.Linear(vision_feature_dim, 1)\n",
        "else:\n",
        "    print(\"ERROR: Could not access model.vision_tower.config to get vision_feature_dim.\")\n",
        "    print(\"Please inspect the 'model' object structure from Unsloth carefully.\")\n",
        "    # You might need to print(model) and explore its attributes\n",
        "    vision_feature_dim = None # Fallback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7rHCq-aceho",
        "outputId": "6c2845df-b6d5-4a91-ebe5-3598bfed5c12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected vision feature dimension: 1152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Applying PEFT (LoRA) ---\")\n",
        "# `model` is the Unsloth-loaded MedGemma model from the previous cell.\n",
        "# We use get_peft_model for LoRA.\n",
        "RANDOM_SEED=42\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,  # LoRA rank (higher can mean more expressiveness but more params)\n",
        "    lora_alpha=32,  # LoRA alpha (scaling factor, often 2*r)\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\", # Recommended by Unsloth\n",
        "    random_state=RANDOM_SEED,\n",
        "    target_modules=None, # Let Unsloth automatically find layers for LoRA.\n",
        "                         # It should target both vision and language linear layers by default.\n",
        "    finetune_vision_layers=True, # CRITICAL: Ensure vision tower layers are targeted for LoRA\n",
        "    finetune_language_layers=False # OPTIONAL: For pure vision regression, we might not need to tune language layers.\n",
        "                                  # Set to False if language model outputs are not used by the regression head.\n",
        "                                  # If True (default), language LoRA adapters will also be trained.\n",
        ")\n",
        "print(\"PEFT (LoRA) adapters added to the MedGemma model.\")\n",
        "print(\"Trainable parameters after LoRA:\")\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APwpZTzwUoES",
        "outputId": "fcebc6f7-60ef-4f6b-fd23-f08776916260"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Applying PEFT (LoRA) ---\n",
            "Unsloth: Making `base_model.model.model.vision_tower.vision_model` require gradients\n",
            "PEFT (LoRA) adapters added to the MedGemma model.\n",
            "Trainable parameters after LoRA:\n",
            "trainable params: 8,695,296 || all params: 4,308,774,768 || trainable%: 0.2018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import torch.nn as nn\n",
        "\n",
        "class MedGemmaVisionRegressor(nn.Module):\n",
        "    def __init__(self, peft_medgemma_model, vision_feature_dim_input: int):\n",
        "        super().__init__()\n",
        "        self.medgemma_model = peft_medgemma_model # This is the PEFT-adapted model from Unsloth\n",
        "\n",
        "        # The regression head takes the pooled vision features and outputs 1 LDL value\n",
        "        self.regression_head = nn.Sequential(\n",
        "            nn.Linear(vision_feature_dim_input, vision_feature_dim_input // 2), # Intermediate layer\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(vision_feature_dim_input // 2, 1) # Output layer\n",
        "        )\n",
        "\n",
        "        # Note: Freezing of base MedGemma layers is handled by Unsloth's PEFT.\n",
        "        # LoRA adapters are trainable. The regression_head is also trainable.\n",
        "\n",
        "    def forward(self, pixel_values: torch.Tensor) -> torch.Tensor:\n",
        "        # The peft_medgemma_model is already a PeftModel.\n",
        "        # We need to pass pixel_values to it.\n",
        "        # The MedGemma model's forward pass can take pixel_values directly.\n",
        "        # It will internally use its vision_tower.\n",
        "        # For regression from vision, we typically want the pooled image features.\n",
        "\n",
        "        # Option 1: If the PEFT model directly gives vision features or allows access\n",
        "        # The `Gemma3ForMultiModalGeneration` (base for MedGemma) has `vision_tower`\n",
        "        # and can output `image_embeds` or similar.\n",
        "        # When using PEFT, the base model is often accessed via `self.medgemma_model.model`\n",
        "\n",
        "        base_model = self.medgemma_model.model # Access the original model underlying PEFT\n",
        "\n",
        "        # Get vision embeddings from the vision_tower\n",
        "        # The vision_tower (SigLIP) in MedGemma outputs pooled features.\n",
        "        vision_outputs = base_model.vision_tower(pixel_values=pixel_values, return_dict=True)\n",
        "\n",
        "        # `pooler_output` from SigLipVisionModelOutput is [batch_size, vision_feature_dim]\n",
        "        image_features = vision_outputs.pooler_output\n",
        "\n",
        "        if image_features is None:\n",
        "            # Fallback if pooler_output is not directly available (should be for SigLIP)\n",
        "            # This might happen if the model structure is different than expected.\n",
        "            # For ViT-like models, the first token's embedding ([CLS] token) is often used.\n",
        "            if hasattr(vision_outputs, 'last_hidden_state'):\n",
        "                image_features = vision_outputs.last_hidden_state[:, 0, :] # CLS token embedding\n",
        "            else:\n",
        "                raise ValueError(\"Could not extract pooled image features (pooler_output or CLS token) from vision_tower output.\")\n",
        "\n",
        "        # Pass vision features through the regression head\n",
        "        ldl_prediction = self.regression_head(image_features)\n",
        "        return ldl_prediction\n",
        "\n",
        "# --- Instantiate the Regressor Model ---\n",
        "if vision_feature_dim is not None:\n",
        "    # `model` here is the PEFT-adapted MedGemma model from Cell 0.4\n",
        "    regressor_model = MedGemmaVisionRegressor(model, vision_feature_dim)\n",
        "    print(f\"MedGemmaVisionRegressor created with regression head input dim {vision_feature_dim}.\")\n",
        "\n",
        "    # Move to GPU if available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    regressor_model.to(device)\n",
        "    print(f\"Regressor model moved to {device}.\")\n",
        "\n",
        "    print(\"\\nTrainable parameters of the Regressor Model (includes LoRA + head):\")\n",
        "    total_params = 0\n",
        "    trainable_params = 0\n",
        "    for name, param in regressor_model.named_parameters():\n",
        "        total_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "            # print(f\"Trainable: {name}, Shape: {param.shape}\") # Uncomment to see all trainable params\n",
        "    print(f\"Total parameters in RegressorModel: {total_params:,}\")\n",
        "    print(f\"Trainable parameters in RegressorModel: {trainable_params:,} ({100 * trainable_params / total_params:.2f}%)\")\n",
        "\n",
        "else:\n",
        "    regressor_model = None\n",
        "    print(\"CRITICAL ERROR: Cannot create MedGemmaVisionRegressor because vision_feature_dim is None.\")\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Cell 0.5: Define and Instantiate Custom Model Wrapper (MedGemmaVisionRegressor) - REVISED\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class MedGemmaVisionRegressor(nn.Module):\n",
        "    def __init__(self, peft_medgemma_model, vision_feature_dim_input: int):\n",
        "        super().__init__()\n",
        "        self.medgemma_model = peft_medgemma_model # This is the PEFT-adapted model from Unsloth\n",
        "        self.target_dtype = self.medgemma_model.dtype # Store the target dtype (e.g., bfloat16)\n",
        "        print(f\"[Regressor Init] Base PEFT model target dtype: {self.target_dtype}\")\n",
        "\n",
        "        # The regression head takes the pooled vision features and outputs 1 LDL value\n",
        "        self.regression_head = nn.Sequential(\n",
        "            nn.Linear(vision_feature_dim_input, vision_feature_dim_input // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(vision_feature_dim_input // 2, 1)\n",
        "        )\n",
        "\n",
        "        # Explicitly cast the regression head to the target_dtype\n",
        "        if self.target_dtype is not None:\n",
        "            print(f\"[Regressor Init] Casting regression_head to {self.target_dtype}.\")\n",
        "            self.regression_head = self.regression_head.to(dtype=self.target_dtype)\n",
        "\n",
        "\n",
        "    def forward(self, pixel_values: torch.Tensor) -> torch.Tensor:\n",
        "        # Input pixel_values should already be cast to self.target_dtype in the training loop\n",
        "        # print_once_train_loop(f\"[Regressor Fwd] Input pixel_values dtype: {pixel_values.dtype}\")\n",
        "\n",
        "        base_model = self.medgemma_model.model # Access the original model underlying PEFT\n",
        "\n",
        "        # Vision tower call\n",
        "        # The `pixel_values` are already expected to be in `self.target_dtype`\n",
        "        vision_outputs = base_model.vision_tower(pixel_values=pixel_values, return_dict=True)\n",
        "\n",
        "        image_features = vision_outputs.pooler_output\n",
        "\n",
        "        if image_features is None:\n",
        "            if hasattr(vision_outputs, 'last_hidden_state'):\n",
        "                image_features = vision_outputs.last_hidden_state[:, 0, :]\n",
        "            else:\n",
        "                raise ValueError(\"Could not extract pooled image features from vision_tower output.\")\n",
        "\n",
        "        # Ensure image_features are in the target_dtype before feeding to regression_head\n",
        "        # (Usually, they come out of the vision tower in the model's operating dtype)\n",
        "        if image_features.dtype != self.target_dtype:\n",
        "            # This print would be very informative if it triggers\n",
        "            print_once_train_loop(f\"[Regressor Fwd] WARNING: image_features dtype {image_features.dtype} != target_dtype {self.target_dtype}. Casting.\")\n",
        "            image_features = image_features.to(self.target_dtype)\n",
        "\n",
        "        # print_once_train_loop(f\"[Regressor Fwd] image_features (to regression_head) dtype: {image_features.dtype}\")\n",
        "\n",
        "        ldl_prediction = self.regression_head(image_features)\n",
        "        # print_once_train_loop(f\"[Regressor Fwd] ldl_prediction (output) dtype: {ldl_prediction.dtype}\")\n",
        "        return ldl_prediction\n",
        "\n",
        "# --- Instantiate the Regressor Model ---\n",
        "if vision_feature_dim is not None and 'model' in locals() and model is not None:\n",
        "    # `model` here is the PEFT-adapted MedGemma model from Cell 0.4\n",
        "    regressor_model = MedGemmaVisionRegressor(model, vision_feature_dim)\n",
        "    print(f\"MedGemmaVisionRegressor created with regression head input dim {vision_feature_dim}.\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    regressor_model.to(device) # Move to device first\n",
        "    print(f\"Regressor model moved to {device}.\")\n",
        "\n",
        "    # The casting of the whole model will be attempted in Cell 9\n",
        "    # after it's on the correct device.\n",
        "\n",
        "    print(\"\\nTrainable parameters of the Regressor Model (includes LoRA + head):\")\n",
        "    # (Parameter printing code from your previous Cell 0.5)\n",
        "    total_params = 0\n",
        "    trainable_params = 0\n",
        "    for name, param in regressor_model.named_parameters():\n",
        "        total_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(f\"Total parameters in RegressorModel: {total_params:,}\")\n",
        "    print(f\"Trainable parameters in RegressorModel: {trainable_params:,} ({100 * trainable_params / total_params:.2f}%)\")\n",
        "\n",
        "else:\n",
        "    regressor_model = None\n",
        "    print(\"CRITICAL ERROR: Cannot create MedGemmaVisionRegressor. Check 'vision_feature_dim' and 'model' (PEFT model).\")"
      ],
      "metadata": {
        "id": "ZKo4mLwBchne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f634103-50c8-47e5-9b12-60b11f86e297"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Regressor Init] Base PEFT model target dtype: torch.bfloat16\n",
            "[Regressor Init] Casting regression_head to torch.bfloat16.\n",
            "MedGemmaVisionRegressor created with regression head input dim 1152.\n",
            "Regressor model moved to cuda.\n",
            "\n",
            "Trainable parameters of the Regressor Model (includes LoRA + head):\n",
            "Total parameters in RegressorModel: 2,499,582,961\n",
            "Trainable parameters in RegressorModel: 9,360,001 (0.37%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 1: PyTorch/HuggingFace Imports and Setup (Adapted from user's Cell 1)\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\nImporting libraries...\")\n",
        "# Python Standard Libraries\n",
        "import shutil # os, zipfile already imported or not needed here\n",
        "import zipfile\n",
        "\n",
        "# Third-party Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import cv2 # OpenCV\n",
        "from PIL import Image\n",
        "\n",
        "# PyTorch\n",
        "# import torch # Already imported\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Hugging Face (tokenizer is already loaded by Unsloth)\n",
        "# from transformers import AutoProcessor # Replaced by Unsloth's tokenizer\n",
        "\n",
        "# Plotting (optional, but often useful)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Colab specific\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"--- Library Version Checks ---\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "import sklearn\n",
        "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
        "# print(f\"TensorFlow Version: {tf.__version__}\") # TensorFlow not used in this Unsloth/PyTorch setup\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    print(f\"PyTorch CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU available for PyTorch: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"GPU not available for PyTorch, using CPU.\")\n",
        "\n",
        "# For reproducibility\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "print(\"\\nCell 1: Imports and basic setup complete.\")"
      ],
      "metadata": {
        "id": "BUr3OCOxsODW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79ea0713-5c99-4625-b3af-901388892a8b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Importing libraries...\n",
            "--- Library Version Checks ---\n",
            "Pandas version: 2.2.2\n",
            "NumPy version: 2.0.2\n",
            "Scikit-learn version: 1.6.1\n",
            "PyTorch version: 2.6.0+cu124\n",
            "PyTorch CUDA version: 12.4\n",
            "GPU available for PyTorch: Tesla T4\n",
            "\n",
            "Cell 1: Imports and basic setup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------\n",
        "# Cell 2: Configuration and Unzip Data (From user's Cell 2)\n",
        "# --------------------------------------------------\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# --- Configuration ---\n",
        "DRIVE_CSV_PATH = \"/content/drive/MyDrive/cp.csv\"\n",
        "DRIVE_ZIP_PATH = \"/content/drive/MyDrive/1000-20250517T062750Z-1-001.zip\" # Your image ZIP on Drive\n",
        "\n",
        "LOCAL_EXTRACT_PATH = \"/content/medgemma_extracted_images\"\n",
        "LOCAL_IMAGES_ROOT = os.path.join(LOCAL_EXTRACT_PATH, \"1000\") # Adjusted to match your structure\n",
        "LOCAL_CSV_PATH = \"/content/medgemma_cp.csv\"\n",
        "\n",
        "# --- Unzip Data (if not already done or if re-running) ---\n",
        "if os.path.exists(DRIVE_CSV_PATH):\n",
        "    shutil.copy(DRIVE_CSV_PATH, LOCAL_CSV_PATH)\n",
        "    print(f\"CSV copied to {LOCAL_CSV_PATH}\")\n",
        "else:\n",
        "    print(f\"ERROR: CSV file not found at {DRIVE_CSV_PATH}\")\n",
        "\n",
        "if os.path.exists(LOCAL_EXTRACT_PATH):\n",
        "    print(f\"Removing existing extraction directory: {LOCAL_EXTRACT_PATH}\")\n",
        "    shutil.rmtree(LOCAL_EXTRACT_PATH)\n",
        "os.makedirs(LOCAL_EXTRACT_PATH, exist_ok=True)\n",
        "print(f\"Created local extraction directory: {LOCAL_EXTRACT_PATH}\")\n",
        "\n",
        "if os.path.exists(DRIVE_ZIP_PATH):\n",
        "    print(f\"Unzipping {DRIVE_ZIP_PATH} to {LOCAL_EXTRACT_PATH}...\")\n",
        "    with zipfile.ZipFile(DRIVE_ZIP_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall(LOCAL_EXTRACT_PATH)\n",
        "    print(\"Unzipping complete.\")\n",
        "    if os.path.exists(LOCAL_IMAGES_ROOT):\n",
        "        print(f\"Image root folder found at: {LOCAL_IMAGES_ROOT}\")\n",
        "    else:\n",
        "        print(f\"ERROR: Expected image root folder '{LOCAL_IMAGES_ROOT}' not found after unzipping. Check ZIP structure.\")\n",
        "        print(f\"Contents of {LOCAL_EXTRACT_PATH}: {os.listdir(LOCAL_EXTRACT_PATH)}\")\n",
        "\n",
        "else:\n",
        "    print(f\"ERROR: ZIP file not found at {DRIVE_ZIP_PATH}\")\n",
        "\n",
        "print(\"\\nCell 2: Data unzipping complete.\")\n"
      ],
      "metadata": {
        "id": "qKhbFStitDQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c980474-6347-4af4-9202-86f4208be170"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "CSV copied to /content/medgemma_cp.csv\n",
            "Created local extraction directory: /content/medgemma_extracted_images\n",
            "Unzipping /content/drive/MyDrive/1000-20250517T062750Z-1-001.zip to /content/medgemma_extracted_images...\n",
            "Unzipping complete.\n",
            "Image root folder found at: /content/medgemma_extracted_images/1000\n",
            "\n",
            "Cell 2: Data unzipping complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------\n",
        "# Cell 3: Load and Filter Clinical Data to create image_df (From user's Cell 3)\n",
        "# --------------------------------------------------\n",
        "image_df = pd.DataFrame()\n",
        "\n",
        "if not os.path.exists(LOCAL_CSV_PATH):\n",
        "    print(f\"FATAL ERROR: Clinical CSV file not found at the expected local path: {LOCAL_CSV_PATH}\")\n",
        "else:\n",
        "    df_raw_from_cell3 = pd.read_csv(LOCAL_CSV_PATH)\n",
        "    print(f\"Initial number of rows in clinical data (Cell 3): {len(df_raw_from_cell3)}\")\n",
        "\n",
        "    person_id_col_name_c3 = 'person_id'\n",
        "    ldl_col_name_c3 = \"LDL Cholesterol Calculation (mg/dL)\" # Ensure this matches your CSV header\n",
        "\n",
        "    if not (person_id_col_name_c3 in df_raw_from_cell3.columns and ldl_col_name_c3 in df_raw_from_cell3.columns):\n",
        "        print(f\"ERROR: Required columns ('{person_id_col_name_c3}' or '{ldl_col_name_c3}') not found in CSV.\")\n",
        "        print(f\"Available columns: {df_raw_from_cell3.columns.tolist()}\")\n",
        "    else:\n",
        "        df_selected_c3 = df_raw_from_cell3[[person_id_col_name_c3, ldl_col_name_c3]].copy()\n",
        "        df_selected_c3.rename(columns={ldl_col_name_c3: 'LDL_temp'}, inplace=True)\n",
        "        df_selected_c3['LDL_temp'] = pd.to_numeric(df_selected_c3['LDL_temp'], errors='coerce')\n",
        "        df_selected_c3.dropna(subset=['LDL_temp'], inplace=True)\n",
        "        df_selected_c3 = df_selected_c3[df_selected_c3['LDL_temp'] > 0].copy()\n",
        "        df_selected_c3[person_id_col_name_c3] = df_selected_c3[person_id_col_name_c3].astype(str)\n",
        "        print(f\"Cleaned clinical data (positive LDLs only): {len(df_selected_c3)} records.\")\n",
        "\n",
        "        ldl_lookup_c3 = df_selected_c3.set_index(person_id_col_name_c3)['LDL_temp'].to_dict()\n",
        "\n",
        "        if not (os.path.exists(LOCAL_IMAGES_ROOT) and os.path.isdir(LOCAL_IMAGES_ROOT)):\n",
        "            print(f\"FATAL ERROR: Images root path '{LOCAL_IMAGES_ROOT}' does not exist or is not a directory.\")\n",
        "        else:\n",
        "            available_folders_c3 = set(os.listdir(LOCAL_IMAGES_ROOT))\n",
        "            valid_ids_clinical_c3 = set(ldl_lookup_c3.keys())\n",
        "            common_person_ids_c3 = sorted(list(valid_ids_clinical_c3 & available_folders_c3))\n",
        "            print(f\"Found {len(common_person_ids_c3)} common person_ids for mapping.\")\n",
        "\n",
        "            image_records_list = []\n",
        "            for pid_c3 in common_person_ids_c3:\n",
        "                folder_path_c3 = os.path.join(LOCAL_IMAGES_ROOT, pid_c3)\n",
        "                ldl_val_c3 = ldl_lookup_c3[pid_c3]\n",
        "                if os.path.isdir(folder_path_c3):\n",
        "                    for filename_c3 in os.listdir(folder_path_c3):\n",
        "                        if filename_c3.lower().endswith(\".dcm\"):\n",
        "                            image_path_c3 = os.path.join(folder_path_c3, filename_c3)\n",
        "                            image_records_list.append({\n",
        "                                \"person_id\": pid_c3,\n",
        "                                \"image_path\": image_path_c3,\n",
        "                                \"LDL\": ldl_val_c3\n",
        "                            })\n",
        "            image_df = pd.DataFrame(image_records_list)\n",
        "            if not image_df.empty:\n",
        "                print(f\"Final image_df created with {len(image_df)} image-LDL pairs.\")\n",
        "                from IPython.display import display # For better display in Colab\n",
        "                display(image_df.head())\n",
        "                print(f\"LDL stats in final image_df: min={image_df['LDL'].min()}, max={image_df['LDL'].max()}, mean={image_df['LDL'].mean()}\")\n",
        "            else:\n",
        "                print(\"WARNING: image_df is empty after mapping. Check paths, IDs, and DICOM file existence.\")\n",
        "print(\"\\nCell 3: image_df preparation complete.\")"
      ],
      "metadata": {
        "id": "nyRLqIrUtLLR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "954666f5-6aae-484c-baeb-aa9bb8705de3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial number of rows in clinical data (Cell 3): 1067\n",
            "Cleaned clinical data (positive LDLs only): 1025 records.\n",
            "Found 527 common person_ids for mapping.\n",
            "Final image_df created with 973 image-LDL pairs.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  person_id                                         image_path         LDL\n",
              "0      1002  /content/medgemma_extracted_images/1000/1002/1...  133.485054\n",
              "1      1004  /content/medgemma_extracted_images/1000/1004/1...   59.674544\n",
              "2      1004  /content/medgemma_extracted_images/1000/1004/1...   59.674544\n",
              "3      1005  /content/medgemma_extracted_images/1000/1005/1...   74.956702\n",
              "4      1007  /content/medgemma_extracted_images/1000/1007/1...   92.278412"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a62964b7-8e9d-4ac9-b9c5-b8510bf8c064\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>person_id</th>\n",
              "      <th>image_path</th>\n",
              "      <th>LDL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1002</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1002/1...</td>\n",
              "      <td>133.485054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1004</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1004/1...</td>\n",
              "      <td>59.674544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1004</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1004/1...</td>\n",
              "      <td>59.674544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1005</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1005/1...</td>\n",
              "      <td>74.956702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1007</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1007/1...</td>\n",
              "      <td>92.278412</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a62964b7-8e9d-4ac9-b9c5-b8510bf8c064')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a62964b7-8e9d-4ac9-b9c5-b8510bf8c064 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a62964b7-8e9d-4ac9-b9c5-b8510bf8c064');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dbfe0734-4094-48d0-b246-30221f6b322a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dbfe0734-4094-48d0-b246-30221f6b322a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dbfe0734-4094-48d0-b246-30221f6b322a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nCell 3: image_df preparation complete\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"person_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"1004\",\n          \"1007\",\n          \"1002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"/content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230809.2448.36605.dcm\",\n          \"/content/medgemma_extracted_images/1000/1007/1007_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230824.20355.67485.dcm\",\n          \"/content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_l_1.2.826.0.1.3680043.8.641.1.20230809.2436.96446.dcm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LDL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.751173059264335,\n        \"min\": 59.67454369,\n        \"max\": 133.4850537,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          59.67454369,\n          92.27841214,\n          133.4850537\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDL stats in final image_df: min=10.77327021, max=278.5634775, mean=92.26371915419321\n",
            "\n",
            "Cell 3: image_df preparation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 4: Verify image_df (Adapted from user's Cell 4)\n",
        "# -----------------------------------------------------------------------------\n",
        "if 'image_df' in locals() and isinstance(image_df, pd.DataFrame) and not image_df.empty:\n",
        "    print(f\"\\nContinuing with 'image_df' which has {len(image_df)} records.\")\n",
        "    print(\"Columns in image_df:\", image_df.columns.tolist())\n",
        "    from IPython.display import display # Ensure display is imported\n",
        "    print(\"Sample of image_df:\")\n",
        "    display(image_df.head())\n",
        "\n",
        "    required_cols = ['person_id', 'image_path', 'LDL']\n",
        "    if not all(col in image_df.columns for col in required_cols):\n",
        "        print(f\"ERROR: 'image_df' is missing one or more required columns: {required_cols}. Please re-run Cell 3.\")\n",
        "    elif image_df['LDL'].min() <= 0:\n",
        "        print(f\"ERROR: 'image_df' still contains non-positive LDL values. LDL min: {image_df['LDL'].min()}. Please re-run filtering in Cell 3.\")\n",
        "    else:\n",
        "        print(\"'image_df' seems okay to proceed.\")\n",
        "else:\n",
        "    print(\"ERROR: 'image_df' not found or is empty. Please ensure Cell 3 (data preparation) has been run successfully.\")\n",
        "    # To prevent later errors, create an empty df if it's missing, though this indicates a problem.\n",
        "    if 'image_df' not in locals() or not isinstance(image_df, pd.DataFrame):\n",
        "        image_df = pd.DataFrame(columns=['person_id', 'image_path', 'LDL'])\n",
        "\n",
        "\n",
        "print(f\"\\nUsing Unsloth loaded model: {selected_model_name}\") # From Cell 0.3\n",
        "print(\"\\nCell 4: image_df verification and Model ID check complete.\")"
      ],
      "metadata": {
        "id": "jKystT4Bt0Yq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "2098dba1-fbb8-42d0-9a23-ffccfdfe4ec8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Continuing with 'image_df' which has 973 records.\n",
            "Columns in image_df: ['person_id', 'image_path', 'LDL']\n",
            "Sample of image_df:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  person_id                                         image_path         LDL\n",
              "0      1002  /content/medgemma_extracted_images/1000/1002/1...  133.485054\n",
              "1      1004  /content/medgemma_extracted_images/1000/1004/1...   59.674544\n",
              "2      1004  /content/medgemma_extracted_images/1000/1004/1...   59.674544\n",
              "3      1005  /content/medgemma_extracted_images/1000/1005/1...   74.956702\n",
              "4      1007  /content/medgemma_extracted_images/1000/1007/1...   92.278412"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c923f4c-8303-4832-bdbf-1ce549dc804e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>person_id</th>\n",
              "      <th>image_path</th>\n",
              "      <th>LDL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1002</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1002/1...</td>\n",
              "      <td>133.485054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1004</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1004/1...</td>\n",
              "      <td>59.674544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1004</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1004/1...</td>\n",
              "      <td>59.674544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1005</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1005/1...</td>\n",
              "      <td>74.956702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1007</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1007/1...</td>\n",
              "      <td>92.278412</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c923f4c-8303-4832-bdbf-1ce549dc804e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2c923f4c-8303-4832-bdbf-1ce549dc804e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2c923f4c-8303-4832-bdbf-1ce549dc804e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a84008aa-6af4-479c-bf94-d874892fee5e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a84008aa-6af4-479c-bf94-d874892fee5e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a84008aa-6af4-479c-bf94-d874892fee5e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nCell 4: image_df verification and Model ID check complete\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"person_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"1004\",\n          \"1007\",\n          \"1002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"/content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230809.2448.36605.dcm\",\n          \"/content/medgemma_extracted_images/1000/1007/1007_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230824.20355.67485.dcm\",\n          \"/content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_l_1.2.826.0.1.3680043.8.641.1.20230809.2436.96446.dcm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LDL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.751173059264335,\n        \"min\": 59.67454369,\n        \"max\": 133.4850537,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          59.67454369,\n          92.27841214,\n          133.4850537\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'image_df' seems okay to proceed.\n",
            "\n",
            "Using Unsloth loaded model: google/medgemma-4b-pt\n",
            "\n",
            "Cell 4: image_df verification and Model ID check complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 5: Unsloth Tokenizer/Processor Info (Adapted from user's Cell 5)\n",
        "# -----------------------------------------------------------------------------\n",
        "# The `medgemma_processor` is now replaced by the `tokenizer` from Unsloth.\n",
        "# For vision models, this tokenizer might wrap an image processor,\n",
        "# or `model.processor` might be set by Unsloth.\n",
        "\n",
        "# This cell's original purpose was to find TARGET_SIZE_MEDGEMMA.\n",
        "# For MedGemma, the image processor (part of the 'tokenizer' object) handles resizing.\n",
        "# We can inspect the image_processor's configuration.\n",
        "\n",
        "print(\"\\n--- Inspecting MedGemma Image Processor ---\")\n",
        "TARGET_SIZE_FOR_IMAGES = None # Will be determined by the image_processor\n",
        "\n",
        "if 'tokenizer' in locals() and hasattr(tokenizer, 'image_processor') and tokenizer.image_processor is not None:\n",
        "    medgemma_image_processor = tokenizer.image_processor\n",
        "    print(f\"MedGemma Image Processor Type: {type(medgemma_image_processor)}\")\n",
        "\n",
        "    # The image processor config usually has 'size' information.\n",
        "    # For SigLIPImageProcessor (used by MedGemma), it's often under `size` directly.\n",
        "    # The 'size' attribute can be an int (for shortest_edge) or a dict {'height': H, 'width': W}.\n",
        "    if hasattr(medgemma_image_processor, 'size'):\n",
        "        size_info = medgemma_image_processor.size\n",
        "        print(f\"  Image processor 'size' attribute: {size_info}\")\n",
        "        if isinstance(size_info, int): # e.g., size=224 means shortest edge is 224\n",
        "            # MedGemma models often use square inputs, e.g., 224x224 for SigLIP-B, 384x384 for SigLIP-L\n",
        "            # The MedGemma paper mentions images are resized to 896×896 for their experiments.\n",
        "            # However, the underlying SigLIP processor might have its own default.\n",
        "            # Let's check if 'crop_size' is also available, which is often the final input size.\n",
        "            if hasattr(medgemma_image_processor, 'crop_size') and medgemma_image_processor.crop_size is not None:\n",
        "                crop_info = medgemma_image_processor.crop_size\n",
        "                if isinstance(crop_info, int):\n",
        "                    TARGET_SIZE_FOR_IMAGES = (crop_info, crop_info)\n",
        "                elif isinstance(crop_info, dict) and 'height' in crop_info and 'width' in crop_info:\n",
        "                    TARGET_SIZE_FOR_IMAGES = (crop_info['height'], crop_info['width'])\n",
        "                print(f\"  Using 'crop_size' for TARGET_SIZE_FOR_IMAGES: {TARGET_SIZE_FOR_IMAGES}\")\n",
        "\n",
        "            if TARGET_SIZE_FOR_IMAGES is None: # If crop_size wasn't definitive\n",
        "                 # If size is int, assume square image based on that size for processing.\n",
        "                 # The processor itself will handle the exact resizing logic.\n",
        "                 # We use this for our basic transforms if the processor fails.\n",
        "                 TARGET_SIZE_FOR_IMAGES = (size_info, size_info)\n",
        "                 print(f\"  Using 'size' attribute for TARGET_SIZE_FOR_IMAGES (assuming square): {TARGET_SIZE_FOR_IMAGES}\")\n",
        "\n",
        "        elif isinstance(size_info, dict) and 'height' in size_info and 'width' in size_info:\n",
        "            TARGET_SIZE_FOR_IMAGES = (size_info['height'], size_info['width'])\n",
        "            print(f\"  Using 'size' dict for TARGET_SIZE_FOR_IMAGES: {TARGET_SIZE_FOR_IMAGES}\")\n",
        "        else:\n",
        "            print(\"  Could not determine target size from image_processor.size. Check processor config.\")\n",
        "    else:\n",
        "        print(\"  Image processor does not have a direct 'size' attribute. Check its config details.\")\n",
        "\n",
        "    # Fallback if still not found, to MedGemma paper's mentioned size\n",
        "    if TARGET_SIZE_FOR_IMAGES is None:\n",
        "        TARGET_SIZE_FOR_IMAGES = (896, 896) # Default from MedGemma paper if not found in processor\n",
        "        print(f\"  Falling back to default TARGET_SIZE_FOR_IMAGES: {TARGET_SIZE_FOR_IMAGES} (from MedGemma paper)\")\n",
        "else:\n",
        "    print(\"ERROR: MedGemma image_processor not found in tokenizer. Cannot determine target image size.\")\n",
        "    TARGET_SIZE_FOR_IMAGES = (896, 896) # Fallback\n",
        "    print(f\"  Using fallback TARGET_SIZE_FOR_IMAGES: {TARGET_SIZE_FOR_IMAGES}\")\n",
        "\n",
        "print(f\"Final TARGET_SIZE_FOR_IMAGES to be used by Dataset (if processor fails or for reference): {TARGET_SIZE_FOR_IMAGES}\")\n",
        "print(\"\\nCell 5: MedGemma image processor check complete.\")"
      ],
      "metadata": {
        "id": "KOsK3Cd4t4G5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "756a8c05-6a15-4d0f-e4a8-5bf8ddc1c2a5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Inspecting MedGemma Image Processor ---\n",
            "MedGemma Image Processor Type: <class 'transformers.models.gemma3.image_processing_gemma3.Gemma3ImageProcessor'>\n",
            "  Image processor 'size' attribute: {'height': 896, 'width': 896}\n",
            "  Using 'size' dict for TARGET_SIZE_FOR_IMAGES: (896, 896)\n",
            "Final TARGET_SIZE_FOR_IMAGES to be used by Dataset (if processor fails or for reference): (896, 896)\n",
            "\n",
            "Cell 5: MedGemma image processor check complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 6: Data Splitting (Patient-Level) and LDL Normalization (From user's Cell 6)\n",
        "# -----------------------------------------------------------------------------\n",
        "train_df, val_df, test_df = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
        "ldl_scaler = None # Will store the fitted StandardScaler\n",
        "\n",
        "if 'image_df' in locals() and not image_df.empty:\n",
        "    print(f\"\\nStarting data splitting for {len(image_df)} image-LDL pairs...\")\n",
        "    if 'person_id' not in image_df.columns:\n",
        "        print(\"ERROR: 'person_id' column missing in image_df. Cannot perform patient-level split. Please check image_df preparation in Cell 3.\")\n",
        "    else:\n",
        "        unique_person_ids = image_df['person_id'].unique()\n",
        "        print(f\"Total unique patients for splitting: {len(unique_person_ids)}\")\n",
        "\n",
        "        if len(unique_person_ids) < 3: # Need at least 3 patients for train/val/test\n",
        "            print(\"Warning: Not enough unique patients for a robust 3-way (train/validation/test) split.\")\n",
        "            # Simplified split logic for few patients\n",
        "            if len(unique_person_ids) == 2:\n",
        "                train_pids, val_pids = train_test_split(unique_person_ids, test_size=0.5, random_state=RANDOM_SEED)\n",
        "                test_pids = np.array([]) # Empty array for consistency\n",
        "            elif len(unique_person_ids) == 1:\n",
        "                train_pids = unique_person_ids\n",
        "                val_pids, test_pids = np.array([]), np.array([])\n",
        "            else: # 0 patients\n",
        "                train_pids, val_pids, test_pids = np.array([]), np.array([]), np.array([])\n",
        "        else:\n",
        "            # Standard 70% train, 15% validation, 15% test split of person_ids\n",
        "            train_pids, temp_pids = train_test_split(\n",
        "                unique_person_ids, test_size=0.30, random_state=RANDOM_SEED # 70% train, 30% temp\n",
        "            )\n",
        "            if len(temp_pids) > 1 : # Ensure there's at least 2 for val/test split\n",
        "                 val_pids, test_pids = train_test_split(\n",
        "                    temp_pids, test_size=0.50, random_state=RANDOM_SEED # Split temp 50/50 for val/test (15% each of total)\n",
        "                )\n",
        "            elif len(temp_pids) == 1: # Only one patient left for temp\n",
        "                val_pids = temp_pids # Assign to validation\n",
        "                test_pids = np.array([])\n",
        "            else: # No patients left for temp\n",
        "                val_pids, test_pids = np.array([]), np.array([])\n",
        "\n",
        "\n",
        "        train_df = image_df[image_df['person_id'].isin(train_pids)].copy()\n",
        "        val_df = image_df[image_df['person_id'].isin(val_pids)].copy()\n",
        "        test_df = image_df[image_df['person_id'].isin(test_pids)].copy()\n",
        "\n",
        "        print(f\"Train set: {len(train_df)} samples from {len(train_pids)} patients.\")\n",
        "        print(f\"Validation set: {len(val_df)} samples from {len(val_pids)} patients.\")\n",
        "        print(f\"Test set: {len(test_df)} samples from {len(test_pids)} patients.\")\n",
        "\n",
        "        # Sanity check for patient overlap\n",
        "        if len(train_pids)>0 and len(val_pids)>0: assert len(set(train_pids) & set(val_pids)) == 0, \"Patient overlap train/val!\"\n",
        "        if len(train_pids)>0 and len(test_pids)>0: assert len(set(train_pids) & set(test_pids)) == 0, \"Patient overlap train/test!\"\n",
        "        if len(val_pids)>0 and len(test_pids)>0: assert len(set(val_pids) & set(test_pids)) == 0, \"Patient overlap val/test!\"\n",
        "        print(\"Patient-level splits verified (no overlap if sets are non-empty).\")\n",
        "\n",
        "        # --- LDL Value Normalization ---\n",
        "        if not train_df.empty and 'LDL' in train_df.columns:\n",
        "            print(\"\\nNormalizing LDL values using StandardScaler...\")\n",
        "            ldl_scaler = StandardScaler()\n",
        "            # Fit the scaler ONLY on the training data's LDL values\n",
        "            train_df['LDL_scaled'] = ldl_scaler.fit_transform(train_df[['LDL']])\n",
        "\n",
        "            # Transform validation and test data using the FITTED scaler\n",
        "            if not val_df.empty:\n",
        "                val_df['LDL_scaled'] = ldl_scaler.transform(val_df[['LDL']])\n",
        "            else: # Add LDL_scaled column even if empty, for consistency\n",
        "                val_df['LDL_scaled'] = pd.Series(dtype='float64')\n",
        "\n",
        "            if not test_df.empty:\n",
        "                test_df['LDL_scaled'] = ldl_scaler.transform(test_df[['LDL']])\n",
        "            else:\n",
        "                test_df['LDL_scaled'] = pd.Series(dtype='float64')\n",
        "\n",
        "            print(\"LDL normalization complete.\")\n",
        "            print(\"Scaled LDL stats in train_df (should be mean~0, std~1):\")\n",
        "            from IPython.display import display # Ensure display is imported\n",
        "            display(train_df['LDL_scaled'].describe())\n",
        "\n",
        "            # Optional: Save the scaler\n",
        "            # import joblib\n",
        "            # scaler_filename = 'ldl_scaler_medgemma.joblib'\n",
        "            # joblib.dump(ldl_scaler, scaler_filename)\n",
        "            # print(f\"LDL scaler saved to {scaler_filename}\")\n",
        "        else:\n",
        "            print(\"Train DataFrame is empty or 'LDL' column missing. Skipping LDL normalization.\")\n",
        "else:\n",
        "    print(\"image_df is empty (from Cell 3). Skipping data splitting and LDL normalization.\")\n",
        "\n",
        "print(\"\\nCell 6: Data splitting and LDL normalization attempt complete.\")"
      ],
      "metadata": {
        "id": "WkxW5lpBt-7y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "1f2b757d-3eed-49bd-e30e-4aee2c2e60c2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting data splitting for 973 image-LDL pairs...\n",
            "Total unique patients for splitting: 527\n",
            "Train set: 681 samples from 368 patients.\n",
            "Validation set: 145 samples from 79 patients.\n",
            "Test set: 147 samples from 80 patients.\n",
            "Patient-level splits verified (no overlap if sets are non-empty).\n",
            "\n",
            "Normalizing LDL values using StandardScaler...\n",
            "LDL normalization complete.\n",
            "Scaled LDL stats in train_df (should be mean~0, std~1):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "count    6.810000e+02\n",
              "mean     2.086763e-16\n",
              "std      1.000735e+00\n",
              "min     -2.303724e+00\n",
              "25%     -7.148712e-01\n",
              "50%     -4.975462e-02\n",
              "75%      6.670533e-01\n",
              "max      2.756859e+00\n",
              "Name: LDL_scaled, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LDL_scaled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6.810000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.086763e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000735e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-2.303724e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-7.148712e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-4.975462e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.670533e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.756859e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cell 6: Data splitting and LDL normalization attempt complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 5.1 (from user, now Cell 6.1): Check Unsloth tokenizer/model.processor\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n--- Sanity Check for Unsloth Components (Cell 6.1) ---\")\n",
        "if 'tokenizer' in locals() and tokenizer is not None:\n",
        "    print(f\"Unsloth tokenizer IS LOADED. Type: {type(tokenizer)}\")\n",
        "    if hasattr(tokenizer, 'image_processor') and tokenizer.image_processor is not None:\n",
        "        print(f\"  It has a tokenizer.image_processor of type: {type(tokenizer.image_processor)}\")\n",
        "    else:\n",
        "        print(\"  It does NOT have a direct `tokenizer.image_processor` attribute (or it's None).\")\n",
        "\n",
        "    if hasattr(model, 'processor') and model.processor is not None:\n",
        "        print(f\"Unsloth model.processor IS LOADED. Type: {type(model.processor)}\")\n",
        "        if hasattr(model.processor, 'image_processor') and model.processor.image_processor is not None:\n",
        "             print(f\"  model.processor has an image_processor component of type: {type(model.processor.image_processor)}\")\n",
        "    else:\n",
        "        print(\"  The model does NOT have a `model.processor` attribute (or it's None).\")\n",
        "\n",
        "    if not (hasattr(tokenizer, 'image_processor') and tokenizer.image_processor is not None) and \\\n",
        "       not (hasattr(model, 'processor') and model.processor is not None and hasattr(model.processor, 'image_processor')):\n",
        "        print(f\"  WARNING: No obvious image processor found. The model '{selected_model_name}' may be text-only.\")\n",
        "        print(\"  If your task requires image input, ensure you've selected a vision-language model and that Unsloth loads its image processor correctly.\")\n",
        "else:\n",
        "    print(\"Unsloth tokenizer IS NOT LOADED or is None.\")"
      ],
      "metadata": {
        "id": "ExnNlqz_uEpb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ede21bd-6c69-492f-d696-d109e052c70b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Sanity Check for Unsloth Components (Cell 6.1) ---\n",
            "Unsloth tokenizer IS LOADED. Type: <class 'transformers.models.gemma3.processing_gemma3.Gemma3Processor'>\n",
            "  It has a tokenizer.image_processor of type: <class 'transformers.models.gemma3.image_processing_gemma3.Gemma3ImageProcessor'>\n",
            "  The model does NOT have a `model.processor` attribute (or it's None).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c19e4e06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "516cb93a-fb84-421e-b20a-b663306d095a"
      },
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 7: Custom PyTorch Dataset for DICOM Images and LDL (New Cell)\n",
        "# -----------------------------------------------------------------------------\n",
        "# Helper for printing messages only once during dataset iteration or training\n",
        "printed_messages_dataset = set()\n",
        "def print_once_dataset(message):\n",
        "    global printed_messages_dataset\n",
        "    if message not in printed_messages_dataset:\n",
        "        print(message)\n",
        "        printed_messages_dataset.add(message)\n",
        "\n",
        "import torchvision.transforms as T # Import T for transforms\n",
        "\n",
        "class MedGemmaVisionDataset(Dataset):\n",
        "    def __init__(self, dataframe, medgemma_tokenizer_processor, target_img_size_ref=(896, 896)):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dataframe (pd.DataFrame): DataFrame with 'image_path' and 'LDL_scaled' columns.\n",
        "            medgemma_tokenizer_processor: The multimodal processor from Unsloth (contains image_processor).\n",
        "            target_img_size_ref (tuple): Reference target image size, primarily for fallback.\n",
        "                                         The image_processor itself determines the actual processing.\n",
        "        \"\"\"\n",
        "        self.dataframe = dataframe\n",
        "        self.processor = medgemma_tokenizer_processor # This is the GemmaProcessor (or similar)\n",
        "        self.target_size_ref = target_img_size_ref # For fallback basic transforms\n",
        "\n",
        "        if not hasattr(self.processor, 'image_processor') or self.processor.image_processor is None:\n",
        "            raise ValueError(\"The provided processor must have a valid 'image_processor' attribute for MedGemma.\")\n",
        "\n",
        "        # Basic image transforms (fallback if image_processor fails for an image)\n",
        "        self.basic_transforms = T.Compose([\n",
        "            T.Resize(self.target_size_ref),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Imagenet stats\n",
        "        ])\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def load_and_preprocess_dicom(self, dicom_path):\n",
        "        try:\n",
        "            dicom_file = pydicom.dcmread(dicom_path)\n",
        "            pixel_array = dicom_file.pixel_array\n",
        "\n",
        "            # Normalize pixel data to 0-255 and ensure 3 channels (RGB)\n",
        "            # This is a common pre-step before PIL conversion for many image processors\n",
        "            if pixel_array.dtype != np.uint8:\n",
        "                pixel_array = pixel_array.astype(np.float32)\n",
        "                min_val, max_val = np.min(pixel_array), np.max(pixel_array)\n",
        "                if max_val > min_val:\n",
        "                    pixel_array = (pixel_array - min_val) / (max_val - min_val) * 255.0\n",
        "                else: # Handle case where all pixels are the same\n",
        "                    pixel_array = np.zeros_like(pixel_array)\n",
        "                pixel_array = pixel_array.astype(np.uint8)\n",
        "\n",
        "            if pixel_array.ndim == 2: # Grayscale\n",
        "                pil_image = Image.fromarray(pixel_array).convert('RGB')\n",
        "            elif pixel_array.ndim == 3 and pixel_array.shape[-1] == 1: # Grayscale with channel dim\n",
        "                pil_image = Image.fromarray(pixel_array.squeeze(-1)).convert('RGB')\n",
        "            elif pixel_array.ndim == 3 and pixel_array.shape[-1] == 3: # RGB\n",
        "                pil_image = Image.fromarray(pixel_array)\n",
        "            elif pixel_array.ndim == 3 and pixel_array.shape[-1] == 4: # RGBA\n",
        "                pil_image = Image.fromarray(pixel_array).convert('RGB')\n",
        "            else:\n",
        "                print_once_dataset(f\"Warning: Unsupported DICOM pixel array shape {pixel_array.shape} for {dicom_path}. Trying to convert.\")\n",
        "                # Attempt to make it a 2D grayscale image if possible\n",
        "                if pixel_array.ndim > 2 : pixel_array = pixel_array[...,0] # take first channel or slice\n",
        "                if pixel_array.ndim > 2 : pixel_array = pixel_array[0] # take first frame\n",
        "                pil_image = Image.fromarray(pixel_array.astype(np.uint8)).convert('RGB')\n",
        "\n",
        "\n",
        "            # Use MedGemma's image_processor\n",
        "            # It expects a PIL Image or list of PIL Images.\n",
        "            # It handles resizing, normalization, and tensor conversion according to MedGemma's needs.\n",
        "            processed_output = self.processor.image_processor(images=pil_image, return_tensors=\"pt\")\n",
        "            pixel_values = processed_output.pixel_values.squeeze(0) # Remove batch dim\n",
        "            return pixel_values\n",
        "\n",
        "        except Exception as e:\n",
        "            print_once_dataset(f\"Error processing DICOM {dicom_path} with image_processor: {e}. Applying basic fallback.\")\n",
        "            # Fallback: create a dummy black image if processing fails\n",
        "            try:\n",
        "                # Try to load with PIL directly for basic transform\n",
        "                pil_image_fallback = Image.open(dicom_path).convert(\"RGB\") # This might fail for some DICOMs\n",
        "                return self.basic_transforms(pil_image_fallback)\n",
        "            except Exception as e_fallback:\n",
        "                print_once_dataset(f\"Fallback PIL loading also failed for {dicom_path}: {e_fallback}. Returning zero tensor.\")\n",
        "                return torch.zeros((3, self.target_size_ref[0], self.target_size_ref[1]))\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        image_path = row['image_path']\n",
        "        ldl_scaled = row['LDL_scaled'] # Target variable\n",
        "\n",
        "        pixel_values = self.load_and_preprocess_dicom(image_path)\n",
        "        target_ldl_scaled = torch.tensor(ldl_scaled, dtype=torch.float32)\n",
        "\n",
        "        return {\n",
        "            \"pixel_values\": pixel_values,\n",
        "            \"labels\": target_ldl_scaled.unsqueeze(0) # Ensure target is (1,) for MSELoss\n",
        "        }\n",
        "\n",
        "# --- Create Datasets ---\n",
        "# `tokenizer` from Cell 0.3 is MedGemma's processor\n",
        "# `TARGET_SIZE_FOR_IMAGES` from Cell 5 is a reference\n",
        "if 'train_df' in locals() and not train_df.empty and 'tokenizer' in locals() and tokenizer is not None:\n",
        "    train_dataset = MedGemmaVisionDataset(train_df, tokenizer, TARGET_SIZE_FOR_IMAGES)\n",
        "    print(f\"Train dataset created with {len(train_dataset)} samples.\")\n",
        "else:\n",
        "    train_dataset = None\n",
        "    print(\"Could not create train_dataset. Check train_df and tokenizer.\")\n",
        "\n",
        "if 'val_df' in locals() and not val_df.empty and 'tokenizer' in locals() and tokenizer is not None:\n",
        "    val_dataset = MedGemmaVisionDataset(val_df, tokenizer, TARGET_SIZE_FOR_IMAGES)\n",
        "    print(f\"Validation dataset created with {len(val_dataset)} samples.\")\n",
        "else:\n",
        "    val_dataset = None\n",
        "    print(\"Could not create val_dataset. Check val_df and tokenizer.\")\n",
        "\n",
        "# Example: Fetch one item to test\n",
        "if train_dataset:\n",
        "    print(\"\\nSample from train_dataset:\")\n",
        "    try:\n",
        "        sample = train_dataset[0]\n",
        "        for key, val in sample.items():\n",
        "            print(f\"  {key}: shape {val.shape}, dtype {val.dtype}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching sample from train_dataset: {e}\")\n",
        "        print(\"This might indicate issues with DICOM loading or processing in your dataset.\")\n",
        "\n",
        "print(\"\\nCell 7: MedGemmaVisionDataset class defined and datasets instantiated.\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset created with 681 samples.\n",
            "Validation dataset created with 145 samples.\n",
            "\n",
            "Sample from train_dataset:\n",
            "  pixel_values: shape torch.Size([3, 896, 896]), dtype torch.float32\n",
            "  labels: shape torch.Size([1]), dtype torch.float32\n",
            "\n",
            "Cell 7: MedGemmaVisionDataset class defined and datasets instantiated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard PyTorch collate_fn should work if items are already tensors.\n",
        "def vision_collate_fn(batch):\n",
        "    pixel_values = torch.stack([item['pixel_values'] for item in batch])\n",
        "    labels = torch.stack([item['labels'] for item in batch])\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
        "\n",
        "BATCH_SIZE = 8 # Adjust based on GPU memory (e.g., 4, 8, 16)\n",
        "\n",
        "if train_dataset:\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        collate_fn=vision_collate_fn, # Use custom collate\n",
        "        num_workers=2, # Use multiple workers for faster data loading if not on Windows/debugging\n",
        "        pin_memory=True if torch.cuda.is_available() else False\n",
        "    )\n",
        "    print(f\"\\nTrain DataLoader created. Batches per epoch: {len(train_loader)}\")\n",
        "else:\n",
        "    train_loader = None\n",
        "\n",
        "if val_dataset:\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False, # No need to shuffle validation data\n",
        "        collate_fn=vision_collate_fn,\n",
        "        num_workers=2,\n",
        "        pin_memory=True if torch.cuda.is_available() else False\n",
        "    )\n",
        "    print(f\"Validation DataLoader created. Batches per epoch: {len(val_loader)}\")\n",
        "else:\n",
        "    val_loader = None\n",
        "\n",
        "# Test one batch from train_loader\n",
        "if train_loader:\n",
        "    print(\"\\nSample batch from train_loader:\")\n",
        "    try:\n",
        "        batch_sample = next(iter(train_loader))\n",
        "        for key, val in batch_sample.items():\n",
        "            print(f\"  {key}: shape {val.shape}, dtype {val.dtype}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching batch from train_loader: {e}\")\n",
        "\n",
        "print(\"\\nCell 8: DataLoaders created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05QUEpMHHP8M",
        "outputId": "91cca3cb-9592-4f3c-e1f8-b538036ada1b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train DataLoader created. Batches per epoch: 86\n",
            "Validation DataLoader created. Batches per epoch: 19\n",
            "\n",
            "Sample batch from train_loader:\n",
            "  pixel_values: shape torch.Size([8, 3, 896, 896]), dtype torch.float32\n",
            "  labels: shape torch.Size([8, 1]), dtype torch.float32\n",
            "\n",
            "Cell 8: DataLoaders created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard PyTorch collate_fn should work if items are already tensors.\n",
        "# Cell 9: Training Setup (Optimizer, Loss, Learning Rate) - MODIFIED\n",
        "\"\"\"\n",
        "import torch.optim as optim\n",
        "\n",
        "LEARNING_RATE = 5e-5 # Common starting point for LoRA fine-tuning. May need adjustment.\n",
        "EPOCHS = 10 # Start with a moderate number, e.g., 5-20.\n",
        "WEIGHT_DECAY = 0.01\n",
        "\n",
        "if regressor_model is not None: # Ensure the model was created in Cell 0.5\n",
        "    optimizer = optim.AdamW(regressor_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # --- STRATEGY 1: Attempt to cast the entire regressor_model to bfloat16 ---\n",
        "    # This assumes `regressor_model` is already on the correct `device` (e.g., 'cuda')\n",
        "    # And `model_dtype` (e.g. torch.bfloat16) should be what Unsloth set for the base model.\n",
        "\n",
        "    # Get the dtype from the Unsloth-loaded base model component within regressor_model\n",
        "    # This is the most reliable source for the target dtype.\n",
        "    if hasattr(regressor_model, 'medgemma_model') and hasattr(regressor_model.medgemma_model, 'dtype'):\n",
        "        target_model_dtype = regressor_model.medgemma_model.dtype\n",
        "        print(f\"\\nTarget dtype for model components (from base Unsloth model): {target_model_dtype}\")\n",
        "\n",
        "        if target_model_dtype == torch.bfloat16:\n",
        "            print(f\"Attempting to cast entire regressor_model and its submodules to {target_model_dtype} (Strategy 1)...\")\n",
        "            try:\n",
        "                # This will attempt to cast all parameters and buffers.\n",
        "                regressor_model = regressor_model.to(dtype=target_model_dtype)\n",
        "                print(\"Casting of entire regressor_model to bfloat16 attempted.\")\n",
        "\n",
        "                # Optional: Verification - Check dtypes of some parameters\n",
        "                # print(\"Verifying some parameter dtypes after full model cast:\")\n",
        "                # for name, param in regressor_model.named_parameters():\n",
        "                #     if \"lora\" in name.lower() or \"regression_head\" in name.lower() or \"bias\" in name.lower(): # Check some key ones\n",
        "                #         if param.numel() > 0: # Only print if param is not empty\n",
        "                #             print(f\"  Param: {name[:60]}..., Dtype: {param.dtype}, Device: {param.device}\")\n",
        "                #         break # Just check a few to avoid too much output\n",
        "            except Exception as e_cast_full:\n",
        "                print(f\"ERROR during full regressor_model.to(dtype={target_model_dtype}): {e_cast_full}\")\n",
        "                print(\"Full model cast failed. Proceeding without it, relying on input tensor casting in training loop.\")\n",
        "        else:\n",
        "            print(f\"Base model dtype is {target_model_dtype}, not bfloat16. Skipping full model bfloat16 cast strategy.\")\n",
        "    else:\n",
        "        print(\"\\nCould not reliably determine target_model_dtype from regressor_model.medgemma_model.dtype.\")\n",
        "        print(\"Skipping full model cast strategy. Will rely on input tensor casting in training loop.\")\n",
        "    # --- END OF STRATEGY 1 ---\n",
        "\n",
        "    print(f\"\\nOptimizer: AdamW, LR: {LEARNING_RATE}, Weight Decay: {WEIGHT_DECAY}\")\n",
        "    print(f\"Loss Function: MSELoss\")\n",
        "    print(f\"Training for {EPOCHS} epochs.\")\n",
        "else:\n",
        "    print(\"CRITICAL ERROR: regressor_model is None (was not created in Cell 0.5). Cannot set up optimizer and loss.\")\n",
        "    optimizer = None\n",
        "    criterion = None\n",
        "\"\"\"\n",
        "# Cell 9: Training Setup (Optimizer, Loss, Learning Rate) - REVISED\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "LEARNING_RATE = 5e-5\n",
        "EPOCHS = 10\n",
        "WEIGHT_DECAY = 0.01\n",
        "\n",
        "if regressor_model is not None:\n",
        "    optimizer = optim.AdamW(regressor_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # --- Attempt to ensure all components of regressor_model are bfloat16 ---\n",
        "    # The regressor_model should already be on the correct device from Cell 0.5\n",
        "\n",
        "    # Get the target dtype from the base Unsloth model component\n",
        "    if hasattr(regressor_model, 'medgemma_model') and hasattr(regressor_model.medgemma_model, 'dtype'):\n",
        "        target_dtype_for_components = regressor_model.medgemma_model.dtype\n",
        "        print(f\"\\nTarget dtype for all model components: {target_dtype_for_components}\")\n",
        "\n",
        "        if target_dtype_for_components == torch.bfloat16:\n",
        "            print(f\"Attempting to ensure all components of regressor_model are on {target_dtype_for_components}...\")\n",
        "            try:\n",
        "                # This should cast all parameters and buffers of regressor_model,\n",
        "                # including the PEFT-adapted medgemma_model and the regression_head.\n",
        "                regressor_model = regressor_model.to(dtype=target_dtype_for_components)\n",
        "                print(\"Casting of entire regressor_model to bfloat16 completed.\")\n",
        "\n",
        "                # Verification: Check dtypes of LoRA layers and regression head\n",
        "                print(\"Verifying select parameter dtypes after full model cast:\")\n",
        "                for name, param in regressor_model.named_parameters():\n",
        "                    # Check LoRA weights (often contain 'lora_A' or 'lora_B')\n",
        "                    # and regression head weights\n",
        "                    if param.requires_grad and (\"lora\" in name.lower() or \"regression_head\" in name.lower()):\n",
        "                        if param.numel() > 0:\n",
        "                             print(f\"  Trainable Param: {name[:70]}..., Dtype: {param.dtype}, Device: {param.device}\")\n",
        "            except Exception as e_cast_all:\n",
        "                print(f\"ERROR during full regressor_model.to(dtype={target_dtype_for_components}): {e_cast_all}\")\n",
        "                print(\"Full model component casting failed. This might be the source of dtype mismatches.\")\n",
        "        else:\n",
        "            print(f\"Base model dtype is {target_dtype_for_components}, not bfloat16. Not forcing bfloat16 on all components.\")\n",
        "    else:\n",
        "        print(\"\\nCould not reliably determine target_dtype from regressor_model.medgemma_model.dtype for component casting.\")\n",
        "    # --- END OF COMPONENT CASTING ---\n",
        "\n",
        "    print(f\"\\nOptimizer: AdamW, LR: {LEARNING_RATE}, Weight Decay: {WEIGHT_DECAY}\")\n",
        "    print(f\"Loss Function: MSELoss\")\n",
        "    print(f\"Training for {EPOCHS} epochs.\")\n",
        "else:\n",
        "    print(\"CRITICAL ERROR: regressor_model is None. Cannot set up optimizer and loss.\")\n",
        "    optimizer = None\n",
        "    criterion = None"
      ],
      "metadata": {
        "id": "cSq1JoFRvFZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "467a367c-ee32-45c7-ffcd-d18989f6a54d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Target dtype for all model components: torch.bfloat16\n",
            "Attempting to ensure all components of regressor_model are on torch.bfloat16...\n",
            "Casting of entire regressor_model to bfloat16 completed.\n",
            "Verifying select parameter dtypes after full model cast:\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: regression_head.0.weight..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: regression_head.0.bias..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: regression_head.3.weight..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: regression_head.3.bias..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "\n",
            "Optimizer: AdamW, LR: 5e-05, Weight Decay: 0.01\n",
            "Loss Function: MSELoss\n",
            "Training for 10 epochs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Training and Evaluation Loop - MODIFIED\n",
        "\n",
        "# Cell 10: Training and Evaluation Loop - MODIFIED\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "PATIENCE_EPOCHS = 3 # For early stopping if validation loss doesn't improve\n",
        "\n",
        "# Helper for printing messages only once during training loop\n",
        "printed_messages_train_loop = set() # Use a different name to avoid conflict if re-running cells\n",
        "def print_once_train_loop(message):\n",
        "    global printed_messages_train_loop\n",
        "    if message not in printed_messages_train_loop:\n",
        "        print(message)\n",
        "        printed_messages_train_loop.add(message)\n",
        "\n",
        "if regressor_model is not None and train_loader is not None and val_loader is not None and optimizer is not None and criterion is not None:\n",
        "    print(f\"\\nStarting training on device: {device}...\") # device was set in Cell 0.5\n",
        "\n",
        "    # Determine the model's expected input dtype (should be bfloat16 if Unsloth set it)\n",
        "    # This comes from the base Unsloth model component\n",
        "    if hasattr(regressor_model, 'medgemma_model') and hasattr(regressor_model.medgemma_model, 'dtype'):\n",
        "        model_input_dtype = regressor_model.medgemma_model.dtype\n",
        "    else:\n",
        "        # Fallback if attribute not found, assume bfloat16 based on previous errors\n",
        "        print_once_train_loop(\"Warning: Could not directly get model_input_dtype from regressor_model.medgemma_model.dtype. Assuming torch.bfloat16.\")\n",
        "        model_input_dtype = torch.bfloat16\n",
        "\n",
        "    print(f\"Model's expected input dtype for pixel_values: {model_input_dtype}\")\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        regressor_model.train()\n",
        "        running_train_loss = 0.0\n",
        "        processed_batches_train = 0\n",
        "\n",
        "        for i, batch in enumerate(train_loader):\n",
        "            # Data from DataLoader is typically float32\n",
        "            pixel_values_f32 = batch['pixel_values'].to(device)\n",
        "            labels_f32 = batch['labels'].to(device) # Labels for MSELoss are typically Float32\n",
        "\n",
        "            # Explicitly cast pixel_values to the model's expected input dtype\n",
        "            pixel_values_casted = pixel_values_f32.to(model_input_dtype)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            try:\n",
        "                # Forward pass with casted input\n",
        "                predictions = regressor_model(pixel_values_casted)\n",
        "\n",
        "                # Predictions will likely be in model_input_dtype (e.g., bfloat16).\n",
        "                # MSELoss can often handle mixed precision (e.g., bfloat16 pred, float32 label).\n",
        "                # If criterion errors on dtype, cast predictions: loss = criterion(predictions.to(torch.float32), labels_f32)\n",
        "                loss = criterion(predictions, labels_f32)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_train_loss += loss.item()\n",
        "                processed_batches_train += 1\n",
        "\n",
        "                if (i + 1) % 20 == 0 or (i + 1) == len(train_loader):\n",
        "                    print(f\"Epoch [{epoch+1}/{EPOCHS}], Batch [{i+1}/{len(train_loader)}], Train Loss: {loss.item():.4f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print_once_train_loop(f\"ERROR during training forward/backward pass at batch {i}: {e}\")\n",
        "                if \"expected scalar type\" in str(e).lower():\n",
        "                    print_once_train_loop(f\"  Input pixel_values_casted dtype: {pixel_values_casted.dtype}\")\n",
        "                    # If predictions object exists before error:\n",
        "                    if 'predictions' in locals() and isinstance(predictions, torch.Tensor):\n",
        "                         print_once_train_loop(f\"  Predictions (if formed) dtype: {predictions.dtype}\")\n",
        "                # To get more details on where exactly the error occurs inside the model:\n",
        "                # import traceback\n",
        "                # print_once_train_loop(traceback.format_exc())\n",
        "                continue # Skip this batch and try the next one\n",
        "\n",
        "        epoch_train_loss = running_train_loss / processed_batches_train if processed_batches_train > 0 else 0.0\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        print(f\"Epoch [{epoch+1}/{EPOCHS}] - Average Training Loss: {epoch_train_loss:.4f}\")\n",
        "\n",
        "        # Validation phase\n",
        "        regressor_model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        processed_batches_val = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_val in val_loader:\n",
        "                pixel_values_f32_val = batch_val['pixel_values'].to(device)\n",
        "                labels_f32_val = batch_val['labels'].to(device)\n",
        "\n",
        "                pixel_values_casted_val = pixel_values_f32_val.to(model_input_dtype)\n",
        "\n",
        "                try:\n",
        "                    predictions_val = regressor_model(pixel_values_casted_val)\n",
        "                    loss_val = criterion(predictions_val, labels_f32_val)\n",
        "                    running_val_loss += loss_val.item()\n",
        "                    processed_batches_val +=1\n",
        "                except Exception as e_val:\n",
        "                    print_once_train_loop(f\"ERROR during validation forward pass: {e_val}\")\n",
        "                    continue\n",
        "\n",
        "        epoch_val_loss = running_val_loss / processed_batches_val if processed_batches_val > 0 else 0.0\n",
        "        val_losses.append(epoch_val_loss)\n",
        "        print(f\"Epoch [{epoch+1}/{EPOCHS}] - Average Validation Loss: {epoch_val_loss:.4f}\")\n",
        "\n",
        "        if epoch_val_loss < best_val_loss:\n",
        "            best_val_loss = epoch_val_loss\n",
        "            patience_counter = 0\n",
        "            save_dir = \"./best_model_checkpoint\"\n",
        "            if not os.path.exists(save_dir): os.makedirs(save_dir)\n",
        "\n",
        "            # Save LoRA adapters from the PEFT-adapted model component\n",
        "            if hasattr(regressor_model, 'medgemma_model') and hasattr(regressor_model.medgemma_model, 'save_pretrained'):\n",
        "                regressor_model.medgemma_model.save_pretrained(os.path.join(save_dir, \"lora_adapters\"))\n",
        "                print(f\"Saved LoRA adapters at epoch {epoch+1}.\")\n",
        "            else:\n",
        "                print_once_train_loop(\"Could not save LoRA adapters: regressor_model.medgemma_model.save_pretrained not found.\")\n",
        "\n",
        "            # Save the state of the regression head\n",
        "            if hasattr(regressor_model, 'regression_head'):\n",
        "                torch.save(regressor_model.regression_head.state_dict(), os.path.join(save_dir, \"regression_head.pth\"))\n",
        "                print(f\"Saved regression head state at epoch {epoch+1}.\")\n",
        "            else:\n",
        "                print_once_train_loop(\"Could not save regression head: regressor_model.regression_head not found.\")\n",
        "            print(f\"Validation loss improved to {best_val_loss:.4f}. Saved best model components.\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        print(\"-\" * 30)\n",
        "        if patience_counter >= PATIENCE_EPOCHS:\n",
        "            print(f\"Early stopping triggered after {PATIENCE_EPOCHS} epochs without improvement on validation loss.\")\n",
        "            break\n",
        "    print(\"Training complete.\")\n",
        "else:\n",
        "    print(\"Cannot start training. One or more critical components (model, dataloaders, optimizer, criterion) are missing.\")\n",
        "\n",
        "# Plotting training and validation loss\n",
        "if train_losses and val_losses:\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss (MSE)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "IvYqs994WWHB",
        "outputId": "ea00249b-8387-4ff7-ea29-be6aa7510374"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training on device: cuda...\n",
            "Model's expected input dtype for pixel_values: torch.bfloat16\n",
            "ERROR during training forward/backward pass at batch 0: self and mat2 must have the same dtype, but got BFloat16 and Half\n",
            "ERROR during training forward/backward pass at batch 1: self and mat2 must have the same dtype, but got BFloat16 and Half\n",
            "ERROR during training forward/backward pass at batch 2: self and mat2 must have the same dtype, but got BFloat16 and Half\n",
            "ERROR during training forward/backward pass at batch 3: self and mat2 must have the same dtype, but got BFloat16 and Half\n",
            "ERROR during training forward/backward pass at batch 4: self and mat2 must have the same dtype, but got BFloat16 and Half\n",
            "ERROR during training forward/backward pass at batch 5: self and mat2 must have the same dtype, but got BFloat16 and Half\n",
            "ERROR during training forward/backward pass at batch 6: self and mat2 must have the same dtype, but got BFloat16 and Half\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-376ff4080508>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprocessed_batches_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;31m# Data from DataLoader is typically float32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mpixel_values_f32\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pixel_values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The best model was saved during training. Here's how you might save the *final* model\n",
        "# if you didn't use early stopping or want the model from the last epoch.\n",
        "\n",
        "final_model_save_path = \"./final_model_checkpoint\"\n",
        "if regressor_model is not None and os.path.exists(\"./best_model_checkpoint\"): # Check if best model was saved\n",
        "    print(f\"\\nBest model was saved during training to ./best_model_checkpoint\")\n",
        "    print(\"To use the best model, load from './best_model_checkpoint/lora_adapters' and './best_model_checkpoint/regression_head.pth'\")\n",
        "elif regressor_model is not None: # Save final model if no best model path exists (e.g. early stopping not triggered or not implemented fully)\n",
        "    if not os.path.exists(final_model_save_path): os.makedirs(final_model_save_path)\n",
        "    print(f\"\\nSaving final model to {final_model_save_path}...\")\n",
        "    # Save LoRA adapters of the base MedGemma model\n",
        "    regressor_model.medgemma_model.save_pretrained(os.path.join(final_model_save_path, \"lora_adapters\"))\n",
        "    # Save the state of the regression head\n",
        "    torch.save(regressor_model.regression_head.state_dict(), os.path.join(final_model_save_path, \"regression_head.pth\"))\n",
        "    print(f\"Final LoRA adapters saved to {os.path.join(final_model_save_path, 'lora_adapters')}\")\n",
        "    print(f\"Final regression head state saved to {os.path.join(final_model_save_path, 'regression_head.pth')}\")\n",
        "else:\n",
        "    print(\"\\nNo model to save or best model already indicated.\")\n",
        "\n",
        "\n",
        "# --- How to load the saved (best or final) model for inference ---\n",
        "# This demonstrates loading the components back.\n",
        "\n",
        "# 1. Define the path to your saved components (e.g., best model)\n",
        "saved_lora_path = \"./best_model_checkpoint/lora_adapters\" # Or final_model_save_path + \"/lora_adapters\"\n",
        "saved_head_path = \"./best_model_checkpoint/regression_head.pth\" # Or final_model_save_path + \"/regression_head.pth\"\n",
        "\n",
        "if os.path.exists(saved_lora_path) and os.path.exists(saved_head_path) and vision_feature_dim is not None:\n",
        "    print(f\"\\n--- Example: Loading saved model components from {saved_lora_path} and {saved_head_path} ---\")\n",
        "    # A. Load the base MedGemma model (without PEFT initially, or it will try to load adapters from original HF name)\n",
        "    #    It's often cleaner to load the base and then apply PEFT adapters.\n",
        "    #    However, Unsloth's `from_pretrained` on a PEFT saved path should work.\n",
        "\n",
        "    print(f\"Loading base MedGemma model ({selected_model_name}) and then applying saved LoRA adapters from {saved_lora_path}...\")\n",
        "\n",
        "    loaded_base_model, loaded_tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name=selected_model_name, # Start with the original base model name\n",
        "        max_seq_length=2048,\n",
        "        dtype=None,\n",
        "        load_in_4bit=True,\n",
        "        # token = \"hf_...\"\n",
        "    )\n",
        "\n",
        "    # Now, apply the saved LoRA adapters\n",
        "    # Important: The `PeftModel.from_pretrained` expects the *base model* and the path to adapters.\n",
        "    from peft import PeftModel\n",
        "    loaded_peft_medgemma_model = PeftModel.from_pretrained(loaded_base_model, saved_lora_path)\n",
        "    print(\"PEFT MedGemma model with saved LoRA adapters loaded.\")\n",
        "\n",
        "    # B. Instantiate your RegressorModel wrapper with the loaded PEFT MedGemma\n",
        "    loaded_regressor_model = MedGemmaVisionRegressor(loaded_peft_medgemma_model, vision_feature_dim)\n",
        "\n",
        "    # C. Load the state_dict for the regression head\n",
        "    loaded_regressor_model.regression_head.load_state_dict(torch.load(saved_head_path, map_location=device))\n",
        "    print(\"Regression head state loaded.\")\n",
        "\n",
        "    loaded_regressor_model.to(device)\n",
        "    loaded_regressor_model.eval() # Set to evaluation mode\n",
        "    print(\"Complete RegressorModel loaded and ready for inference.\")\n",
        "\n",
        "    # Example inference (requires a sample from val_loader or test_loader)\n",
        "    if val_loader:\n",
        "        try:\n",
        "            sample_batch_inference = next(iter(val_loader))\n",
        "            pixel_values_inf = sample_batch_inference['pixel_values'].to(device)\n",
        "            labels_inf = sample_batch_inference['labels'].to(device)\n",
        "            with torch.no_grad():\n",
        "                predictions_inf = loaded_regressor_model(pixel_values_inf)\n",
        "            print(f\"\\nSample inference output shape: {predictions_inf.shape}\")\n",
        "            # You would then unscale predictions using ldl_scaler.inverse_transform()\n",
        "            if ldl_scaler:\n",
        "                 predicted_ldl_original_scale = ldl_scaler.inverse_transform(predictions_inf.cpu().numpy())\n",
        "                 actual_ldl_original_scale = ldl_scaler.inverse_transform(labels_inf.cpu().numpy())\n",
        "                 print(f\"Sample predictions (original scale): {predicted_ldl_original_scale[:5].flatten()}\")\n",
        "                 print(f\"Sample actuals (original scale):    {actual_ldl_original_scale[:5].flatten()}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during sample inference with loaded model: {e}\")\n",
        "else:\n",
        "    print(\"\\nSkipping demonstration of loading model as saved paths or vision_feature_dim not found.\")\n",
        "\n",
        "\n",
        "print(\"\\nCell 11: Model saving and loading example complete.\")\n",
        "print(\"\\n--- End of Script ---\")"
      ],
      "metadata": {
        "id": "VbHPLQdsWa2c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}