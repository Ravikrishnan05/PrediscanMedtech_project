{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b43cdf3a9f184843bce6b65f01b6eb00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fb5a53475f24852b327d77b2ee23cb4",
              "IPY_MODEL_0ed2e2b3b18c4a6ebcebf075870b6add",
              "IPY_MODEL_a3588bd8016c409b9e311d18895e0faa"
            ],
            "layout": "IPY_MODEL_4998291abeb24ca8a9efa3abc8a2617f"
          }
        },
        "3fb5a53475f24852b327d77b2ee23cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7e5a41c2fee4e34a2636d24c0fd3dfc",
            "placeholder": "​",
            "style": "IPY_MODEL_932c4ed977f24e40832dc6f0087b9cd8",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "0ed2e2b3b18c4a6ebcebf075870b6add": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d5e192bc6f14997a9b67c7711fe74d6",
            "max": 90558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb1b3210edba4acbb27d4c933cba367b",
            "value": 90558
          }
        },
        "a3588bd8016c409b9e311d18895e0faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6d3ce901bf2457980679633c1de56a2",
            "placeholder": "​",
            "style": "IPY_MODEL_fb3c77ec275b40e484750ca0b636413a",
            "value": " 90.6k/90.6k [00:00&lt;00:00, 8.43MB/s]"
          }
        },
        "4998291abeb24ca8a9efa3abc8a2617f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7e5a41c2fee4e34a2636d24c0fd3dfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "932c4ed977f24e40832dc6f0087b9cd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d5e192bc6f14997a9b67c7711fe74d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb1b3210edba4acbb27d4c933cba367b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6d3ce901bf2457980679633c1de56a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb3c77ec275b40e484750ca0b636413a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82c384db1a9c4f2389170118ef908709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e46e48133b94cf6a0ea9b2afb6eaf8c",
              "IPY_MODEL_cc9e69e6aef8486da43279a50c12f59d",
              "IPY_MODEL_e952366fb5cf4471bdce14fcde90a086"
            ],
            "layout": "IPY_MODEL_ea3fa6bbe3dd401b882a0edd7ba78902"
          }
        },
        "9e46e48133b94cf6a0ea9b2afb6eaf8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8422ab858f44353acd1e96b3e97a414",
            "placeholder": "​",
            "style": "IPY_MODEL_54f8f9870bfc470187305fe2a09f76c8",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "cc9e69e6aef8486da43279a50c12f59d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_195db63b64c5443c912d5b79a93af9e9",
            "max": 4961251752,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_532cd500f33c476abffbc363d84230a7",
            "value": 4961251279
          }
        },
        "e952366fb5cf4471bdce14fcde90a086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db24a20eb7934f44b2a0502656ebbd1c",
            "placeholder": "​",
            "style": "IPY_MODEL_0cd11222efe44e879ce5cbcf1d244285",
            "value": " 4.96G/4.96G [00:36&lt;00:00, 560MB/s]"
          }
        },
        "ea3fa6bbe3dd401b882a0edd7ba78902": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8422ab858f44353acd1e96b3e97a414": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54f8f9870bfc470187305fe2a09f76c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "195db63b64c5443c912d5b79a93af9e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "532cd500f33c476abffbc363d84230a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db24a20eb7934f44b2a0502656ebbd1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cd11222efe44e879ce5cbcf1d244285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d9c4043a1324158a1475159ea37198f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e145561ecbf3407fa46c89a90a2cbaad",
              "IPY_MODEL_a34d3b889799452baff2d3682c9e6368",
              "IPY_MODEL_73b31f8c74484e87b52da147328836c6"
            ],
            "layout": "IPY_MODEL_83e14e753b5649969bb9d6628e1714ba"
          }
        },
        "e145561ecbf3407fa46c89a90a2cbaad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab559920cba248e3b1da547fb9cc98cf",
            "placeholder": "​",
            "style": "IPY_MODEL_59f8cee601834b279bdf88e90aba5c1a",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "a34d3b889799452baff2d3682c9e6368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08fd2f939da240fd851dd3829bd4826c",
            "max": 3639026128,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ee74fc04a704cb89e2e68dd37354a12",
            "value": 3639025781
          }
        },
        "73b31f8c74484e87b52da147328836c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_396e77d754e145dfa05735ad06e469ae",
            "placeholder": "​",
            "style": "IPY_MODEL_a652ee4208be4ce183abd30349942062",
            "value": " 3.64G/3.64G [00:30&lt;00:00, 58.8MB/s]"
          }
        },
        "83e14e753b5649969bb9d6628e1714ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab559920cba248e3b1da547fb9cc98cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59f8cee601834b279bdf88e90aba5c1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08fd2f939da240fd851dd3829bd4826c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ee74fc04a704cb89e2e68dd37354a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "396e77d754e145dfa05735ad06e469ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a652ee4208be4ce183abd30349942062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27938866f73e4afe81165c01b68f2d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03a1041953e54cedaf98d29638d62683",
              "IPY_MODEL_4bdc7537b3ff48f4b9f1b4b2bff6c055",
              "IPY_MODEL_b426d2ed969e4d73ad0823f727845a8e"
            ],
            "layout": "IPY_MODEL_8e83fe4c923942ec92a1a7c43df5a432"
          }
        },
        "03a1041953e54cedaf98d29638d62683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bbbf09f16da43ba95f9352e1f9719a1",
            "placeholder": "​",
            "style": "IPY_MODEL_a096ea764ab349b5b6a6ee5feb9b7a6c",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4bdc7537b3ff48f4b9f1b4b2bff6c055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2914366a0f5490e80659c1bd32d3e57",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed22e97251864257ae5a795a0686d886",
            "value": 2
          }
        },
        "b426d2ed969e4d73ad0823f727845a8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe934d07b842455fbb86147d3d9aefb5",
            "placeholder": "​",
            "style": "IPY_MODEL_ca3857d8a4124835bfce6b5132b836cb",
            "value": " 2/2 [00:48&lt;00:00, 23.66s/it]"
          }
        },
        "8e83fe4c923942ec92a1a7c43df5a432": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bbbf09f16da43ba95f9352e1f9719a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a096ea764ab349b5b6a6ee5feb9b7a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2914366a0f5490e80659c1bd32d3e57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed22e97251864257ae5a795a0686d886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe934d07b842455fbb86147d3d9aefb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca3857d8a4124835bfce6b5132b836cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4346dd514da74045a980a84faafcca76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a88f0449cfb4c748b0db773fb5471ca",
              "IPY_MODEL_dff8361b6df240e9aa5e9c09fd78a252",
              "IPY_MODEL_6f98650e827b4991bec519fa3228050c"
            ],
            "layout": "IPY_MODEL_9d109da83c0a4515a67711cbfe1ccd45"
          }
        },
        "2a88f0449cfb4c748b0db773fb5471ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81a7688b67ff4e01baf52ab87f254262",
            "placeholder": "​",
            "style": "IPY_MODEL_d45718d0f0a54805a76019cf3ec1ff97",
            "value": "generation_config.json: 100%"
          }
        },
        "dff8361b6df240e9aa5e9c09fd78a252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5d545dd35604185b52d46e87b3f4316",
            "max": 133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5fec2fc16624489ba3735a091db71679",
            "value": 133
          }
        },
        "6f98650e827b4991bec519fa3228050c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d30dac4b473245deaf9821233b9978c8",
            "placeholder": "​",
            "style": "IPY_MODEL_c7558cbb397b439c9fecbae79b74df1b",
            "value": " 133/133 [00:00&lt;00:00, 13.9kB/s]"
          }
        },
        "9d109da83c0a4515a67711cbfe1ccd45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81a7688b67ff4e01baf52ab87f254262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d45718d0f0a54805a76019cf3ec1ff97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5d545dd35604185b52d46e87b3f4316": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fec2fc16624489ba3735a091db71679": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d30dac4b473245deaf9821233b9978c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7558cbb397b439c9fecbae79b74df1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07b2fd37a3bd44fb8717a3f898c98208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b90395eed4a4e088df5373dd9cd4fa7",
              "IPY_MODEL_5261e4ce48eb4105b0f9270892c633a5",
              "IPY_MODEL_f16b2afbcf8c494cbe6b9e60f95737be"
            ],
            "layout": "IPY_MODEL_b79a1e5661584f2fbd3851437b08da8c"
          }
        },
        "6b90395eed4a4e088df5373dd9cd4fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21677a4eaf914786b5fb5e0b71a849e8",
            "placeholder": "​",
            "style": "IPY_MODEL_ac0730bd89b04c10b6809de1147e7f01",
            "value": "processor_config.json: 100%"
          }
        },
        "5261e4ce48eb4105b0f9270892c633a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ceaa49ed4c8d4cc6b840a7d49faf3b5e",
            "max": 70,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_462a32ea35bc4a31a1f45e570983dd5f",
            "value": 70
          }
        },
        "f16b2afbcf8c494cbe6b9e60f95737be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42d02a26614e4f9c9874ca338def7af5",
            "placeholder": "​",
            "style": "IPY_MODEL_5530d2aa3d6d4286bae24284242acb7c",
            "value": " 70.0/70.0 [00:00&lt;00:00, 6.27kB/s]"
          }
        },
        "b79a1e5661584f2fbd3851437b08da8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21677a4eaf914786b5fb5e0b71a849e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac0730bd89b04c10b6809de1147e7f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ceaa49ed4c8d4cc6b840a7d49faf3b5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "462a32ea35bc4a31a1f45e570983dd5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42d02a26614e4f9c9874ca338def7af5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5530d2aa3d6d4286bae24284242acb7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e38cbf13cc07456e91585d4964c13b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b47a2c8b67b64f02ab0d38e2ca0827d8",
              "IPY_MODEL_3e2497973ee44759a9f8f0d6e44fdaae",
              "IPY_MODEL_5ccb87ba3aa144678538adaacec65c5e"
            ],
            "layout": "IPY_MODEL_6ba0275bbe324263b72254b4dce6cb38"
          }
        },
        "b47a2c8b67b64f02ab0d38e2ca0827d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_970b27d7ccc34e298da4ac797fc0aa28",
            "placeholder": "​",
            "style": "IPY_MODEL_cd2ef0c4342a4523ae36f0bf5190a343",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "3e2497973ee44759a9f8f0d6e44fdaae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_545e54e172e44238adf2be33072391de",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd3e3193fe9c4abba509d7fea258bab1",
            "value": 570
          }
        },
        "5ccb87ba3aa144678538adaacec65c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ef51bcc90744a81953d52db414f5c51",
            "placeholder": "​",
            "style": "IPY_MODEL_025880ce541e484489455072bdc86000",
            "value": " 570/570 [00:00&lt;00:00, 55.2kB/s]"
          }
        },
        "6ba0275bbe324263b72254b4dce6cb38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "970b27d7ccc34e298da4ac797fc0aa28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd2ef0c4342a4523ae36f0bf5190a343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "545e54e172e44238adf2be33072391de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd3e3193fe9c4abba509d7fea258bab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ef51bcc90744a81953d52db414f5c51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "025880ce541e484489455072bdc86000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b86f3b8dcaf4c8dab71aa5f2c9d8b71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ae30c0f92824538bb078fd39f3b8088",
              "IPY_MODEL_6873ea3a64854b53b0555af61878a183",
              "IPY_MODEL_a00b369b87a6415bb562f853ae96d528"
            ],
            "layout": "IPY_MODEL_6950491895284e6181b553089f7b22cd"
          }
        },
        "3ae30c0f92824538bb078fd39f3b8088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43452a4a90a548529850cd798b6af045",
            "placeholder": "​",
            "style": "IPY_MODEL_3963da5b1d194c02b0e0f08124e16246",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6873ea3a64854b53b0555af61878a183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb04581a4b9b490c9b2a6964a6740953",
            "max": 1155389,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f06ef47cc58d4c009893825ca52b1d75",
            "value": 1155389
          }
        },
        "a00b369b87a6415bb562f853ae96d528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54bf7bb63e9747a999bebf9df981d12a",
            "placeholder": "​",
            "style": "IPY_MODEL_3957ee79d21b455788d055f6e9617538",
            "value": " 1.16M/1.16M [00:00&lt;00:00, 4.56MB/s]"
          }
        },
        "6950491895284e6181b553089f7b22cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43452a4a90a548529850cd798b6af045": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3963da5b1d194c02b0e0f08124e16246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb04581a4b9b490c9b2a6964a6740953": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f06ef47cc58d4c009893825ca52b1d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54bf7bb63e9747a999bebf9df981d12a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3957ee79d21b455788d055f6e9617538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e827c576b0af47da8f66f427c4f1f37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25c7ccbe9442454fa3e9b2dfa031547a",
              "IPY_MODEL_d5daa7de0a074e57aae089c59b06c6db",
              "IPY_MODEL_36042f6e5e3b4bb28d3379c86ac26f3b"
            ],
            "layout": "IPY_MODEL_64b7de7de99e42b59528a054fd4f1e1a"
          }
        },
        "25c7ccbe9442454fa3e9b2dfa031547a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3d613a1e1ff49bbb23e1e35851ba856",
            "placeholder": "​",
            "style": "IPY_MODEL_7d0eca9bcc564d5dabea68c3a163f8e8",
            "value": "tokenizer.model: 100%"
          }
        },
        "d5daa7de0a074e57aae089c59b06c6db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a44085b219ee4507852a69b541c10fe8",
            "max": 4689074,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3c729fe7ea2432cad8195cd92ff6ed2",
            "value": 4689074
          }
        },
        "36042f6e5e3b4bb28d3379c86ac26f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecd8be76592a47c4bfc1b4273a5c059d",
            "placeholder": "​",
            "style": "IPY_MODEL_dc23a91b5a8242c1830da0e596b81d75",
            "value": " 4.69M/4.69M [00:00&lt;00:00, 27.1MB/s]"
          }
        },
        "64b7de7de99e42b59528a054fd4f1e1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3d613a1e1ff49bbb23e1e35851ba856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d0eca9bcc564d5dabea68c3a163f8e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a44085b219ee4507852a69b541c10fe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3c729fe7ea2432cad8195cd92ff6ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecd8be76592a47c4bfc1b4273a5c059d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc23a91b5a8242c1830da0e596b81d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a6a61a221a348a1a8a3d21855ecdea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb8d61ec57494609bc3f0c3212960e43",
              "IPY_MODEL_8ee0aebd45534114adbcace61a52b20c",
              "IPY_MODEL_95fe4c4298ef4595adf36052080a551c"
            ],
            "layout": "IPY_MODEL_8f8c68ad8c0d402c876e1ed282a71fe9"
          }
        },
        "cb8d61ec57494609bc3f0c3212960e43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dcb5b40bd7a4127a313bdb100dd034e",
            "placeholder": "​",
            "style": "IPY_MODEL_2153b2528bb0404bb18eac10ba40fc51",
            "value": "tokenizer.json: 100%"
          }
        },
        "8ee0aebd45534114adbcace61a52b20c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea0d4018342d463dbdf729aab5b5dc55",
            "max": 33384570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b1234a05940415088b49b88c9d1843b",
            "value": 33384570
          }
        },
        "95fe4c4298ef4595adf36052080a551c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27edaffa310543b3b96d5f012c1fc8f6",
            "placeholder": "​",
            "style": "IPY_MODEL_07c70a122a264582bfa4b43342b83f50",
            "value": " 33.4M/33.4M [00:00&lt;00:00, 140MB/s]"
          }
        },
        "8f8c68ad8c0d402c876e1ed282a71fe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dcb5b40bd7a4127a313bdb100dd034e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2153b2528bb0404bb18eac10ba40fc51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea0d4018342d463dbdf729aab5b5dc55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b1234a05940415088b49b88c9d1843b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27edaffa310543b3b96d5f012c1fc8f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07c70a122a264582bfa4b43342b83f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39fed68782894918864c8ff51480e252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57d2d01c757e464c91d9500d213c3e64",
              "IPY_MODEL_751b7be3e13d4317a68efd93148bf1fd",
              "IPY_MODEL_c446f157ce3d44a091e870b96ea24634"
            ],
            "layout": "IPY_MODEL_98343abe744c4e01b90eebda7868fbf5"
          }
        },
        "57d2d01c757e464c91d9500d213c3e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e50f515ea3840ceb8e6da231e4bc381",
            "placeholder": "​",
            "style": "IPY_MODEL_0af02ca48bf74df9ace44d532b3c84ed",
            "value": "added_tokens.json: 100%"
          }
        },
        "751b7be3e13d4317a68efd93148bf1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc0dae82a8a84f52aaba584fd3637751",
            "max": 35,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_243979bd252f4c7eaa78ec9bab8cb6df",
            "value": 35
          }
        },
        "c446f157ce3d44a091e870b96ea24634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d36da6edcc38415b9be49f66f0b821be",
            "placeholder": "​",
            "style": "IPY_MODEL_4e65ad140381483a9b0ee177715ab85a",
            "value": " 35.0/35.0 [00:00&lt;00:00, 3.43kB/s]"
          }
        },
        "98343abe744c4e01b90eebda7868fbf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e50f515ea3840ceb8e6da231e4bc381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0af02ca48bf74df9ace44d532b3c84ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc0dae82a8a84f52aaba584fd3637751": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "243979bd252f4c7eaa78ec9bab8cb6df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d36da6edcc38415b9be49f66f0b821be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e65ad140381483a9b0ee177715ab85a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb597793d5644954b10b4ac5eda74ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_617bea01f8ed4ad98922c08a171510a5",
              "IPY_MODEL_29cc0ea275b74ca092d8ba657327f0a0",
              "IPY_MODEL_3160a0ac2f1549f680c101822bfebb34"
            ],
            "layout": "IPY_MODEL_d6d9474199ce429c878d69366e58f6ce"
          }
        },
        "617bea01f8ed4ad98922c08a171510a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfbdfc7fb21f47aa8532c2de811ab069",
            "placeholder": "​",
            "style": "IPY_MODEL_33c69651dd79416c968e8454de043200",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "29cc0ea275b74ca092d8ba657327f0a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0f185fef6c54f499d7026893e98ea0c",
            "max": 662,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7030d0bf64ca4e18835b30952860166a",
            "value": 662
          }
        },
        "3160a0ac2f1549f680c101822bfebb34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e18525cc58649e0accd9c6517c19203",
            "placeholder": "​",
            "style": "IPY_MODEL_7f6f4804119e4fb0a9c3b1281880dc7d",
            "value": " 662/662 [00:00&lt;00:00, 45.5kB/s]"
          }
        },
        "d6d9474199ce429c878d69366e58f6ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfbdfc7fb21f47aa8532c2de811ab069": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33c69651dd79416c968e8454de043200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0f185fef6c54f499d7026893e98ea0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7030d0bf64ca4e18835b30952860166a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e18525cc58649e0accd9c6517c19203": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f6f4804119e4fb0a9c3b1281880dc7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ravikrishnan05/PrediscanMedtech_project/blob/main/Unsloth_ptmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4A4G9LfFoEEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d492fac-ceb9-40d0-f1df-a29fee7724da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing Unsloth for Colab environment...\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (24.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (1.11.1.4)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: flash-attn in /usr/local/lib/python3.11/dist-packages (2.7.4.post1)\n",
            "Requirement already satisfied: xformers in /usr/local/lib/python3.11/dist-packages (0.0.30)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.18.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.0)\n",
            "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-z__qlxuq/unsloth_9bca881f7f9c44408d0d92e4f7f3d212\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-z__qlxuq/unsloth_9bca881f7f9c44408d0d92e4f7f3d212\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit 8c432a9d52a735f66fe1d3bcdfc0b2b0dc271a2e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# To run this, press \"Runtime\" and press \"Run all\" on a free Tesla T4 Google Colab instance!\n",
        "\n",
        "#    Join Discord if you need help + ⭐ Star us on Github ⭐\n",
        "# To install Unsloth on your own computer, follow the installation instructions on our Github page here.\n",
        "\n",
        "# You will learn how to do data prep, how to train, how to run the model, & how to save it\n",
        "\n",
        "# News\n",
        "# Unsloth now supports Text-to-Speech (TTS) models. Read our guide here.\n",
        "\n",
        "# Read our Qwen3 Guide and check out our new Dynamic 2.0 quants which outperforms other quantization methods!\n",
        "\n",
        "# Visit our docs for all our model uploads and notebooks.\n",
        "\n",
        "# To run this, press \"Runtime\" and press \"Run all\" on a free Tesla T4 Google Colab instance!\n",
        "# %%capture # Use %%capture to hide pip outputs if desired\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    print(\"Installing Unsloth for local environment...\")\n",
        "    !pip install \"unsloth[colab-new]@git+https://github.com/unslothai/unsloth.git\"\n",
        "else:\n",
        "    print(\"Installing Unsloth for Colab environment...\")\n",
        "    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n",
        "    !pip install --no-deps \"unsloth[colab-new]@git+https://github.com/unslothai/unsloth.git\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 0.2: Additional Library Installations\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\nInstalling additional libraries for data processing and DICOM handling...\")\n",
        "!pip install -q pydicom pandas opencv-python Pillow scikit-learn matplotlib seaborn \"huggingface_hub>=0.23.0\" \"hf_transfer>=0.1.6\" \"datasets>=2.16.0\" sentencepiece protobuf\n",
        "\n",
        "# Install unsloth_zoo\n",
        "print(\"\\nInstalling unsloth_zoo...\")\n",
        "!pip install unsloth_zoo"
      ],
      "metadata": {
        "id": "fhJQhFboqc1U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57a75954-47b8-496b-ec77-07fe764a79cb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Installing additional libraries for data processing and DICOM handling...\n",
            "\n",
            "Installing unsloth_zoo...\n",
            "Requirement already satisfied: unsloth_zoo in /usr/local/lib/python3.11/dist-packages (2025.5.11)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (2.6.0+cu124)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (3.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (24.2)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.9.24)\n",
            "Requirement already satisfied: transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,>=4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (4.52.3)\n",
            "Requirement already satisfied: datasets>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (3.6.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (2.0.2)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (1.7.0)\n",
            "Requirement already satisfied: trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.18.1)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.15.2)\n",
            "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (3.20.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.32.2)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.1.9)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (25.1.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (11.2.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (2024.11.6)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo) (0.19.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth_zoo) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth_zoo) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth_zoo) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth_zoo) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth_zoo) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth_zoo) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth_zoo) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth_zoo) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth_zoo) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.30.0->unsloth_zoo) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.30.0->unsloth_zoo) (1.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->unsloth_zoo) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->unsloth_zoo) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,>=4.51.3->unsloth_zoo) (0.21.1)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth_zoo) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth_zoo) (13.9.4)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth_zoo) (1.7.2)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth_zoo) (4.4.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.4.1->unsloth_zoo) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.4.1->unsloth_zoo) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.4.1->unsloth_zoo) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.4.1->unsloth_zoo) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth_zoo) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth_zoo) (2.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->unsloth_zoo) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth_zoo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth_zoo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth_zoo) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (1.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth_zoo) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.4.1->unsloth_zoo) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unsloth FastModel supports loading nearly any model now! This includes Vision and Text models!\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Cell 0.3: Unsloth Model Loading\n",
        "# -----------------------------------------------------------------------------\n",
        "from unsloth import FastLanguageModel # Changed from FastModel to FastLanguageModel as per recent Unsloth examples for language models\n",
        "import torch"
      ],
      "metadata": {
        "id": "aTMppuNfrAxl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c59fc839-62f4-47c2-d300-3e4a67cb5a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.6.0+cu124)\n",
            "    Python  3.11.12 (you have 3.11.12)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: MODEL SELECTION FOR YOUR TASK\n",
        "# The model \"unsloth/gemma-3-4b-it\" is a TEXT-BASED instruct model.\n",
        "# Your original code used MedGemma, a VISION-LANGUAGE model, and processed images.\n",
        "# If your task involves processing images to predict LDL, you MUST select a vision-language model.\n",
        "# Examples:\n",
        "#   - Search for Unsloth-quantized vision models: https://huggingface.co/unsloth\n",
        "#   - Try loading a standard HF vision model (e.g., \"google/medgemma-4b-pt\", \"llava-hf/llava-1.5-7b-hf\", \"microsoft/phi-3-vision-128k-instruct\")\n",
        "#     FastLanguageModel might support them. If so, set `finetune_vision_layers = True` in the PEFT setup.\n",
        "# For this example, we'll use the text model from the Unsloth template.\n",
        "# You will need to adapt your data processing (especially image handling in the Dataset)\n",
        "# if you use a text model for a vision task, or change the model_name.\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "# --- Model Selection ---\n",
        "# We are focusing on MedGemma for vision-based LDL prediction.\n",
        "selected_model_name = \"google/medgemma-4b-pt\"\n",
        "\n",
        "print(f\"Attempting to load model: {selected_model_name}\")\n",
        "# When loading a multimodal model like MedGemma, FastLanguageModel handles it.\n",
        "# The 'tokenizer' returned will be a multimodal processor (e.g., GemmaProcessor)\n",
        "# which contains both the image_processor and the text_tokenizer.\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=selected_model_name,\n",
        "    max_seq_length=2048,  # Max sequence length for the language model part (less critical for pure vision regression)\n",
        "    dtype=None,           # Autodetect\n",
        "    load_in_4bit=True,    # Enable 4-bit quantization for memory efficiency\n",
        "    # token = \"hf_...\",   # Use if the model is gated\n",
        ")\n",
        "print(f\"Model {selected_model_name} loaded successfully.\")\n",
        "print(f\"Tokenizer type: {type(tokenizer)}\")\n",
        "\n",
        "# --- Verify Image Processor and Get Vision Feature Dimension ---\n",
        "# For MedGemma, the tokenizer is a GemmaProcessor which should have an 'image_processor'\n",
        "if hasattr(tokenizer, 'image_processor') and tokenizer.image_processor is not None:\n",
        "    print(\"Image processor found in tokenizer.\")\n",
        "    # The vision tower configuration is part of the main model's config for MedGemma\n",
        "    if hasattr(model.config, 'vision_config'):\n",
        "        vision_config = model.config.vision_config\n",
        "        # The vision feature dimension is typically 'hidden_size' of the vision_config\n",
        "        # For SigLIP (MedGemma's vision tower), it's usually referred to as hidden_size.\n",
        "        vision_feature_dim = vision_config.hidden_size\n",
        "        print(f\"Detected vision feature dimension from model.config.vision_config: {vision_feature_dim}\")\n",
        "    else:\n",
        "        print(\"ERROR: model.config.vision_config not found. Cannot determine vision_feature_dim automatically.\")\n",
        "        # Fallback: Try to inspect the vision_tower directly if it exists on the base model\n",
        "        # This path might be needed if Unsloth wraps the model differently.\n",
        "        base_model_ref = model.model if hasattr(model, 'model') else model\n",
        "        if hasattr(base_model_ref, 'vision_tower') and hasattr(base_model_ref.vision_tower, 'config'):\n",
        "            vision_feature_dim = base_model_ref.vision_tower.config.hidden_size\n",
        "            print(f\"Detected vision feature dimension from base_model.vision_tower.config: {vision_feature_dim}\")\n",
        "        else:\n",
        "            vision_feature_dim = None\n",
        "            print(\"ERROR: Could not access vision_tower.config. Manually inspect 'model' object and set vision_feature_dim.\")\n",
        "            print(\"Model structure:\", model) # Helps in debugging\n",
        "else:\n",
        "    print(\"ERROR: No image_processor found in the tokenizer. This is unexpected for MedGemma.\")\n",
        "    vision_feature_dim = None\n",
        "\n",
        "if vision_feature_dim is None:\n",
        "    print(\"CRITICAL ERROR: vision_feature_dim could not be determined. Regression head cannot be initialized correctly.\")\n",
        "    # You might need to manually set it based on MedGemma's architecture if auto-detection fails.\n",
        "    # For medgemma-4b-pt, the vision feature dimension (SigLIP-L/16) is 1024.\n",
        "    vision_feature_dim = 1152 # Example: Manually set if necessary\n",
        "    print(f\"Attempting to use manually set vision_feature_dim: {vision_feature_dim}\")\n",
        "\n",
        "# Note: For vision models, the 'tokenizer' might be a composite object\n",
        "# or you might access an image processor via `model.processor` or `tokenizer.image_processor`.\n",
        "# This depends on how Unsloth handles vision models."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802,
          "referenced_widgets": [
            "b43cdf3a9f184843bce6b65f01b6eb00",
            "3fb5a53475f24852b327d77b2ee23cb4",
            "0ed2e2b3b18c4a6ebcebf075870b6add",
            "a3588bd8016c409b9e311d18895e0faa",
            "4998291abeb24ca8a9efa3abc8a2617f",
            "b7e5a41c2fee4e34a2636d24c0fd3dfc",
            "932c4ed977f24e40832dc6f0087b9cd8",
            "4d5e192bc6f14997a9b67c7711fe74d6",
            "eb1b3210edba4acbb27d4c933cba367b",
            "b6d3ce901bf2457980679633c1de56a2",
            "fb3c77ec275b40e484750ca0b636413a",
            "82c384db1a9c4f2389170118ef908709",
            "9e46e48133b94cf6a0ea9b2afb6eaf8c",
            "cc9e69e6aef8486da43279a50c12f59d",
            "e952366fb5cf4471bdce14fcde90a086",
            "ea3fa6bbe3dd401b882a0edd7ba78902",
            "e8422ab858f44353acd1e96b3e97a414",
            "54f8f9870bfc470187305fe2a09f76c8",
            "195db63b64c5443c912d5b79a93af9e9",
            "532cd500f33c476abffbc363d84230a7",
            "db24a20eb7934f44b2a0502656ebbd1c",
            "0cd11222efe44e879ce5cbcf1d244285",
            "1d9c4043a1324158a1475159ea37198f",
            "e145561ecbf3407fa46c89a90a2cbaad",
            "a34d3b889799452baff2d3682c9e6368",
            "73b31f8c74484e87b52da147328836c6",
            "83e14e753b5649969bb9d6628e1714ba",
            "ab559920cba248e3b1da547fb9cc98cf",
            "59f8cee601834b279bdf88e90aba5c1a",
            "08fd2f939da240fd851dd3829bd4826c",
            "0ee74fc04a704cb89e2e68dd37354a12",
            "396e77d754e145dfa05735ad06e469ae",
            "a652ee4208be4ce183abd30349942062",
            "27938866f73e4afe81165c01b68f2d2b",
            "03a1041953e54cedaf98d29638d62683",
            "4bdc7537b3ff48f4b9f1b4b2bff6c055",
            "b426d2ed969e4d73ad0823f727845a8e",
            "8e83fe4c923942ec92a1a7c43df5a432",
            "6bbbf09f16da43ba95f9352e1f9719a1",
            "a096ea764ab349b5b6a6ee5feb9b7a6c",
            "d2914366a0f5490e80659c1bd32d3e57",
            "ed22e97251864257ae5a795a0686d886",
            "fe934d07b842455fbb86147d3d9aefb5",
            "ca3857d8a4124835bfce6b5132b836cb",
            "4346dd514da74045a980a84faafcca76",
            "2a88f0449cfb4c748b0db773fb5471ca",
            "dff8361b6df240e9aa5e9c09fd78a252",
            "6f98650e827b4991bec519fa3228050c",
            "9d109da83c0a4515a67711cbfe1ccd45",
            "81a7688b67ff4e01baf52ab87f254262",
            "d45718d0f0a54805a76019cf3ec1ff97",
            "f5d545dd35604185b52d46e87b3f4316",
            "5fec2fc16624489ba3735a091db71679",
            "d30dac4b473245deaf9821233b9978c8",
            "c7558cbb397b439c9fecbae79b74df1b",
            "07b2fd37a3bd44fb8717a3f898c98208",
            "6b90395eed4a4e088df5373dd9cd4fa7",
            "5261e4ce48eb4105b0f9270892c633a5",
            "f16b2afbcf8c494cbe6b9e60f95737be",
            "b79a1e5661584f2fbd3851437b08da8c",
            "21677a4eaf914786b5fb5e0b71a849e8",
            "ac0730bd89b04c10b6809de1147e7f01",
            "ceaa49ed4c8d4cc6b840a7d49faf3b5e",
            "462a32ea35bc4a31a1f45e570983dd5f",
            "42d02a26614e4f9c9874ca338def7af5",
            "5530d2aa3d6d4286bae24284242acb7c",
            "e38cbf13cc07456e91585d4964c13b06",
            "b47a2c8b67b64f02ab0d38e2ca0827d8",
            "3e2497973ee44759a9f8f0d6e44fdaae",
            "5ccb87ba3aa144678538adaacec65c5e",
            "6ba0275bbe324263b72254b4dce6cb38",
            "970b27d7ccc34e298da4ac797fc0aa28",
            "cd2ef0c4342a4523ae36f0bf5190a343",
            "545e54e172e44238adf2be33072391de",
            "fd3e3193fe9c4abba509d7fea258bab1",
            "0ef51bcc90744a81953d52db414f5c51",
            "025880ce541e484489455072bdc86000",
            "7b86f3b8dcaf4c8dab71aa5f2c9d8b71",
            "3ae30c0f92824538bb078fd39f3b8088",
            "6873ea3a64854b53b0555af61878a183",
            "a00b369b87a6415bb562f853ae96d528",
            "6950491895284e6181b553089f7b22cd",
            "43452a4a90a548529850cd798b6af045",
            "3963da5b1d194c02b0e0f08124e16246",
            "cb04581a4b9b490c9b2a6964a6740953",
            "f06ef47cc58d4c009893825ca52b1d75",
            "54bf7bb63e9747a999bebf9df981d12a",
            "3957ee79d21b455788d055f6e9617538",
            "e827c576b0af47da8f66f427c4f1f37e",
            "25c7ccbe9442454fa3e9b2dfa031547a",
            "d5daa7de0a074e57aae089c59b06c6db",
            "36042f6e5e3b4bb28d3379c86ac26f3b",
            "64b7de7de99e42b59528a054fd4f1e1a",
            "a3d613a1e1ff49bbb23e1e35851ba856",
            "7d0eca9bcc564d5dabea68c3a163f8e8",
            "a44085b219ee4507852a69b541c10fe8",
            "d3c729fe7ea2432cad8195cd92ff6ed2",
            "ecd8be76592a47c4bfc1b4273a5c059d",
            "dc23a91b5a8242c1830da0e596b81d75",
            "0a6a61a221a348a1a8a3d21855ecdea6",
            "cb8d61ec57494609bc3f0c3212960e43",
            "8ee0aebd45534114adbcace61a52b20c",
            "95fe4c4298ef4595adf36052080a551c",
            "8f8c68ad8c0d402c876e1ed282a71fe9",
            "9dcb5b40bd7a4127a313bdb100dd034e",
            "2153b2528bb0404bb18eac10ba40fc51",
            "ea0d4018342d463dbdf729aab5b5dc55",
            "8b1234a05940415088b49b88c9d1843b",
            "27edaffa310543b3b96d5f012c1fc8f6",
            "07c70a122a264582bfa4b43342b83f50",
            "39fed68782894918864c8ff51480e252",
            "57d2d01c757e464c91d9500d213c3e64",
            "751b7be3e13d4317a68efd93148bf1fd",
            "c446f157ce3d44a091e870b96ea24634",
            "98343abe744c4e01b90eebda7868fbf5",
            "5e50f515ea3840ceb8e6da231e4bc381",
            "0af02ca48bf74df9ace44d532b3c84ed",
            "fc0dae82a8a84f52aaba584fd3637751",
            "243979bd252f4c7eaa78ec9bab8cb6df",
            "d36da6edcc38415b9be49f66f0b821be",
            "4e65ad140381483a9b0ee177715ab85a",
            "cb597793d5644954b10b4ac5eda74ac3",
            "617bea01f8ed4ad98922c08a171510a5",
            "29cc0ea275b74ca092d8ba657327f0a0",
            "3160a0ac2f1549f680c101822bfebb34",
            "d6d9474199ce429c878d69366e58f6ce",
            "cfbdfc7fb21f47aa8532c2de811ab069",
            "33c69651dd79416c968e8454de043200",
            "c0f185fef6c54f499d7026893e98ea0c",
            "7030d0bf64ca4e18835b30952860166a",
            "3e18525cc58649e0accd9c6517c19203",
            "7f6f4804119e4fb0a9c3b1281880dc7d"
          ]
        },
        "id": "6CH2bYyCacJB",
        "outputId": "60ea2bd7-c6d4-4da5-9e5d-332e26540a9c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.7.0+cu126 with CUDA 1206 (you have 2.6.0+cu124)\n",
            "    Python  3.11.12 (you have 3.11.12)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "Attempting to load model: google/medgemma-4b-pt\n",
            "==((====))==  Unsloth 2025.5.10: Fast Gemma3 patching. Transformers: 4.52.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: Using float16 precision for gemma3 won't work! Using float32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/90.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b43cdf3a9f184843bce6b65f01b6eb00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82c384db1a9c4f2389170118ef908709"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.64G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d9c4043a1324158a1475159ea37198f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27938866f73e4afe81165c01b68f2d2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/133 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4346dd514da74045a980a84faafcca76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "processor_config.json:   0%|          | 0.00/70.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07b2fd37a3bd44fb8717a3f898c98208"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e38cbf13cc07456e91585d4964c13b06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b86f3b8dcaf4c8dab71aa5f2c9d8b71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e827c576b0af47da8f66f427c4f1f37e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a6a61a221a348a1a8a3d21855ecdea6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39fed68782894918864c8ff51480e252"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb597793d5644954b10b4ac5eda74ac3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model google/medgemma-4b-pt loaded successfully.\n",
            "Tokenizer type: <class 'transformers.models.gemma3.processing_gemma3.Gemma3Processor'>\n",
            "Image processor found in tokenizer.\n",
            "Detected vision feature dimension from model.config.vision_config: 1152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After loading the model with Unsloth:\n",
        "# The actual path might be model.model.vision_tower if PEFT wraps it further\n",
        "base_medgemma_model = model.model if hasattr(model, 'model') else model # Access base model if PEFT wrapped\n",
        "\n",
        "if hasattr(base_medgemma_model, 'vision_tower') and hasattr(base_medgemma_model.vision_tower, 'config'):\n",
        "    vision_config = base_medgemma_model.vision_tower.config\n",
        "    vision_feature_dim = vision_config.hidden_size\n",
        "    print(f\"Detected vision feature dimension: {vision_feature_dim}\")\n",
        "    # Now define your regression head separately or as part of a wrapper\n",
        "    # regression_head = torch.nn.Linear(vision_feature_dim, 1)\n",
        "else:\n",
        "    print(\"ERROR: Could not access model.vision_tower.config to get vision_feature_dim.\")\n",
        "    print(\"Please inspect the 'model' object structure from Unsloth carefully.\")\n",
        "    # You might need to print(model) and explore its attributes\n",
        "    vision_feature_dim = None # Fallback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7rHCq-aceho",
        "outputId": "986f5853-6f48-4971-81cd-ae9faffd46c0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected vision feature dimension: 1152\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Applying PEFT (LoRA) ---\")\n",
        "# `model` is the Unsloth-loaded MedGemma model from the previous cell.\n",
        "# We use get_peft_model for LoRA.\n",
        "RANDOM_SEED=42\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,  # LoRA rank (higher can mean more expressiveness but more params)\n",
        "    lora_alpha=32,  # LoRA alpha (scaling factor, often 2*r)\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\", # Recommended by Unsloth\n",
        "    random_state=RANDOM_SEED,\n",
        "    target_modules=None, # Let Unsloth automatically find layers for LoRA.\n",
        "                         # It should target both vision and language linear layers by default.\n",
        "    finetune_vision_layers=True, # CRITICAL: Ensure vision tower layers are targeted for LoRA\n",
        "    finetune_language_layers=False # OPTIONAL: For pure vision regression, we might not need to tune language layers.\n",
        "                                  # Set to False if language model outputs are not used by the regression head.\n",
        "                                  # If True (default), language LoRA adapters will also be trained.\n",
        ")\n",
        "print(\"PEFT (LoRA) adapters added to the MedGemma model.\")\n",
        "print(\"Trainable parameters after LoRA:\")\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APwpZTzwUoES",
        "outputId": "b2dfd610-9968-4b15-ff0f-b0ce30630a4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Applying PEFT (LoRA) ---\n",
            "Unsloth: Making `base_model.model.model.vision_tower.vision_model` require gradients\n",
            "PEFT (LoRA) adapters added to the MedGemma model.\n",
            "Trainable parameters after LoRA:\n",
            "trainable params: 8,695,296 || all params: 4,308,774,768 || trainable%: 0.2018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import torch.nn as nn\n",
        "\n",
        "class MedGemmaVisionRegressor(nn.Module):\n",
        "    def __init__(self, peft_medgemma_model, vision_feature_dim_input: int):\n",
        "        super().__init__()\n",
        "        self.medgemma_model = peft_medgemma_model # This is the PEFT-adapted model from Unsloth\n",
        "\n",
        "        # The regression head takes the pooled vision features and outputs 1 LDL value\n",
        "        self.regression_head = nn.Sequential(\n",
        "            nn.Linear(vision_feature_dim_input, vision_feature_dim_input // 2), # Intermediate layer\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(vision_feature_dim_input // 2, 1) # Output layer\n",
        "        )\n",
        "\n",
        "        # Note: Freezing of base MedGemma layers is handled by Unsloth's PEFT.\n",
        "        # LoRA adapters are trainable. The regression_head is also trainable.\n",
        "\n",
        "    def forward(self, pixel_values: torch.Tensor) -> torch.Tensor:\n",
        "        # The peft_medgemma_model is already a PeftModel.\n",
        "        # We need to pass pixel_values to it.\n",
        "        # The MedGemma model's forward pass can take pixel_values directly.\n",
        "        # It will internally use its vision_tower.\n",
        "        # For regression from vision, we typically want the pooled image features.\n",
        "\n",
        "        # Option 1: If the PEFT model directly gives vision features or allows access\n",
        "        # The `Gemma3ForMultiModalGeneration` (base for MedGemma) has `vision_tower`\n",
        "        # and can output `image_embeds` or similar.\n",
        "        # When using PEFT, the base model is often accessed via `self.medgemma_model.model`\n",
        "\n",
        "        base_model = self.medgemma_model.model # Access the original model underlying PEFT\n",
        "\n",
        "        # Get vision embeddings from the vision_tower\n",
        "        # The vision_tower (SigLIP) in MedGemma outputs pooled features.\n",
        "        vision_outputs = base_model.vision_tower(pixel_values=pixel_values, return_dict=True)\n",
        "\n",
        "        # `pooler_output` from SigLipVisionModelOutput is [batch_size, vision_feature_dim]\n",
        "        image_features = vision_outputs.pooler_output\n",
        "\n",
        "        if image_features is None:\n",
        "            # Fallback if pooler_output is not directly available (should be for SigLIP)\n",
        "            # This might happen if the model structure is different than expected.\n",
        "            # For ViT-like models, the first token's embedding ([CLS] token) is often used.\n",
        "            if hasattr(vision_outputs, 'last_hidden_state'):\n",
        "                image_features = vision_outputs.last_hidden_state[:, 0, :] # CLS token embedding\n",
        "            else:\n",
        "                raise ValueError(\"Could not extract pooled image features (pooler_output or CLS token) from vision_tower output.\")\n",
        "\n",
        "        # Pass vision features through the regression head\n",
        "        ldl_prediction = self.regression_head(image_features)\n",
        "        return ldl_prediction\n",
        "\n",
        "# --- Instantiate the Regressor Model ---\n",
        "if vision_feature_dim is not None:\n",
        "    # `model` here is the PEFT-adapted MedGemma model from Cell 0.4\n",
        "    regressor_model = MedGemmaVisionRegressor(model, vision_feature_dim)\n",
        "    print(f\"MedGemmaVisionRegressor created with regression head input dim {vision_feature_dim}.\")\n",
        "\n",
        "    # Move to GPU if available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    regressor_model.to(device)\n",
        "    print(f\"Regressor model moved to {device}.\")\n",
        "\n",
        "    print(\"\\nTrainable parameters of the Regressor Model (includes LoRA + head):\")\n",
        "    total_params = 0\n",
        "    trainable_params = 0\n",
        "    for name, param in regressor_model.named_parameters():\n",
        "        total_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "            # print(f\"Trainable: {name}, Shape: {param.shape}\") # Uncomment to see all trainable params\n",
        "    print(f\"Total parameters in RegressorModel: {total_params:,}\")\n",
        "    print(f\"Trainable parameters in RegressorModel: {trainable_params:,} ({100 * trainable_params / total_params:.2f}%)\")\n",
        "\n",
        "else:\n",
        "    regressor_model = None\n",
        "    print(\"CRITICAL ERROR: Cannot create MedGemmaVisionRegressor because vision_feature_dim is None.\")\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Cell 0.5: Define and Instantiate Custom Model Wrapper (MedGemmaVisionRegressor) - REVISED\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class MedGemmaVisionRegressor(nn.Module):\n",
        "    def __init__(self, peft_medgemma_model, vision_feature_dim_input: int):\n",
        "        super().__init__()\n",
        "        self.medgemma_model = peft_medgemma_model # This is the PEFT-adapted model from Unsloth\n",
        "        self.target_dtype = self.medgemma_model.dtype # Store the target dtype (e.g., bfloat16)\n",
        "        print(f\"[Regressor Init] Base PEFT model target dtype: {self.target_dtype}\")\n",
        "\n",
        "        # The regression head takes the pooled vision features and outputs 1 LDL value\n",
        "        self.regression_head = nn.Sequential(\n",
        "            nn.Linear(vision_feature_dim_input, vision_feature_dim_input // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(vision_feature_dim_input // 2, 1)\n",
        "        )\n",
        "\n",
        "        # Explicitly cast the regression head to the target_dtype\n",
        "        if self.target_dtype is not None:\n",
        "            print(f\"[Regressor Init] Casting regression_head to {self.target_dtype}.\")\n",
        "            self.regression_head = self.regression_head.to(dtype=self.target_dtype)\n",
        "\n",
        "\n",
        "    def forward(self, pixel_values: torch.Tensor) -> torch.Tensor:\n",
        "        # Input pixel_values should already be cast to self.target_dtype in the training loop\n",
        "        # print_once_train_loop(f\"[Regressor Fwd] Input pixel_values dtype: {pixel_values.dtype}\")\n",
        "\n",
        "        base_model = self.medgemma_model.model # Access the original model underlying PEFT\n",
        "\n",
        "        # Vision tower call\n",
        "        # The `pixel_values` are already expected to be in `self.target_dtype`\n",
        "        vision_outputs = base_model.vision_tower(pixel_values=pixel_values, return_dict=True)\n",
        "\n",
        "        image_features = vision_outputs.pooler_output\n",
        "\n",
        "        if image_features is None:\n",
        "            if hasattr(vision_outputs, 'last_hidden_state'):\n",
        "                image_features = vision_outputs.last_hidden_state[:, 0, :]\n",
        "            else:\n",
        "                raise ValueError(\"Could not extract pooled image features from vision_tower output.\")\n",
        "\n",
        "        # Ensure image_features are in the target_dtype before feeding to regression_head\n",
        "        # (Usually, they come out of the vision tower in the model's operating dtype)\n",
        "        if image_features.dtype != self.target_dtype:\n",
        "            # This print would be very informative if it triggers\n",
        "            print_once_train_loop(f\"[Regressor Fwd] WARNING: image_features dtype {image_features.dtype} != target_dtype {self.target_dtype}. Casting.\")\n",
        "            image_features = image_features.to(self.target_dtype)\n",
        "\n",
        "        # print_once_train_loop(f\"[Regressor Fwd] image_features (to regression_head) dtype: {image_features.dtype}\")\n",
        "\n",
        "        ldl_prediction = self.regression_head(image_features)\n",
        "        # print_once_train_loop(f\"[Regressor Fwd] ldl_prediction (output) dtype: {ldl_prediction.dtype}\")\n",
        "        return ldl_prediction\n",
        "\n",
        "# --- Instantiate the Regressor Model ---\n",
        "if vision_feature_dim is not None and 'model' in locals() and model is not None:\n",
        "    # `model` here is the PEFT-adapted MedGemma model from Cell 0.4\n",
        "    regressor_model = MedGemmaVisionRegressor(model, vision_feature_dim)\n",
        "    print(f\"MedGemmaVisionRegressor created with regression head input dim {vision_feature_dim}.\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    regressor_model.to(device) # Move to device first\n",
        "    print(f\"Regressor model moved to {device}.\")\n",
        "\n",
        "    # The casting of the whole model will be attempted in Cell 9\n",
        "    # after it's on the correct device.\n",
        "\n",
        "    print(\"\\nTrainable parameters of the Regressor Model (includes LoRA + head):\")\n",
        "    # (Parameter printing code from your previous Cell 0.5)\n",
        "    total_params = 0\n",
        "    trainable_params = 0\n",
        "    for name, param in regressor_model.named_parameters():\n",
        "        total_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(f\"Total parameters in RegressorModel: {total_params:,}\")\n",
        "    print(f\"Trainable parameters in RegressorModel: {trainable_params:,} ({100 * trainable_params / total_params:.2f}%)\")\n",
        "\n",
        "else:\n",
        "    regressor_model = None\n",
        "    print(\"CRITICAL ERROR: Cannot create MedGemmaVisionRegressor. Check 'vision_feature_dim' and 'model' (PEFT model).\")"
      ],
      "metadata": {
        "id": "ZKo4mLwBchne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2495653a-b768-4c0d-af36-b45c01ceb368"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Regressor Init] Base PEFT model target dtype: torch.bfloat16\n",
            "[Regressor Init] Casting regression_head to torch.bfloat16.\n",
            "MedGemmaVisionRegressor created with regression head input dim 1152.\n",
            "Regressor model moved to cuda.\n",
            "\n",
            "Trainable parameters of the Regressor Model (includes LoRA + head):\n",
            "Total parameters in RegressorModel: 2,499,582,961\n",
            "Trainable parameters in RegressorModel: 9,360,001 (0.37%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 1: PyTorch/HuggingFace Imports and Setup (Adapted from user's Cell 1)\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\nImporting libraries...\")\n",
        "# Python Standard Libraries\n",
        "import shutil # os, zipfile already imported or not needed here\n",
        "import zipfile\n",
        "\n",
        "# Third-party Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import cv2 # OpenCV\n",
        "from PIL import Image\n",
        "\n",
        "# PyTorch\n",
        "# import torch # Already imported\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Hugging Face (tokenizer is already loaded by Unsloth)\n",
        "# from transformers import AutoProcessor # Replaced by Unsloth's tokenizer\n",
        "\n",
        "# Plotting (optional, but often useful)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Colab specific\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"--- Library Version Checks ---\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "import sklearn\n",
        "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
        "# print(f\"TensorFlow Version: {tf.__version__}\") # TensorFlow not used in this Unsloth/PyTorch setup\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    print(f\"PyTorch CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU available for PyTorch: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"GPU not available for PyTorch, using CPU.\")\n",
        "\n",
        "# For reproducibility\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "print(\"\\nCell 1: Imports and basic setup complete.\")"
      ],
      "metadata": {
        "id": "BUr3OCOxsODW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88579dbe-86d8-431b-b9c1-5d41ee8e3fc7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Importing libraries...\n",
            "--- Library Version Checks ---\n",
            "Pandas version: 2.2.2\n",
            "NumPy version: 2.0.2\n",
            "Scikit-learn version: 1.6.1\n",
            "PyTorch version: 2.6.0+cu124\n",
            "PyTorch CUDA version: 12.4\n",
            "GPU available for PyTorch: Tesla T4\n",
            "\n",
            "Cell 1: Imports and basic setup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------\n",
        "# Cell 2: Configuration and Unzip Data (From user's Cell 2)\n",
        "# --------------------------------------------------\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# --- Configuration ---\n",
        "DRIVE_CSV_PATH = \"/content/drive/MyDrive/cp.csv\"\n",
        "DRIVE_ZIP_PATH = \"/content/drive/MyDrive/1000-20250517T062750Z-1-001.zip\" # Your image ZIP on Drive\n",
        "\n",
        "LOCAL_EXTRACT_PATH = \"/content/medgemma_extracted_images\"\n",
        "LOCAL_IMAGES_ROOT = os.path.join(LOCAL_EXTRACT_PATH, \"1000\") # Adjusted to match your structure\n",
        "LOCAL_CSV_PATH = \"/content/medgemma_cp.csv\"\n",
        "\n",
        "# --- Unzip Data (if not already done or if re-running) ---\n",
        "if os.path.exists(DRIVE_CSV_PATH):\n",
        "    shutil.copy(DRIVE_CSV_PATH, LOCAL_CSV_PATH)\n",
        "    print(f\"CSV copied to {LOCAL_CSV_PATH}\")\n",
        "else:\n",
        "    print(f\"ERROR: CSV file not found at {DRIVE_CSV_PATH}\")\n",
        "\n",
        "if os.path.exists(LOCAL_EXTRACT_PATH):\n",
        "    print(f\"Removing existing extraction directory: {LOCAL_EXTRACT_PATH}\")\n",
        "    shutil.rmtree(LOCAL_EXTRACT_PATH)\n",
        "os.makedirs(LOCAL_EXTRACT_PATH, exist_ok=True)\n",
        "print(f\"Created local extraction directory: {LOCAL_EXTRACT_PATH}\")\n",
        "\n",
        "if os.path.exists(DRIVE_ZIP_PATH):\n",
        "    print(f\"Unzipping {DRIVE_ZIP_PATH} to {LOCAL_EXTRACT_PATH}...\")\n",
        "    with zipfile.ZipFile(DRIVE_ZIP_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall(LOCAL_EXTRACT_PATH)\n",
        "    print(\"Unzipping complete.\")\n",
        "    if os.path.exists(LOCAL_IMAGES_ROOT):\n",
        "        print(f\"Image root folder found at: {LOCAL_IMAGES_ROOT}\")\n",
        "    else:\n",
        "        print(f\"ERROR: Expected image root folder '{LOCAL_IMAGES_ROOT}' not found after unzipping. Check ZIP structure.\")\n",
        "        print(f\"Contents of {LOCAL_EXTRACT_PATH}: {os.listdir(LOCAL_EXTRACT_PATH)}\")\n",
        "\n",
        "else:\n",
        "    print(f\"ERROR: ZIP file not found at {DRIVE_ZIP_PATH}\")\n",
        "\n",
        "print(\"\\nCell 2: Data unzipping complete.\")\n"
      ],
      "metadata": {
        "id": "qKhbFStitDQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc01bad7-b80b-405c-ccb8-67912778c157"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "CSV copied to /content/medgemma_cp.csv\n",
            "Created local extraction directory: /content/medgemma_extracted_images\n",
            "Unzipping /content/drive/MyDrive/1000-20250517T062750Z-1-001.zip to /content/medgemma_extracted_images...\n",
            "Unzipping complete.\n",
            "Image root folder found at: /content/medgemma_extracted_images/1000\n",
            "\n",
            "Cell 2: Data unzipping complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------\n",
        "# Cell 3: Load and Filter Clinical Data to create image_df (From user's Cell 3)\n",
        "# --------------------------------------------------\n",
        "image_df = pd.DataFrame()\n",
        "\n",
        "if not os.path.exists(LOCAL_CSV_PATH):\n",
        "    print(f\"FATAL ERROR: Clinical CSV file not found at the expected local path: {LOCAL_CSV_PATH}\")\n",
        "else:\n",
        "    df_raw_from_cell3 = pd.read_csv(LOCAL_CSV_PATH)\n",
        "    print(f\"Initial number of rows in clinical data (Cell 3): {len(df_raw_from_cell3)}\")\n",
        "\n",
        "    person_id_col_name_c3 = 'person_id'\n",
        "    ldl_col_name_c3 = \"LDL Cholesterol Calculation (mg/dL)\" # Ensure this matches your CSV header\n",
        "\n",
        "    if not (person_id_col_name_c3 in df_raw_from_cell3.columns and ldl_col_name_c3 in df_raw_from_cell3.columns):\n",
        "        print(f\"ERROR: Required columns ('{person_id_col_name_c3}' or '{ldl_col_name_c3}') not found in CSV.\")\n",
        "        print(f\"Available columns: {df_raw_from_cell3.columns.tolist()}\")\n",
        "    else:\n",
        "        df_selected_c3 = df_raw_from_cell3[[person_id_col_name_c3, ldl_col_name_c3]].copy()\n",
        "        df_selected_c3.rename(columns={ldl_col_name_c3: 'LDL_temp'}, inplace=True)\n",
        "        df_selected_c3['LDL_temp'] = pd.to_numeric(df_selected_c3['LDL_temp'], errors='coerce')\n",
        "        df_selected_c3.dropna(subset=['LDL_temp'], inplace=True)\n",
        "        df_selected_c3 = df_selected_c3[df_selected_c3['LDL_temp'] > 0].copy()\n",
        "        df_selected_c3[person_id_col_name_c3] = df_selected_c3[person_id_col_name_c3].astype(str)\n",
        "        print(f\"Cleaned clinical data (positive LDLs only): {len(df_selected_c3)} records.\")\n",
        "\n",
        "        ldl_lookup_c3 = df_selected_c3.set_index(person_id_col_name_c3)['LDL_temp'].to_dict()\n",
        "\n",
        "        if not (os.path.exists(LOCAL_IMAGES_ROOT) and os.path.isdir(LOCAL_IMAGES_ROOT)):\n",
        "            print(f\"FATAL ERROR: Images root path '{LOCAL_IMAGES_ROOT}' does not exist or is not a directory.\")\n",
        "        else:\n",
        "            available_folders_c3 = set(os.listdir(LOCAL_IMAGES_ROOT))\n",
        "            valid_ids_clinical_c3 = set(ldl_lookup_c3.keys())\n",
        "            common_person_ids_c3 = sorted(list(valid_ids_clinical_c3 & available_folders_c3))\n",
        "            print(f\"Found {len(common_person_ids_c3)} common person_ids for mapping.\")\n",
        "\n",
        "            image_records_list = []\n",
        "            for pid_c3 in common_person_ids_c3:\n",
        "                folder_path_c3 = os.path.join(LOCAL_IMAGES_ROOT, pid_c3)\n",
        "                ldl_val_c3 = ldl_lookup_c3[pid_c3]\n",
        "                if os.path.isdir(folder_path_c3):\n",
        "                    for filename_c3 in os.listdir(folder_path_c3):\n",
        "                        if filename_c3.lower().endswith(\".dcm\"):\n",
        "                            image_path_c3 = os.path.join(folder_path_c3, filename_c3)\n",
        "                            image_records_list.append({\n",
        "                                \"person_id\": pid_c3,\n",
        "                                \"image_path\": image_path_c3,\n",
        "                                \"LDL\": ldl_val_c3\n",
        "                            })\n",
        "            image_df = pd.DataFrame(image_records_list)\n",
        "            if not image_df.empty:\n",
        "                print(f\"Final image_df created with {len(image_df)} image-LDL pairs.\")\n",
        "                from IPython.display import display # For better display in Colab\n",
        "                display(image_df.head())\n",
        "                print(f\"LDL stats in final image_df: min={image_df['LDL'].min()}, max={image_df['LDL'].max()}, mean={image_df['LDL'].mean()}\")\n",
        "            else:\n",
        "                print(\"WARNING: image_df is empty after mapping. Check paths, IDs, and DICOM file existence.\")\n",
        "print(\"\\nCell 3: image_df preparation complete.\")"
      ],
      "metadata": {
        "id": "nyRLqIrUtLLR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "bc1d418e-ee5c-4b95-d000-06234ec6601e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial number of rows in clinical data (Cell 3): 1067\n",
            "Cleaned clinical data (positive LDLs only): 1025 records.\n",
            "Found 527 common person_ids for mapping.\n",
            "Final image_df created with 973 image-LDL pairs.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  person_id                                         image_path         LDL\n",
              "0      1002  /content/medgemma_extracted_images/1000/1002/1...  133.485054\n",
              "1      1004  /content/medgemma_extracted_images/1000/1004/1...   59.674544\n",
              "2      1004  /content/medgemma_extracted_images/1000/1004/1...   59.674544\n",
              "3      1005  /content/medgemma_extracted_images/1000/1005/1...   74.956702\n",
              "4      1007  /content/medgemma_extracted_images/1000/1007/1...   92.278412"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17569301-f8e9-4165-89bb-30e80ea44718\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>person_id</th>\n",
              "      <th>image_path</th>\n",
              "      <th>LDL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1002</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1002/1...</td>\n",
              "      <td>133.485054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1004</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1004/1...</td>\n",
              "      <td>59.674544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1004</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1004/1...</td>\n",
              "      <td>59.674544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1005</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1005/1...</td>\n",
              "      <td>74.956702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1007</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1007/1...</td>\n",
              "      <td>92.278412</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17569301-f8e9-4165-89bb-30e80ea44718')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17569301-f8e9-4165-89bb-30e80ea44718 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17569301-f8e9-4165-89bb-30e80ea44718');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9f7d1b6e-eafd-4103-b78f-5b3ea933da4a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f7d1b6e-eafd-4103-b78f-5b3ea933da4a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9f7d1b6e-eafd-4103-b78f-5b3ea933da4a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nCell 3: image_df preparation complete\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"person_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"1004\",\n          \"1007\",\n          \"1002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"/content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230809.2448.36605.dcm\",\n          \"/content/medgemma_extracted_images/1000/1007/1007_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230824.20355.67485.dcm\",\n          \"/content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_l_1.2.826.0.1.3680043.8.641.1.20230809.2436.96446.dcm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LDL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.751173059264335,\n        \"min\": 59.67454369,\n        \"max\": 133.4850537,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          59.67454369,\n          92.27841214,\n          133.4850537\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDL stats in final image_df: min=10.77327021, max=278.5634775, mean=92.26371915419321\n",
            "\n",
            "Cell 3: image_df preparation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 4: Verify image_df (Adapted from user's Cell 4)\n",
        "# -----------------------------------------------------------------------------\n",
        "if 'image_df' in locals() and isinstance(image_df, pd.DataFrame) and not image_df.empty:\n",
        "    print(f\"\\nContinuing with 'image_df' which has {len(image_df)} records.\")\n",
        "    print(\"Columns in image_df:\", image_df.columns.tolist())\n",
        "    from IPython.display import display # Ensure display is imported\n",
        "    print(\"Sample of image_df:\")\n",
        "    display(image_df.head())\n",
        "\n",
        "    required_cols = ['person_id', 'image_path', 'LDL']\n",
        "    if not all(col in image_df.columns for col in required_cols):\n",
        "        print(f\"ERROR: 'image_df' is missing one or more required columns: {required_cols}. Please re-run Cell 3.\")\n",
        "    elif image_df['LDL'].min() <= 0:\n",
        "        print(f\"ERROR: 'image_df' still contains non-positive LDL values. LDL min: {image_df['LDL'].min()}. Please re-run filtering in Cell 3.\")\n",
        "    else:\n",
        "        print(\"'image_df' seems okay to proceed.\")\n",
        "else:\n",
        "    print(\"ERROR: 'image_df' not found or is empty. Please ensure Cell 3 (data preparation) has been run successfully.\")\n",
        "    # To prevent later errors, create an empty df if it's missing, though this indicates a problem.\n",
        "    if 'image_df' not in locals() or not isinstance(image_df, pd.DataFrame):\n",
        "        image_df = pd.DataFrame(columns=['person_id', 'image_path', 'LDL'])\n",
        "\n",
        "\n",
        "print(f\"\\nUsing Unsloth loaded model: {selected_model_name}\") # From Cell 0.3\n",
        "print(\"\\nCell 4: image_df verification and Model ID check complete.\")"
      ],
      "metadata": {
        "id": "jKystT4Bt0Yq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "3260d98d-3d73-42ea-b3e2-c13df43dcf93"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Continuing with 'image_df' which has 973 records.\n",
            "Columns in image_df: ['person_id', 'image_path', 'LDL']\n",
            "Sample of image_df:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  person_id                                         image_path         LDL\n",
              "0      1002  /content/medgemma_extracted_images/1000/1002/1...  133.485054\n",
              "1      1004  /content/medgemma_extracted_images/1000/1004/1...   59.674544\n",
              "2      1004  /content/medgemma_extracted_images/1000/1004/1...   59.674544\n",
              "3      1005  /content/medgemma_extracted_images/1000/1005/1...   74.956702\n",
              "4      1007  /content/medgemma_extracted_images/1000/1007/1...   92.278412"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4fb857b-227f-438e-b8f9-5aa59a51f216\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>person_id</th>\n",
              "      <th>image_path</th>\n",
              "      <th>LDL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1002</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1002/1...</td>\n",
              "      <td>133.485054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1004</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1004/1...</td>\n",
              "      <td>59.674544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1004</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1004/1...</td>\n",
              "      <td>59.674544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1005</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1005/1...</td>\n",
              "      <td>74.956702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1007</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1007/1...</td>\n",
              "      <td>92.278412</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4fb857b-227f-438e-b8f9-5aa59a51f216')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d4fb857b-227f-438e-b8f9-5aa59a51f216 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d4fb857b-227f-438e-b8f9-5aa59a51f216');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c044c017-537e-41fd-9204-297515417552\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c044c017-537e-41fd-9204-297515417552')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c044c017-537e-41fd-9204-297515417552 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nCell 4: image_df verification and Model ID check complete\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"person_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"1004\",\n          \"1007\",\n          \"1002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"/content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230809.2448.36605.dcm\",\n          \"/content/medgemma_extracted_images/1000/1007/1007_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230824.20355.67485.dcm\",\n          \"/content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_l_1.2.826.0.1.3680043.8.641.1.20230809.2436.96446.dcm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LDL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.751173059264335,\n        \"min\": 59.67454369,\n        \"max\": 133.4850537,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          59.67454369,\n          92.27841214,\n          133.4850537\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'image_df' seems okay to proceed.\n",
            "\n",
            "Using Unsloth loaded model: google/medgemma-4b-pt\n",
            "\n",
            "Cell 4: image_df verification and Model ID check complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 5: Unsloth Tokenizer/Processor Info (Adapted from user's Cell 5)\n",
        "# -----------------------------------------------------------------------------\n",
        "# The `medgemma_processor` is now replaced by the `tokenizer` from Unsloth.\n",
        "# For vision models, this tokenizer might wrap an image processor,\n",
        "# or `model.processor` might be set by Unsloth.\n",
        "\n",
        "# This cell's original purpose was to find TARGET_SIZE_MEDGEMMA.\n",
        "# For MedGemma, the image processor (part of the 'tokenizer' object) handles resizing.\n",
        "# We can inspect the image_processor's configuration.\n",
        "\n",
        "print(\"\\n--- Inspecting MedGemma Image Processor ---\")\n",
        "TARGET_SIZE_FOR_IMAGES = None # Will be determined by the image_processor\n",
        "\n",
        "if 'tokenizer' in locals() and hasattr(tokenizer, 'image_processor') and tokenizer.image_processor is not None:\n",
        "    medgemma_image_processor = tokenizer.image_processor\n",
        "    print(f\"MedGemma Image Processor Type: {type(medgemma_image_processor)}\")\n",
        "\n",
        "    # The image processor config usually has 'size' information.\n",
        "    # For SigLIPImageProcessor (used by MedGemma), it's often under `size` directly.\n",
        "    # The 'size' attribute can be an int (for shortest_edge) or a dict {'height': H, 'width': W}.\n",
        "    if hasattr(medgemma_image_processor, 'size'):\n",
        "        size_info = medgemma_image_processor.size\n",
        "        print(f\"  Image processor 'size' attribute: {size_info}\")\n",
        "        if isinstance(size_info, int): # e.g., size=224 means shortest edge is 224\n",
        "            # MedGemma models often use square inputs, e.g., 224x224 for SigLIP-B, 384x384 for SigLIP-L\n",
        "            # The MedGemma paper mentions images are resized to 896×896 for their experiments.\n",
        "            # However, the underlying SigLIP processor might have its own default.\n",
        "            # Let's check if 'crop_size' is also available, which is often the final input size.\n",
        "            if hasattr(medgemma_image_processor, 'crop_size') and medgemma_image_processor.crop_size is not None:\n",
        "                crop_info = medgemma_image_processor.crop_size\n",
        "                if isinstance(crop_info, int):\n",
        "                    TARGET_SIZE_FOR_IMAGES = (crop_info, crop_info)\n",
        "                elif isinstance(crop_info, dict) and 'height' in crop_info and 'width' in crop_info:\n",
        "                    TARGET_SIZE_FOR_IMAGES = (crop_info['height'], crop_info['width'])\n",
        "                print(f\"  Using 'crop_size' for TARGET_SIZE_FOR_IMAGES: {TARGET_SIZE_FOR_IMAGES}\")\n",
        "\n",
        "            if TARGET_SIZE_FOR_IMAGES is None: # If crop_size wasn't definitive\n",
        "                 # If size is int, assume square image based on that size for processing.\n",
        "                 # The processor itself will handle the exact resizing logic.\n",
        "                 # We use this for our basic transforms if the processor fails.\n",
        "                 TARGET_SIZE_FOR_IMAGES = (size_info, size_info)\n",
        "                 print(f\"  Using 'size' attribute for TARGET_SIZE_FOR_IMAGES (assuming square): {TARGET_SIZE_FOR_IMAGES}\")\n",
        "\n",
        "        elif isinstance(size_info, dict) and 'height' in size_info and 'width' in size_info:\n",
        "            TARGET_SIZE_FOR_IMAGES = (size_info['height'], size_info['width'])\n",
        "            print(f\"  Using 'size' dict for TARGET_SIZE_FOR_IMAGES: {TARGET_SIZE_FOR_IMAGES}\")\n",
        "        else:\n",
        "            print(\"  Could not determine target size from image_processor.size. Check processor config.\")\n",
        "    else:\n",
        "        print(\"  Image processor does not have a direct 'size' attribute. Check its config details.\")\n",
        "\n",
        "    # Fallback if still not found, to MedGemma paper's mentioned size\n",
        "    if TARGET_SIZE_FOR_IMAGES is None:\n",
        "        TARGET_SIZE_FOR_IMAGES = (896, 896) # Default from MedGemma paper if not found in processor\n",
        "        print(f\"  Falling back to default TARGET_SIZE_FOR_IMAGES: {TARGET_SIZE_FOR_IMAGES} (from MedGemma paper)\")\n",
        "else:\n",
        "    print(\"ERROR: MedGemma image_processor not found in tokenizer. Cannot determine target image size.\")\n",
        "    TARGET_SIZE_FOR_IMAGES = (896, 896) # Fallback\n",
        "    print(f\"  Using fallback TARGET_SIZE_FOR_IMAGES: {TARGET_SIZE_FOR_IMAGES}\")\n",
        "\n",
        "print(f\"Final TARGET_SIZE_FOR_IMAGES to be used by Dataset (if processor fails or for reference): {TARGET_SIZE_FOR_IMAGES}\")\n",
        "print(\"\\nCell 5: MedGemma image processor check complete.\")"
      ],
      "metadata": {
        "id": "KOsK3Cd4t4G5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4401b60a-4606-4a55-a2e3-f4313e8ba333"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Inspecting MedGemma Image Processor ---\n",
            "MedGemma Image Processor Type: <class 'transformers.models.gemma3.image_processing_gemma3.Gemma3ImageProcessor'>\n",
            "  Image processor 'size' attribute: {'height': 896, 'width': 896}\n",
            "  Using 'size' dict for TARGET_SIZE_FOR_IMAGES: (896, 896)\n",
            "Final TARGET_SIZE_FOR_IMAGES to be used by Dataset (if processor fails or for reference): (896, 896)\n",
            "\n",
            "Cell 5: MedGemma image processor check complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 6: Data Splitting (Patient-Level) and LDL Normalization (From user's Cell 6)\n",
        "# -----------------------------------------------------------------------------\n",
        "train_df, val_df, test_df = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
        "ldl_scaler = None # Will store the fitted StandardScaler\n",
        "\n",
        "if 'image_df' in locals() and not image_df.empty:\n",
        "    print(f\"\\nStarting data splitting for {len(image_df)} image-LDL pairs...\")\n",
        "    if 'person_id' not in image_df.columns:\n",
        "        print(\"ERROR: 'person_id' column missing in image_df. Cannot perform patient-level split. Please check image_df preparation in Cell 3.\")\n",
        "    else:\n",
        "        unique_person_ids = image_df['person_id'].unique()\n",
        "        print(f\"Total unique patients for splitting: {len(unique_person_ids)}\")\n",
        "\n",
        "        if len(unique_person_ids) < 3: # Need at least 3 patients for train/val/test\n",
        "            print(\"Warning: Not enough unique patients for a robust 3-way (train/validation/test) split.\")\n",
        "            # Simplified split logic for few patients\n",
        "            if len(unique_person_ids) == 2:\n",
        "                train_pids, val_pids = train_test_split(unique_person_ids, test_size=0.5, random_state=RANDOM_SEED)\n",
        "                test_pids = np.array([]) # Empty array for consistency\n",
        "            elif len(unique_person_ids) == 1:\n",
        "                train_pids = unique_person_ids\n",
        "                val_pids, test_pids = np.array([]), np.array([])\n",
        "            else: # 0 patients\n",
        "                train_pids, val_pids, test_pids = np.array([]), np.array([]), np.array([])\n",
        "        else:\n",
        "            # Standard 70% train, 15% validation, 15% test split of person_ids\n",
        "            train_pids, temp_pids = train_test_split(\n",
        "                unique_person_ids, test_size=0.30, random_state=RANDOM_SEED # 70% train, 30% temp\n",
        "            )\n",
        "            if len(temp_pids) > 1 : # Ensure there's at least 2 for val/test split\n",
        "                 val_pids, test_pids = train_test_split(\n",
        "                    temp_pids, test_size=0.50, random_state=RANDOM_SEED # Split temp 50/50 for val/test (15% each of total)\n",
        "                )\n",
        "            elif len(temp_pids) == 1: # Only one patient left for temp\n",
        "                val_pids = temp_pids # Assign to validation\n",
        "                test_pids = np.array([])\n",
        "            else: # No patients left for temp\n",
        "                val_pids, test_pids = np.array([]), np.array([])\n",
        "\n",
        "\n",
        "        train_df = image_df[image_df['person_id'].isin(train_pids)].copy()\n",
        "        val_df = image_df[image_df['person_id'].isin(val_pids)].copy()\n",
        "        test_df = image_df[image_df['person_id'].isin(test_pids)].copy()\n",
        "\n",
        "        print(f\"Train set: {len(train_df)} samples from {len(train_pids)} patients.\")\n",
        "        print(f\"Validation set: {len(val_df)} samples from {len(val_pids)} patients.\")\n",
        "        print(f\"Test set: {len(test_df)} samples from {len(test_pids)} patients.\")\n",
        "\n",
        "        # Sanity check for patient overlap\n",
        "        if len(train_pids)>0 and len(val_pids)>0: assert len(set(train_pids) & set(val_pids)) == 0, \"Patient overlap train/val!\"\n",
        "        if len(train_pids)>0 and len(test_pids)>0: assert len(set(train_pids) & set(test_pids)) == 0, \"Patient overlap train/test!\"\n",
        "        if len(val_pids)>0 and len(test_pids)>0: assert len(set(val_pids) & set(test_pids)) == 0, \"Patient overlap val/test!\"\n",
        "        print(\"Patient-level splits verified (no overlap if sets are non-empty).\")\n",
        "\n",
        "        # --- LDL Value Normalization ---\n",
        "        if not train_df.empty and 'LDL' in train_df.columns:\n",
        "            print(\"\\nNormalizing LDL values using StandardScaler...\")\n",
        "            ldl_scaler = StandardScaler()\n",
        "            # Fit the scaler ONLY on the training data's LDL values\n",
        "            train_df['LDL_scaled'] = ldl_scaler.fit_transform(train_df[['LDL']])\n",
        "\n",
        "            # Transform validation and test data using the FITTED scaler\n",
        "            if not val_df.empty:\n",
        "                val_df['LDL_scaled'] = ldl_scaler.transform(val_df[['LDL']])\n",
        "            else: # Add LDL_scaled column even if empty, for consistency\n",
        "                val_df['LDL_scaled'] = pd.Series(dtype='float64')\n",
        "\n",
        "            if not test_df.empty:\n",
        "                test_df['LDL_scaled'] = ldl_scaler.transform(test_df[['LDL']])\n",
        "            else:\n",
        "                test_df['LDL_scaled'] = pd.Series(dtype='float64')\n",
        "\n",
        "            print(\"LDL normalization complete.\")\n",
        "            print(\"Scaled LDL stats in train_df (should be mean~0, std~1):\")\n",
        "            from IPython.display import display # Ensure display is imported\n",
        "            display(train_df['LDL_scaled'].describe())\n",
        "\n",
        "            # Optional: Save the scaler\n",
        "            # import joblib\n",
        "            # scaler_filename = 'ldl_scaler_medgemma.joblib'\n",
        "            # joblib.dump(ldl_scaler, scaler_filename)\n",
        "            # print(f\"LDL scaler saved to {scaler_filename}\")\n",
        "        else:\n",
        "            print(\"Train DataFrame is empty or 'LDL' column missing. Skipping LDL normalization.\")\n",
        "else:\n",
        "    print(\"image_df is empty (from Cell 3). Skipping data splitting and LDL normalization.\")\n",
        "\n",
        "print(\"\\nCell 6: Data splitting and LDL normalization attempt complete.\")"
      ],
      "metadata": {
        "id": "WkxW5lpBt-7y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "2e805423-4fca-48f7-b90d-a6c7a5bd6156"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting data splitting for 973 image-LDL pairs...\n",
            "Total unique patients for splitting: 527\n",
            "Train set: 681 samples from 368 patients.\n",
            "Validation set: 145 samples from 79 patients.\n",
            "Test set: 147 samples from 80 patients.\n",
            "Patient-level splits verified (no overlap if sets are non-empty).\n",
            "\n",
            "Normalizing LDL values using StandardScaler...\n",
            "LDL normalization complete.\n",
            "Scaled LDL stats in train_df (should be mean~0, std~1):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "count    6.810000e+02\n",
              "mean     2.086763e-16\n",
              "std      1.000735e+00\n",
              "min     -2.303724e+00\n",
              "25%     -7.148712e-01\n",
              "50%     -4.975462e-02\n",
              "75%      6.670533e-01\n",
              "max      2.756859e+00\n",
              "Name: LDL_scaled, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LDL_scaled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6.810000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.086763e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000735e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-2.303724e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-7.148712e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-4.975462e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.670533e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.756859e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cell 6: Data splitting and LDL normalization attempt complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 5.1 (from user, now Cell 6.1): Check Unsloth tokenizer/model.processor\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n--- Sanity Check for Unsloth Components (Cell 6.1) ---\")\n",
        "if 'tokenizer' in locals() and tokenizer is not None:\n",
        "    print(f\"Unsloth tokenizer IS LOADED. Type: {type(tokenizer)}\")\n",
        "    if hasattr(tokenizer, 'image_processor') and tokenizer.image_processor is not None:\n",
        "        print(f\"  It has a tokenizer.image_processor of type: {type(tokenizer.image_processor)}\")\n",
        "    else:\n",
        "        print(\"  It does NOT have a direct `tokenizer.image_processor` attribute (or it's None).\")\n",
        "\n",
        "    if hasattr(model, 'processor') and model.processor is not None:\n",
        "        print(f\"Unsloth model.processor IS LOADED. Type: {type(model.processor)}\")\n",
        "        if hasattr(model.processor, 'image_processor') and model.processor.image_processor is not None:\n",
        "             print(f\"  model.processor has an image_processor component of type: {type(model.processor.image_processor)}\")\n",
        "    else:\n",
        "        print(\"  The model does NOT have a `model.processor` attribute (or it's None).\")\n",
        "\n",
        "    if not (hasattr(tokenizer, 'image_processor') and tokenizer.image_processor is not None) and \\\n",
        "       not (hasattr(model, 'processor') and model.processor is not None and hasattr(model.processor, 'image_processor')):\n",
        "        print(f\"  WARNING: No obvious image processor found. The model '{selected_model_name}' may be text-only.\")\n",
        "        print(\"  If your task requires image input, ensure you've selected a vision-language model and that Unsloth loads its image processor correctly.\")\n",
        "else:\n",
        "    print(\"Unsloth tokenizer IS NOT LOADED or is None.\")"
      ],
      "metadata": {
        "id": "ExnNlqz_uEpb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af2e05c6-8c6c-4133-b572-4732a5d30c5b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Sanity Check for Unsloth Components (Cell 6.1) ---\n",
            "Unsloth tokenizer IS LOADED. Type: <class 'transformers.models.gemma3.processing_gemma3.Gemma3Processor'>\n",
            "  It has a tokenizer.image_processor of type: <class 'transformers.models.gemma3.image_processing_gemma3.Gemma3ImageProcessor'>\n",
            "  The model does NOT have a `model.processor` attribute (or it's None).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c19e4e06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "941e0d87-1a5f-41e9-a782-b95a340bec0d"
      },
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 7: Custom PyTorch Dataset for DICOM Images and LDL (New Cell)\n",
        "# -----------------------------------------------------------------------------\n",
        "# Helper for printing messages only once during dataset iteration or training\n",
        "printed_messages_dataset = set()\n",
        "def print_once_dataset(message):\n",
        "    global printed_messages_dataset\n",
        "    if message not in printed_messages_dataset:\n",
        "        print(message)\n",
        "        printed_messages_dataset.add(message)\n",
        "\n",
        "import torchvision.transforms as T # Import T for transforms\n",
        "\n",
        "class MedGemmaVisionDataset(Dataset):\n",
        "    def __init__(self, dataframe, medgemma_tokenizer_processor, target_img_size_ref=(896, 896)):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dataframe (pd.DataFrame): DataFrame with 'image_path' and 'LDL_scaled' columns.\n",
        "            medgemma_tokenizer_processor: The multimodal processor from Unsloth (contains image_processor).\n",
        "            target_img_size_ref (tuple): Reference target image size, primarily for fallback.\n",
        "                                         The image_processor itself determines the actual processing.\n",
        "        \"\"\"\n",
        "        self.dataframe = dataframe\n",
        "        self.processor = medgemma_tokenizer_processor # This is the GemmaProcessor (or similar)\n",
        "        self.target_size_ref = target_img_size_ref # For fallback basic transforms\n",
        "\n",
        "        if not hasattr(self.processor, 'image_processor') or self.processor.image_processor is None:\n",
        "            raise ValueError(\"The provided processor must have a valid 'image_processor' attribute for MedGemma.\")\n",
        "\n",
        "        # Basic image transforms (fallback if image_processor fails for an image)\n",
        "        self.basic_transforms = T.Compose([\n",
        "            T.Resize(self.target_size_ref),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Imagenet stats\n",
        "        ])\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def load_and_preprocess_dicom(self, dicom_path):\n",
        "        try:\n",
        "            dicom_file = pydicom.dcmread(dicom_path)\n",
        "            pixel_array = dicom_file.pixel_array\n",
        "\n",
        "            # Normalize pixel data to 0-255 and ensure 3 channels (RGB)\n",
        "            # This is a common pre-step before PIL conversion for many image processors\n",
        "            if pixel_array.dtype != np.uint8:\n",
        "                pixel_array = pixel_array.astype(np.float32)\n",
        "                min_val, max_val = np.min(pixel_array), np.max(pixel_array)\n",
        "                if max_val > min_val:\n",
        "                    pixel_array = (pixel_array - min_val) / (max_val - min_val) * 255.0\n",
        "                else: # Handle case where all pixels are the same\n",
        "                    pixel_array = np.zeros_like(pixel_array)\n",
        "                pixel_array = pixel_array.astype(np.uint8)\n",
        "\n",
        "            if pixel_array.ndim == 2: # Grayscale\n",
        "                pil_image = Image.fromarray(pixel_array).convert('RGB')\n",
        "            elif pixel_array.ndim == 3 and pixel_array.shape[-1] == 1: # Grayscale with channel dim\n",
        "                pil_image = Image.fromarray(pixel_array.squeeze(-1)).convert('RGB')\n",
        "            elif pixel_array.ndim == 3 and pixel_array.shape[-1] == 3: # RGB\n",
        "                pil_image = Image.fromarray(pixel_array)\n",
        "            elif pixel_array.ndim == 3 and pixel_array.shape[-1] == 4: # RGBA\n",
        "                pil_image = Image.fromarray(pixel_array).convert('RGB')\n",
        "            else:\n",
        "                print_once_dataset(f\"Warning: Unsupported DICOM pixel array shape {pixel_array.shape} for {dicom_path}. Trying to convert.\")\n",
        "                # Attempt to make it a 2D grayscale image if possible\n",
        "                if pixel_array.ndim > 2 : pixel_array = pixel_array[...,0] # take first channel or slice\n",
        "                if pixel_array.ndim > 2 : pixel_array = pixel_array[0] # take first frame\n",
        "                pil_image = Image.fromarray(pixel_array.astype(np.uint8)).convert('RGB')\n",
        "\n",
        "\n",
        "            # Use MedGemma's image_processor\n",
        "            # It expects a PIL Image or list of PIL Images.\n",
        "            # It handles resizing, normalization, and tensor conversion according to MedGemma's needs.\n",
        "            processed_output = self.processor.image_processor(images=pil_image, return_tensors=\"pt\")\n",
        "            pixel_values = processed_output.pixel_values.squeeze(0) # Remove batch dim\n",
        "            return pixel_values\n",
        "\n",
        "        except Exception as e:\n",
        "            print_once_dataset(f\"Error processing DICOM {dicom_path} with image_processor: {e}. Applying basic fallback.\")\n",
        "            # Fallback: create a dummy black image if processing fails\n",
        "            try:\n",
        "                # Try to load with PIL directly for basic transform\n",
        "                pil_image_fallback = Image.open(dicom_path).convert(\"RGB\") # This might fail for some DICOMs\n",
        "                return self.basic_transforms(pil_image_fallback)\n",
        "            except Exception as e_fallback:\n",
        "                print_once_dataset(f\"Fallback PIL loading also failed for {dicom_path}: {e_fallback}. Returning zero tensor.\")\n",
        "                return torch.zeros((3, self.target_size_ref[0], self.target_size_ref[1]))\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        image_path = row['image_path']\n",
        "        ldl_scaled = row['LDL_scaled'] # Target variable\n",
        "\n",
        "        pixel_values = self.load_and_preprocess_dicom(image_path)\n",
        "        target_ldl_scaled = torch.tensor(ldl_scaled, dtype=torch.float32)\n",
        "\n",
        "        return {\n",
        "            \"pixel_values\": pixel_values,\n",
        "            \"labels\": target_ldl_scaled.unsqueeze(0) # Ensure target is (1,) for MSELoss\n",
        "        }\n",
        "\n",
        "# --- Create Datasets ---\n",
        "# `tokenizer` from Cell 0.3 is MedGemma's processor\n",
        "# `TARGET_SIZE_FOR_IMAGES` from Cell 5 is a reference\n",
        "if 'train_df' in locals() and not train_df.empty and 'tokenizer' in locals() and tokenizer is not None:\n",
        "    train_dataset = MedGemmaVisionDataset(train_df, tokenizer, TARGET_SIZE_FOR_IMAGES)\n",
        "    print(f\"Train dataset created with {len(train_dataset)} samples.\")\n",
        "else:\n",
        "    train_dataset = None\n",
        "    print(\"Could not create train_dataset. Check train_df and tokenizer.\")\n",
        "\n",
        "if 'val_df' in locals() and not val_df.empty and 'tokenizer' in locals() and tokenizer is not None:\n",
        "    val_dataset = MedGemmaVisionDataset(val_df, tokenizer, TARGET_SIZE_FOR_IMAGES)\n",
        "    print(f\"Validation dataset created with {len(val_dataset)} samples.\")\n",
        "else:\n",
        "    val_dataset = None\n",
        "    print(\"Could not create val_dataset. Check val_df and tokenizer.\")\n",
        "\n",
        "# Example: Fetch one item to test\n",
        "if train_dataset:\n",
        "    print(\"\\nSample from train_dataset:\")\n",
        "    try:\n",
        "        sample = train_dataset[0]\n",
        "        for key, val in sample.items():\n",
        "            print(f\"  {key}: shape {val.shape}, dtype {val.dtype}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching sample from train_dataset: {e}\")\n",
        "        print(\"This might indicate issues with DICOM loading or processing in your dataset.\")\n",
        "\n",
        "print(\"\\nCell 7: MedGemmaVisionDataset class defined and datasets instantiated.\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset created with 681 samples.\n",
            "Validation dataset created with 145 samples.\n",
            "\n",
            "Sample from train_dataset:\n",
            "  pixel_values: shape torch.Size([3, 896, 896]), dtype torch.float32\n",
            "  labels: shape torch.Size([1]), dtype torch.float32\n",
            "\n",
            "Cell 7: MedGemmaVisionDataset class defined and datasets instantiated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard PyTorch collate_fn should work if items are already tensors.\n",
        "def vision_collate_fn(batch):\n",
        "    pixel_values = torch.stack([item['pixel_values'] for item in batch])\n",
        "    labels = torch.stack([item['labels'] for item in batch])\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
        "\n",
        "BATCH_SIZE = 8 # Adjust based on GPU memory (e.g., 4, 8, 16)\n",
        "\n",
        "if train_dataset:\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        collate_fn=vision_collate_fn, # Use custom collate\n",
        "        num_workers=2, # Use multiple workers for faster data loading if not on Windows/debugging\n",
        "        pin_memory=True if torch.cuda.is_available() else False\n",
        "    )\n",
        "    print(f\"\\nTrain DataLoader created. Batches per epoch: {len(train_loader)}\")\n",
        "else:\n",
        "    train_loader = None\n",
        "\n",
        "if val_dataset:\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False, # No need to shuffle validation data\n",
        "        collate_fn=vision_collate_fn,\n",
        "        num_workers=2,\n",
        "        pin_memory=True if torch.cuda.is_available() else False\n",
        "    )\n",
        "    print(f\"Validation DataLoader created. Batches per epoch: {len(val_loader)}\")\n",
        "else:\n",
        "    val_loader = None\n",
        "\n",
        "# Test one batch from train_loader\n",
        "if train_loader:\n",
        "    print(\"\\nSample batch from train_loader:\")\n",
        "    try:\n",
        "        batch_sample = next(iter(train_loader))\n",
        "        for key, val in batch_sample.items():\n",
        "            print(f\"  {key}: shape {val.shape}, dtype {val.dtype}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching batch from train_loader: {e}\")\n",
        "\n",
        "print(\"\\nCell 8: DataLoaders created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05QUEpMHHP8M",
        "outputId": "299f0ac6-0d54-4a53-e881-d36c252f5ec6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train DataLoader created. Batches per epoch: 86\n",
            "Validation DataLoader created. Batches per epoch: 19\n",
            "\n",
            "Sample batch from train_loader:\n",
            "  pixel_values: shape torch.Size([8, 3, 896, 896]), dtype torch.float32\n",
            "  labels: shape torch.Size([8, 1]), dtype torch.float32\n",
            "\n",
            "Cell 8: DataLoaders created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard PyTorch collate_fn should work if items are already tensors.\n",
        "# Cell 9: Training Setup (Optimizer, Loss, Learning Rate) - MODIFIED\n",
        "\"\"\"\n",
        "import torch.optim as optim\n",
        "\n",
        "LEARNING_RATE = 5e-5 # Common starting point for LoRA fine-tuning. May need adjustment.\n",
        "EPOCHS = 10 # Start with a moderate number, e.g., 5-20.\n",
        "WEIGHT_DECAY = 0.01\n",
        "\n",
        "if regressor_model is not None: # Ensure the model was created in Cell 0.5\n",
        "    optimizer = optim.AdamW(regressor_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # --- STRATEGY 1: Attempt to cast the entire regressor_model to bfloat16 ---\n",
        "    # This assumes `regressor_model` is already on the correct `device` (e.g., 'cuda')\n",
        "    # And `model_dtype` (e.g. torch.bfloat16) should be what Unsloth set for the base model.\n",
        "\n",
        "    # Get the dtype from the Unsloth-loaded base model component within regressor_model\n",
        "    # This is the most reliable source for the target dtype.\n",
        "    if hasattr(regressor_model, 'medgemma_model') and hasattr(regressor_model.medgemma_model, 'dtype'):\n",
        "        target_model_dtype = regressor_model.medgemma_model.dtype\n",
        "        print(f\"\\nTarget dtype for model components (from base Unsloth model): {target_model_dtype}\")\n",
        "\n",
        "        if target_model_dtype == torch.bfloat16:\n",
        "            print(f\"Attempting to cast entire regressor_model and its submodules to {target_model_dtype} (Strategy 1)...\")\n",
        "            try:\n",
        "                # This will attempt to cast all parameters and buffers.\n",
        "                regressor_model = regressor_model.to(dtype=target_model_dtype)\n",
        "                print(\"Casting of entire regressor_model to bfloat16 attempted.\")\n",
        "\n",
        "                # Optional: Verification - Check dtypes of some parameters\n",
        "                # print(\"Verifying some parameter dtypes after full model cast:\")\n",
        "                # for name, param in regressor_model.named_parameters():\n",
        "                #     if \"lora\" in name.lower() or \"regression_head\" in name.lower() or \"bias\" in name.lower(): # Check some key ones\n",
        "                #         if param.numel() > 0: # Only print if param is not empty\n",
        "                #             print(f\"  Param: {name[:60]}..., Dtype: {param.dtype}, Device: {param.device}\")\n",
        "                #         break # Just check a few to avoid too much output\n",
        "            except Exception as e_cast_full:\n",
        "                print(f\"ERROR during full regressor_model.to(dtype={target_model_dtype}): {e_cast_full}\")\n",
        "                print(\"Full model cast failed. Proceeding without it, relying on input tensor casting in training loop.\")\n",
        "        else:\n",
        "            print(f\"Base model dtype is {target_model_dtype}, not bfloat16. Skipping full model bfloat16 cast strategy.\")\n",
        "    else:\n",
        "        print(\"\\nCould not reliably determine target_model_dtype from regressor_model.medgemma_model.dtype.\")\n",
        "        print(\"Skipping full model cast strategy. Will rely on input tensor casting in training loop.\")\n",
        "    # --- END OF STRATEGY 1 ---\n",
        "\n",
        "    print(f\"\\nOptimizer: AdamW, LR: {LEARNING_RATE}, Weight Decay: {WEIGHT_DECAY}\")\n",
        "    print(f\"Loss Function: MSELoss\")\n",
        "    print(f\"Training for {EPOCHS} epochs.\")\n",
        "else:\n",
        "    print(\"CRITICAL ERROR: regressor_model is None (was not created in Cell 0.5). Cannot set up optimizer and loss.\")\n",
        "    optimizer = None\n",
        "    criterion = None\n",
        "\"\"\"\n",
        "# Cell 9: Training Setup (Optimizer, Loss, Learning Rate) - REVISED\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "LEARNING_RATE = 5e-5\n",
        "EPOCHS = 10\n",
        "WEIGHT_DECAY = 0.01\n",
        "\n",
        "if regressor_model is not None:\n",
        "    optimizer = optim.AdamW(regressor_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # --- Attempt to ensure all components of regressor_model are bfloat16 ---\n",
        "    # The regressor_model should already be on the correct device from Cell 0.5\n",
        "\n",
        "    # Get the target dtype from the base Unsloth model component\n",
        "    if hasattr(regressor_model, 'medgemma_model') and hasattr(regressor_model.medgemma_model, 'dtype'):\n",
        "        target_dtype_for_components = regressor_model.medgemma_model.dtype\n",
        "        print(f\"\\nTarget dtype for all model components: {target_dtype_for_components}\")\n",
        "\n",
        "        if target_dtype_for_components == torch.bfloat16:\n",
        "            print(f\"Attempting to ensure all components of regressor_model are on {target_dtype_for_components}...\")\n",
        "            try:\n",
        "                # This should cast all parameters and buffers of regressor_model,\n",
        "                # including the PEFT-adapted medgemma_model and the regression_head.\n",
        "                regressor_model = regressor_model.to(dtype=target_dtype_for_components)\n",
        "                print(\"Casting of entire regressor_model to bfloat16 completed.\")\n",
        "\n",
        "                # Verification: Check dtypes of LoRA layers and regression head\n",
        "                print(\"Verifying select parameter dtypes after full model cast:\")\n",
        "                for name, param in regressor_model.named_parameters():\n",
        "                    # Check LoRA weights (often contain 'lora_A' or 'lora_B')\n",
        "                    # and regression head weights\n",
        "                    if param.requires_grad and (\"lora\" in name.lower() or \"regression_head\" in name.lower()):\n",
        "                        if param.numel() > 0:\n",
        "                             print(f\"  Trainable Param: {name[:70]}..., Dtype: {param.dtype}, Device: {param.device}\")\n",
        "            except Exception as e_cast_all:\n",
        "                print(f\"ERROR during full regressor_model.to(dtype={target_dtype_for_components}): {e_cast_all}\")\n",
        "                print(\"Full model component casting failed. This might be the source of dtype mismatches.\")\n",
        "        else:\n",
        "            print(f\"Base model dtype is {target_dtype_for_components}, not bfloat16. Not forcing bfloat16 on all components.\")\n",
        "    else:\n",
        "        print(\"\\nCould not reliably determine target_dtype from regressor_model.medgemma_model.dtype for component casting.\")\n",
        "    # --- END OF COMPONENT CASTING ---\n",
        "\n",
        "    print(f\"\\nOptimizer: AdamW, LR: {LEARNING_RATE}, Weight Decay: {WEIGHT_DECAY}\")\n",
        "    print(f\"Loss Function: MSELoss\")\n",
        "    print(f\"Training for {EPOCHS} epochs.\")\n",
        "else:\n",
        "    print(\"CRITICAL ERROR: regressor_model is None. Cannot set up optimizer and loss.\")\n",
        "    optimizer = None\n",
        "    criterion = None"
      ],
      "metadata": {
        "id": "cSq1JoFRvFZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef3af3d9-7b25-4b00-dccf-919e257daa55"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Target dtype for all model components: torch.bfloat16\n",
            "Attempting to ensure all components of regressor_model are on torch.bfloat16...\n",
            "Casting of entire regressor_model to bfloat16 completed.\n",
            "Verifying select parameter dtypes after full model cast:\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: medgemma_model.base_model.model.model.vision_tower.vision_model.encode..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: regression_head.0.weight..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: regression_head.0.bias..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: regression_head.3.weight..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "  Trainable Param: regression_head.3.bias..., Dtype: torch.bfloat16, Device: cuda:0\n",
            "\n",
            "Optimizer: AdamW, LR: 5e-05, Weight Decay: 0.01\n",
            "Loss Function: MSELoss\n",
            "Training for 10 epochs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Training and Evaluation Loop - MODIFIED\n",
        "\n",
        "# Cell 10: Training and Evaluation Loop - MODIFIED\n",
        "\n",
        "# Cell 10: Training and Evaluation Loop - REVISED with torch.amp.autocast\n",
        "\n",
        "# Cell 10: Training and Evaluation Loop - REVISED with torch.amp.autocast\n",
        "\n",
        "import torch.amp # Import for autocast\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "PATIENCE_EPOCHS = 3\n",
        "\n",
        "printed_messages_train_loop = set()\n",
        "def print_once_train_loop(message):\n",
        "    global printed_messages_train_loop\n",
        "    if message not in printed_messages_train_loop:\n",
        "        print(message)\n",
        "        printed_messages_train_loop.add(message)\n",
        "\n",
        "if regressor_model is not None and train_loader is not None and val_loader is not None and optimizer is not None and criterion is not None:\n",
        "    print(f\"\\nStarting training on device: {device}...\")\n",
        "\n",
        "    # model_input_dtype is the dtype of our input activations, which we set to bfloat16\n",
        "    if hasattr(regressor_model, 'medgemma_model') and hasattr(regressor_model.medgemma_model, 'dtype'):\n",
        "        model_activation_dtype = regressor_model.medgemma_model.dtype\n",
        "    else:\n",
        "        print_once_train_loop(\"Warning: Could not directly get model_activation_dtype. Assuming torch.bfloat16.\")\n",
        "        model_activation_dtype = torch.bfloat16\n",
        "\n",
        "    print(f\"Model's activation dtype (for input pixel_values): {model_activation_dtype}\")\n",
        "    # Autocast will manage operations, potentially using float32 for matmuls if needed\n",
        "    # and then casting back to bfloat16 where appropriate if the model operates in bfloat16.\n",
        "    # If model_activation_dtype is bfloat16, autocast will try to keep things in bfloat16\n",
        "    # but will upcast for ops that require it (like matmul between bfloat16 and half).\n",
        "    autocast_dtype = torch.bfloat16 if model_activation_dtype == torch.bfloat16 and device.type == 'cuda' else torch.float16\n",
        "\n",
        "    print(f\"Using torch.amp.autocast with dtype: {autocast_dtype} on device type: {device.type}\")\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        regressor_model.train()\n",
        "        running_train_loss = 0.0\n",
        "        processed_batches_train = 0\n",
        "\n",
        "        for i, batch in enumerate(train_loader):\n",
        "            pixel_values_f32 = batch['pixel_values'].to(device)\n",
        "            labels_f32 = batch['labels'].to(device)\n",
        "\n",
        "            pixel_values_casted_for_input = pixel_values_f32.to(model_activation_dtype)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Use autocast for the forward pass and loss calculation\n",
        "            # This allows PyTorch to manage precision for operations like matmul.\n",
        "            # It will try to use `autocast_dtype` but can upcast to float32 for stability if needed.\n",
        "            with torch.amp.autocast(device_type=device.type, dtype=autocast_dtype, enabled=True):\n",
        "                try:\n",
        "                    predictions = regressor_model(pixel_values_casted_for_input)\n",
        "                    # Ensure predictions are float32 before loss with float32 labels if autocast doesn't do it\n",
        "                    # or if criterion is sensitive. MSELoss is usually robust.\n",
        "                    loss = criterion(predictions.to(torch.float32), labels_f32)\n",
        "                                    # ^ Casting predictions to float32 here for robust loss calculation\n",
        "                                    #   as autocast might output bfloat16/float16 predictions.\n",
        "\n",
        "                except Exception as e:\n",
        "                    print_once_train_loop(f\"ERROR during training forward pass (inside autocast) at batch {i}: {e}\")\n",
        "                    if \"expected scalar type\" in str(e).lower() or \"same dtype\" in str(e).lower():\n",
        "                        print_once_train_loop(f\"  Input pixel_values_casted_for_input dtype: {pixel_values_casted_for_input.dtype}\")\n",
        "                        if 'predictions' in locals() and isinstance(predictions, torch.Tensor):\n",
        "                             print_once_train_loop(f\"  Predictions (if formed) dtype: {predictions.dtype}\")\n",
        "                    # import traceback # Uncomment for full traceback if error is persistent\n",
        "                    # print_once_train_loop(traceback.format_exc())\n",
        "                    continue\n",
        "\n",
        "            # Gradient scaling is typically handled by Unsloth when using its Trainer\n",
        "            # or if you manage it manually. For a simple loop, direct backward() is often fine\n",
        "            # if not using a GradScaler. Unsloth's optimizations might already account for this.\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_train_loss += loss.item()\n",
        "            processed_batches_train += 1\n",
        "\n",
        "            if (i + 1) % 20 == 0 or (i + 1) == len(train_loader):\n",
        "                print(f\"Epoch [{epoch+1}/{EPOCHS}], Batch [{i+1}/{len(train_loader)}], Train Loss: {loss.item():.4f}\")\n",
        "\n",
        "        epoch_train_loss = running_train_loss / processed_batches_train if processed_batches_train > 0 else 0.0\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        print(f\"Epoch [{epoch+1}/{EPOCHS}] - Average Training Loss: {epoch_train_loss:.4f}\")\n",
        "\n",
        "        # Validation phase\n",
        "        regressor_model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        processed_batches_val = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_val in val_loader:\n",
        "                pixel_values_f32_val = batch_val['pixel_values'].to(device)\n",
        "                labels_f32_val = batch_val['labels'].to(device)\n",
        "                pixel_values_casted_for_input_val = pixel_values_f32_val.to(model_activation_dtype)\n",
        "\n",
        "                with torch.amp.autocast(device_type=device.type, dtype=autocast_dtype, enabled=True):\n",
        "                    try:\n",
        "                        predictions_val = regressor_model(pixel_values_casted_for_input_val)\n",
        "                        loss_val = criterion(predictions_val.to(torch.float32), labels_f32_val)\n",
        "                    except Exception as e_val:\n",
        "                        print_once_train_loop(f\"ERROR during validation forward pass (inside autocast): {e_val}\")\n",
        "                        continue\n",
        "\n",
        "                running_val_loss += loss_val.item()\n",
        "                processed_batches_val +=1\n",
        "\n",
        "        epoch_val_loss = running_val_loss / processed_batches_val if processed_batches_val > 0 else 0.0\n",
        "        val_losses.append(epoch_val_loss)\n",
        "        print(f\"Epoch [{epoch+1}/{EPOCHS}] - Average Validation Loss: {epoch_val_loss:.4f}\")\n",
        "\n",
        "        if epoch_val_loss < best_val_loss:\n",
        "            best_val_loss = epoch_val_loss\n",
        "            patience_counter = 0\n",
        "            save_dir = \"./best_model_checkpoint\"\n",
        "            if not os.path.exists(save_dir): os.makedirs(save_dir)\n",
        "            if hasattr(regressor_model, 'medgemma_model') and hasattr(regressor_model.medgemma_model, 'save_pretrained'):\n",
        "                regressor_model.medgemma_model.save_pretrained(os.path.join(save_dir, \"lora_adapters\"))\n",
        "            if hasattr(regressor_model, 'regression_head'):\n",
        "                torch.save(regressor_model.regression_head.state_dict(), os.path.join(save_dir, \"regression_head.pth\"))\n",
        "            print(f\"Validation loss improved to {best_val_loss:.4f}. Saved best model components at epoch {epoch+1}.\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        print(\"-\" * 30)\n",
        "        if patience_counter >= PATIENCE_EPOCHS:\n",
        "            print(f\"Early stopping triggered after {PATIENCE_EPOCHS} epochs without improvement on validation loss.\")\n",
        "            break\n",
        "    print(\"Training complete.\")\n",
        "else:\n",
        "    print(\"Cannot start training. One or more critical components (model, dataloaders, optimizer, criterion) are missing.\")\n",
        "\n",
        "# Plotting (same as before)\n",
        "if train_losses and val_losses:\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss (MSE)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "IvYqs994WWHB",
        "outputId": "523b6172-39db-481f-ce1a-2876505b5924"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training on device: cuda...\n",
            "Model's activation dtype (for input pixel_values): torch.bfloat16\n",
            "Using torch.amp.autocast with dtype: torch.bfloat16 on device type: cuda\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Current CUDA Device does not support bfloat16. Please switch dtype to float16.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a864501e9aa8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;31m# This allows PyTorch to manage precision for operations like matmul.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m# It will try to use `autocast_dtype` but can upcast to float32 for stability if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautocast_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_values_casted_for_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, device_type, dtype, enabled, cache_enabled)\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bf16_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             ):\n\u001b[0;32m--> 322\u001b[0;31m                 raise RuntimeError(\n\u001b[0m\u001b[1;32m    323\u001b[0m                     \u001b[0;34m\"Current CUDA Device does not support bfloat16. Please switch dtype to float16.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m                 )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Current CUDA Device does not support bfloat16. Please switch dtype to float16."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The best model was saved during training. Here's how you might save the *final* model\n",
        "# if you didn't use early stopping or want the model from the last epoch.\n",
        "\n",
        "final_model_save_path = \"./final_model_checkpoint\"\n",
        "if regressor_model is not None and os.path.exists(\"./best_model_checkpoint\"): # Check if best model was saved\n",
        "    print(f\"\\nBest model was saved during training to ./best_model_checkpoint\")\n",
        "    print(\"To use the best model, load from './best_model_checkpoint/lora_adapters' and './best_model_checkpoint/regression_head.pth'\")\n",
        "elif regressor_model is not None: # Save final model if no best model path exists (e.g. early stopping not triggered or not implemented fully)\n",
        "    if not os.path.exists(final_model_save_path): os.makedirs(final_model_save_path)\n",
        "    print(f\"\\nSaving final model to {final_model_save_path}...\")\n",
        "    # Save LoRA adapters of the base MedGemma model\n",
        "    regressor_model.medgemma_model.save_pretrained(os.path.join(final_model_save_path, \"lora_adapters\"))\n",
        "    # Save the state of the regression head\n",
        "    torch.save(regressor_model.regression_head.state_dict(), os.path.join(final_model_save_path, \"regression_head.pth\"))\n",
        "    print(f\"Final LoRA adapters saved to {os.path.join(final_model_save_path, 'lora_adapters')}\")\n",
        "    print(f\"Final regression head state saved to {os.path.join(final_model_save_path, 'regression_head.pth')}\")\n",
        "else:\n",
        "    print(\"\\nNo model to save or best model already indicated.\")\n",
        "\n",
        "\n",
        "# --- How to load the saved (best or final) model for inference ---\n",
        "# This demonstrates loading the components back.\n",
        "\n",
        "# 1. Define the path to your saved components (e.g., best model)\n",
        "saved_lora_path = \"./best_model_checkpoint/lora_adapters\" # Or final_model_save_path + \"/lora_adapters\"\n",
        "saved_head_path = \"./best_model_checkpoint/regression_head.pth\" # Or final_model_save_path + \"/regression_head.pth\"\n",
        "\n",
        "if os.path.exists(saved_lora_path) and os.path.exists(saved_head_path) and vision_feature_dim is not None:\n",
        "    print(f\"\\n--- Example: Loading saved model components from {saved_lora_path} and {saved_head_path} ---\")\n",
        "    # A. Load the base MedGemma model (without PEFT initially, or it will try to load adapters from original HF name)\n",
        "    #    It's often cleaner to load the base and then apply PEFT adapters.\n",
        "    #    However, Unsloth's `from_pretrained` on a PEFT saved path should work.\n",
        "\n",
        "    print(f\"Loading base MedGemma model ({selected_model_name}) and then applying saved LoRA adapters from {saved_lora_path}...\")\n",
        "\n",
        "    loaded_base_model, loaded_tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name=selected_model_name, # Start with the original base model name\n",
        "        max_seq_length=2048,\n",
        "        dtype=None,\n",
        "        load_in_4bit=True,\n",
        "        # token = \"hf_...\"\n",
        "    )\n",
        "\n",
        "    # Now, apply the saved LoRA adapters\n",
        "    # Important: The `PeftModel.from_pretrained` expects the *base model* and the path to adapters.\n",
        "    from peft import PeftModel\n",
        "    loaded_peft_medgemma_model = PeftModel.from_pretrained(loaded_base_model, saved_lora_path)\n",
        "    print(\"PEFT MedGemma model with saved LoRA adapters loaded.\")\n",
        "\n",
        "    # B. Instantiate your RegressorModel wrapper with the loaded PEFT MedGemma\n",
        "    loaded_regressor_model = MedGemmaVisionRegressor(loaded_peft_medgemma_model, vision_feature_dim)\n",
        "\n",
        "    # C. Load the state_dict for the regression head\n",
        "    loaded_regressor_model.regression_head.load_state_dict(torch.load(saved_head_path, map_location=device))\n",
        "    print(\"Regression head state loaded.\")\n",
        "\n",
        "    loaded_regressor_model.to(device)\n",
        "    loaded_regressor_model.eval() # Set to evaluation mode\n",
        "    print(\"Complete RegressorModel loaded and ready for inference.\")\n",
        "\n",
        "    # Example inference (requires a sample from val_loader or test_loader)\n",
        "    if val_loader:\n",
        "        try:\n",
        "            sample_batch_inference = next(iter(val_loader))\n",
        "            pixel_values_inf = sample_batch_inference['pixel_values'].to(device)\n",
        "            labels_inf = sample_batch_inference['labels'].to(device)\n",
        "            with torch.no_grad():\n",
        "                predictions_inf = loaded_regressor_model(pixel_values_inf)\n",
        "            print(f\"\\nSample inference output shape: {predictions_inf.shape}\")\n",
        "            # You would then unscale predictions using ldl_scaler.inverse_transform()\n",
        "            if ldl_scaler:\n",
        "                 predicted_ldl_original_scale = ldl_scaler.inverse_transform(predictions_inf.cpu().numpy())\n",
        "                 actual_ldl_original_scale = ldl_scaler.inverse_transform(labels_inf.cpu().numpy())\n",
        "                 print(f\"Sample predictions (original scale): {predicted_ldl_original_scale[:5].flatten()}\")\n",
        "                 print(f\"Sample actuals (original scale):    {actual_ldl_original_scale[:5].flatten()}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during sample inference with loaded model: {e}\")\n",
        "else:\n",
        "    print(\"\\nSkipping demonstration of loading model as saved paths or vision_feature_dim not found.\")\n",
        "\n",
        "\n",
        "print(\"\\nCell 11: Model saving and loading example complete.\")\n",
        "print(\"\\n--- End of Script ---\")"
      ],
      "metadata": {
        "id": "VbHPLQdsWa2c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}