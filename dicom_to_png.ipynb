{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1eTHxBMjEXnSgSviGo2Jf3Q69epDNCKYm",
      "authorship_tag": "ABX9TyOgjf3J0kL0boUP05ze0XUi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ravikrishnan05/PrediscanMedtech_project/blob/main/dicom_to_png.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WoA74JthMEk",
        "outputId": "7104a4cd-8fd8-4579-fc41-6ab848646e8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List the contents of your mounted drive to find the shared drive\n",
        "!ls /content/drive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jysQzh1thj8z",
        "outputId": "42b559e4-d161-4d9f-8673-95de5bc2ab87"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# List the contents of your mounted drive to find the shared drive directory\n",
        "!ls /content/drive/MyDrive/retinal_photography"
      ],
      "metadata": {
        "id": "nbAnCGHZjjSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39255042-0051-484e-b39b-ad3738b44b62"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            " cfp   ir\t\t      manifest.gsheet   Selected_1000_Images\n",
            " faf  'manifest (1).gsheet'   manifest.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/retinal_photography/'manifest (1).gsheet'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRzsfcY_lMxr",
        "outputId": "74224978-1986-4492-daa4-3be56e0d21d5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/MyDrive/retinal_photography/manifest (1).gsheet'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive\n",
        " # drive.mount('/content/drive') # Only need if not already mounted\n",
        "\n",
        "# --- CONFIGURATION: UPDATED PATH & SEPARATOR ---\n",
        "\n",
        "# Path to your TSV file on Google Drive\n",
        "# Check if manifest.tsv is indeed the file with the columns you showed earlier!\n",
        "data_file_path = '/content/drive/MyDrive/retinal_photography/manifest.tsv'\n",
        "SEPARATOR = '\\t' # Use '\\t' for TSV, or ',' for CSV\n",
        "\n",
        "# --- END OF CONFIGURATION ---\n",
        "\n",
        "\n",
        "def print_header(title):\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\" {title.upper()} \".center(50, \"=\"))\n",
        "    print(\"=\"*50)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"Attempting to load data from: {data_file_path}\")\n",
        "    try:\n",
        "         # NOTE the sep=SEPARATOR parameter here\n",
        "        df = pd.read_csv(data_file_path, sep=SEPARATOR)\n",
        "        # Check if 'filepath' column exists, crucial for path logic later\n",
        "        if 'filepath' not in df.columns:\n",
        "             print(f\"\\nERROR: Column 'filepath' not found in {data_file_path}. Columns are:\")\n",
        "             print(df.columns.tolist())\n",
        "             exit()\n",
        "        # Ensure all filepaths start with the expected base, fix if the TSV is different\n",
        "        # The code expects /retinal_photography/cfp/... based on your first example\n",
        "        if not str(df['filepath'].iloc[0]).startswith('/retinal_photography/'):\n",
        "             print(\"\\nWARNING: Filepaths do not start with '/retinal_photography/'. Adapting...\")\n",
        "             # Add adapter logic here if needed, or print error\n",
        "             print(f\"Example path: {df['filepath'].iloc[0]}\")\n",
        "             # For now, we'll assume the original code's path replacement logic is sufficient\n",
        "             # but the analysis below might look slightly off if paths are weird.\n",
        "\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"\\nERROR: The file was not found at: {data_file_path}\")\n",
        "        exit()\n",
        "    except Exception as e:\n",
        "         print(f\"\\nERROR loading file. Is it really a TSV? Error: {e}\")\n",
        "         exit()\n",
        "\n",
        "\n",
        "    print(f\"\\nSuccessfully loaded the file. First 5 rows head:\\n{df.head()}\")\n",
        "    print(\"\\nColumns found:\", df.columns.tolist())\n",
        "\n",
        "\n",
        "    print_header(\"Overall Summary\")\n",
        "    total_files = len(df)\n",
        "     # Check if column exists before using it\n",
        "    unique_participants = df['participant_id'].nunique() if 'participant_id' in df.columns else 'N/A'\n",
        "    print(f\"Total number of DICOM file entries: {total_files}\")\n",
        "    print(f\"Total number of unique participants: {unique_participants}\")\n",
        "\n",
        "    if 'imaging' in df.columns:\n",
        "        print_header(\"Distribution by Imaging Type\")\n",
        "        print(df['imaging'].value_counts().to_string())\n",
        "\n",
        "     # Verification by Filepath always works\n",
        "    print(\"\\n--- Verification by Filepath (cfp/faf/ir) ---\")\n",
        "    df['folder_type'] = df['filepath'].apply(lambda x: 'cfp' if '/cfp/' in str(x) else ('faf' if '/faf/' in str(x) else ('ir' if '/ir/' in str(x) else 'unknown')))\n",
        "    print(df['folder_type'].value_counts().to_string())\n",
        "\n",
        "\n",
        "    if 'manufacturer' in df.columns:\n",
        "        print_header(\"Distribution by Manufacturer\")\n",
        "        print(df['manufacturer'].value_counts().to_string())\n",
        "\n",
        "    if 'laterality' in df.columns:\n",
        "        print_header(\"Distribution by Laterality\")\n",
        "        print(df['laterality'].value_counts().to_string())\n",
        "\n",
        "    if 'height' in df.columns and 'width' in df.columns:\n",
        "        print_header(\"Summary of Image Dimensions (Height/Width)\")\n",
        "        print(df[['height', 'width']].describe().round(0))\n",
        "    print(\"\\nAnalysis Complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deNjKvsImGNS",
        "outputId": "24a4a6a0-b0f0-4c73-933a-a67e15aa73a9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to load data from: /content/drive/MyDrive/retinal_photography/manifest.tsv\n",
            "\n",
            "Successfully loaded the file. First 5 rows head:\n",
            "   participant_id manufacturer manufacturers_model_name laterality  \\\n",
            "0            1001        iCare                    Eidon          L   \n",
            "1            1001        iCare                    Eidon          R   \n",
            "2            1001        iCare                    Eidon          L   \n",
            "3            1001        iCare                    Eidon          R   \n",
            "4            1001        iCare                    Eidon          L   \n",
            "\n",
            "  anatomic_region            imaging  height  width  color_channel_dimension  \\\n",
            "0          Mosaic  Color Photography    1836   3293                        3   \n",
            "1          Mosaic  Color Photography    1837   3314                        3   \n",
            "2          Macula  Color Photography    3288   3680                        3   \n",
            "3          Macula  Color Photography    3288   3680                        3   \n",
            "4           Nasal  Color Photography    3288   3680                        3   \n",
            "\n",
            "                                  sop_instance_uid  \\\n",
            "0  1.2.826.0.1.3680043.8.641.1.20230809.2044.20521   \n",
            "1  1.2.826.0.1.3680043.8.641.1.20230809.2032.60283   \n",
            "2   1.2.826.0.1.3680043.8.641.1.20230809.2050.9281   \n",
            "3  1.2.826.0.1.3680043.8.641.1.20230809.2041.31942   \n",
            "4  1.2.826.0.1.3680043.8.641.1.20230809.2054.10612   \n",
            "\n",
            "                                            filepath  \n",
            "0  /retinal_photography/cfp/icare_eidon/1001/1001...  \n",
            "1  /retinal_photography/cfp/icare_eidon/1001/1001...  \n",
            "2  /retinal_photography/cfp/icare_eidon/1001/1001...  \n",
            "3  /retinal_photography/cfp/icare_eidon/1001/1001...  \n",
            "4  /retinal_photography/cfp/icare_eidon/1001/1001...  \n",
            "\n",
            "Columns found: ['participant_id', 'manufacturer', 'manufacturers_model_name', 'laterality', 'anatomic_region', 'imaging', 'height', 'width', 'color_channel_dimension', 'sop_instance_uid', 'filepath']\n",
            "\n",
            "==================================================\n",
            "================ OVERALL SUMMARY =================\n",
            "==================================================\n",
            "Total number of DICOM file entries: 43420\n",
            "Total number of unique participants: 1065\n",
            "\n",
            "==================================================\n",
            "========== DISTRIBUTION BY IMAGING TYPE ==========\n",
            "==================================================\n",
            "imaging\n",
            "Color Photography       23917\n",
            "Infrared Reflectance    17208\n",
            "Autofluorescence         2295\n",
            "\n",
            "--- Verification by Filepath (cfp/faf/ir) ---\n",
            "folder_type\n",
            "cfp    23915\n",
            "ir     17210\n",
            "faf     2295\n",
            "\n",
            "==================================================\n",
            "========== DISTRIBUTION BY MANUFACTURER ==========\n",
            "==================================================\n",
            "manufacturer\n",
            "Topcon        12958\n",
            "iCare         12853\n",
            "Zeiss          8705\n",
            "Optomed        4792\n",
            "Heidelberg     4112\n",
            "\n",
            "==================================================\n",
            "=========== DISTRIBUTION BY LATERALITY ===========\n",
            "==================================================\n",
            "laterality\n",
            "R    21905\n",
            "L    21515\n",
            "\n",
            "==================================================\n",
            "=== SUMMARY OF IMAGE DIMENSIONS (HEIGHT/WIDTH) ===\n",
            "==================================================\n",
            "        height    width\n",
            "count  43420.0  43420.0\n",
            "mean    1883.0   2243.0\n",
            "std      956.0   1175.0\n",
            "min      480.0    512.0\n",
            "25%      768.0    768.0\n",
            "50%     1934.0   2576.0\n",
            "75%     3288.0   3680.0\n",
            "max     3288.0   3680.0\n",
            "\n",
            "Analysis Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pydicom\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm.auto import tqdm # For the progress bar\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount drive if not already mounted.\n",
        "# If it's already mounted, this will just confirm it.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ensure all necessary packages are installed\n",
        "!pip install -q pandas pydicom pillow numpy tqdm\n",
        "\n",
        "# --- CONFIGURATION (VERIFIED AND CORRECT FOR YOUR SETUP) ---\n",
        "\n",
        "# 1. Path to your data file on Google Drive\n",
        "data_file_path = '/content/drive/MyDrive/retinal_photography/manifest.tsv'\n",
        "SEPARATOR = '\\t'\n",
        "\n",
        "# 2. The PARENT directory where 'retinal_photography' folder is.\n",
        "input_parent_dir = '/content/drive/MyDrive'\n",
        "output_parent_dir = '/content/drive/MyDrive'\n",
        "\n",
        "# 3. Define the source and target folder names for creating the new structure\n",
        "source_folder_name = 'retinal_photography'\n",
        "target_folder_name = 'retinal_photography_png' # Will be created at /content/drive/MyDrive/retinal_photography_png\n",
        "\n",
        "# --- END OF CONFIGURATION ---\n",
        "\n",
        "def convert_dicom_to_png(dicom_filepath, png_filepath):\n",
        "    \"\"\"Reads DICOM, converts pixel data, saves as high-quality PNG.\"\"\"\n",
        "    try:\n",
        "        ds = pydicom.dcmread(dicom_filepath)\n",
        "        pixel_array = ds.pixel_array\n",
        "\n",
        "        # Apply Windowing if available for better contrast in non-color (monochrome) images\n",
        "        if 'WindowCenter' in ds and 'WindowWidth' in ds and ds.PhotometricInterpretation != \"RGB\":\n",
        "            window_center = float(ds.WindowCenter)\n",
        "            window_width = float(ds.WindowWidth)\n",
        "            img_min = window_center - window_width / 2.0\n",
        "            img_max = window_center + window_width / 2.0\n",
        "            pixel_array = np.clip(pixel_array, img_min, img_max)\n",
        "\n",
        "        # Normalize pixel data to 8-bit range (0-255) for standard PNG saving\n",
        "        if pixel_array.dtype != np.uint8:\n",
        "            if np.max(pixel_array) > np.min(pixel_array):\n",
        "                pixel_array = pixel_array.astype(float)\n",
        "                pixel_array = (pixel_array - np.min(pixel_array)) / (np.max(pixel_array) - np.min(pixel_array))\n",
        "                pixel_array = (pixel_array * 255).astype(np.uint8)\n",
        "            else:\n",
        "                pixel_array = np.zeros_like(pixel_array, dtype=np.uint8)\n",
        "\n",
        "        image = Image.fromarray(pixel_array)\n",
        "        os.makedirs(os.path.dirname(png_filepath), exist_ok=True)\n",
        "        image.save(png_filepath, 'PNG')\n",
        "        return True, None\n",
        "    except FileNotFoundError:\n",
        "        return False, \"DICOM File Not Found at path\"\n",
        "    except Exception as e:\n",
        "        return False, str(e)\n",
        "\n",
        "\n",
        "# --- Main Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting DICOM to PNG conversion process...\")\n",
        "    try:\n",
        "        df = pd.read_csv(data_file_path, sep=SEPARATOR)\n",
        "    except Exception as e:\n",
        "        print(f\"FATAL ERROR: Could not load the manifest file: {e}\")\n",
        "        exit()\n",
        "\n",
        "    print(f\"Found {len(df)} files to process from the manifest.\")\n",
        "\n",
        "    # Create the main output directory to check for write permissions early\n",
        "    output_base_dir = os.path.join(output_parent_dir, target_folder_name)\n",
        "    try:\n",
        "        os.makedirs(output_base_dir, exist_ok=True)\n",
        "        print(f\"Output will be saved in: {output_base_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\"PERMISSION ERROR: Cannot create output directory '{output_base_dir}'.\")\n",
        "        print(\"Please ensure you have 'Editor' or 'Contributor' access to the Google Drive location.\")\n",
        "        exit()\n",
        "\n",
        "    success_count = 0\n",
        "    error_count = 0\n",
        "    failed_files = []\n",
        "\n",
        "    # Use tqdm for a live progress bar\n",
        "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Converting Files\"):\n",
        "        relative_filepath = str(row['filepath'])\n",
        "\n",
        "        if relative_filepath.startswith('/'):\n",
        "            relative_filepath = relative_filepath[1:]\n",
        "\n",
        "        # Construct the full path to the source DICOM\n",
        "        dicom_path = os.path.join(input_parent_dir, relative_filepath)\n",
        "\n",
        "        # Construct the full path for the destination PNG\n",
        "        target_relative_path = relative_filepath.replace(source_folder_name, target_folder_name, 1)\n",
        "        png_base_path, _ = os.path.splitext(target_relative_path)\n",
        "        png_relative_path_with_ext = png_base_path + '.png'\n",
        "        png_path = os.path.join(output_parent_dir, png_relative_path_with_ext)\n",
        "\n",
        "        # Perform the conversion\n",
        "        success, error_message = convert_dicom_to_png(dicom_path, png_path)\n",
        "\n",
        "        if success:\n",
        "            success_count += 1\n",
        "        else:\n",
        "            error_count += 1\n",
        "            failed_files.append((dicom_path, error_message))\n",
        "\n",
        "    print(\"\\n\\n--- CONVERSION COMPLETE ---\")\n",
        "    print(f\"Successfully converted: {success_count} files.\")\n",
        "    print(f\"Failed to convert: {error_count} files.\")\n",
        "    print(f\"All new PNG files are saved in the folder: '{output_base_dir}'\")\n",
        "\n",
        "    if error_count > 0:\n",
        "        print(\"\\n--- List of Failed Files ---\")\n",
        "        for f_path, reason in failed_files:\n",
        "            print(f\"- Path: {f_path}\\n  Reason: {reason}\\n\")"
      ],
      "metadata": {
        "id": "P3i5ozh5qDo2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}