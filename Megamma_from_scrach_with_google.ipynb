{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a4469a146a2420fbbb500f5a07417b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4cd9e10b62546f38c26ea9b3e5dc40f",
              "IPY_MODEL_d10e319c54914f50b11ac5acfce9060f",
              "IPY_MODEL_385c93fb65cc4c04a79178e89757b670"
            ],
            "layout": "IPY_MODEL_c9d10b15cca64191aac56be356eea9fc"
          }
        },
        "b4cd9e10b62546f38c26ea9b3e5dc40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8639d7b282ea4390822976662ffaa203",
            "placeholder": "​",
            "style": "IPY_MODEL_cc77c8366c3b4a98af63a2b98efff7e7",
            "value": "processor_config.json: 100%"
          }
        },
        "d10e319c54914f50b11ac5acfce9060f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4ec4ae1d8174ffb839cfcef28807b23",
            "max": 70,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbe278bc9ba743679c5e2a70197d199c",
            "value": 70
          }
        },
        "385c93fb65cc4c04a79178e89757b670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7c20dcb3af84712b6af8cc221bc6dbe",
            "placeholder": "​",
            "style": "IPY_MODEL_491543afe7f9451c93cb3024e28d47e9",
            "value": " 70.0/70.0 [00:00&lt;00:00, 7.25kB/s]"
          }
        },
        "c9d10b15cca64191aac56be356eea9fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8639d7b282ea4390822976662ffaa203": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc77c8366c3b4a98af63a2b98efff7e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4ec4ae1d8174ffb839cfcef28807b23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbe278bc9ba743679c5e2a70197d199c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7c20dcb3af84712b6af8cc221bc6dbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "491543afe7f9451c93cb3024e28d47e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d87ff41b5bc74d5a818e756bbbd6ebae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_634a89ab05e7414a84719db258fa1a12",
              "IPY_MODEL_46ef9e6a37d64916b712cfd6bd27e718",
              "IPY_MODEL_5e42e930be874650a578a8cd483d000b"
            ],
            "layout": "IPY_MODEL_50b3947b3bc143f99a10492c15674843"
          }
        },
        "634a89ab05e7414a84719db258fa1a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57f32ea3b9814de1b6951f75bc6d1bcb",
            "placeholder": "​",
            "style": "IPY_MODEL_662461f8cadd4482875abc9eae7a765c",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "46ef9e6a37d64916b712cfd6bd27e718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1cf2910784040d6a596f2cc55b872b2",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f576e84a25e645d386db78d3a0730be2",
            "value": 570
          }
        },
        "5e42e930be874650a578a8cd483d000b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a59fb3858fc4a5bb01dfc176b64ff0e",
            "placeholder": "​",
            "style": "IPY_MODEL_8cffab60c21c46a38ec4007e67e21d69",
            "value": " 570/570 [00:00&lt;00:00, 61.1kB/s]"
          }
        },
        "50b3947b3bc143f99a10492c15674843": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57f32ea3b9814de1b6951f75bc6d1bcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "662461f8cadd4482875abc9eae7a765c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1cf2910784040d6a596f2cc55b872b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f576e84a25e645d386db78d3a0730be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a59fb3858fc4a5bb01dfc176b64ff0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cffab60c21c46a38ec4007e67e21d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d06efde760d4d31843ba0cb7ab18b8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d156c5f2209d43e69247b2fdae2b67e5",
              "IPY_MODEL_6d69675ded87462b8f317774d972a96c",
              "IPY_MODEL_e419302173c24630a5d64a7868f5f1ac"
            ],
            "layout": "IPY_MODEL_7611ac6954af44ff9669dd05aa78996e"
          }
        },
        "d156c5f2209d43e69247b2fdae2b67e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61c5cfff8f284343a0384e777eee43df",
            "placeholder": "​",
            "style": "IPY_MODEL_ab00266a5212492a87065c974d5fd4b6",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6d69675ded87462b8f317774d972a96c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b291468c5e4845a59f7daf0066c553f5",
            "max": 1155389,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_539d2deef7ab4fa6ad8974edbe9e2de5",
            "value": 1155389
          }
        },
        "e419302173c24630a5d64a7868f5f1ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d487a266b6c34fe7914af7db3ffdd7ea",
            "placeholder": "​",
            "style": "IPY_MODEL_33366ba6c6d84a54bde37e034c70971c",
            "value": " 1.16M/1.16M [00:00&lt;00:00, 15.1MB/s]"
          }
        },
        "7611ac6954af44ff9669dd05aa78996e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61c5cfff8f284343a0384e777eee43df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab00266a5212492a87065c974d5fd4b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b291468c5e4845a59f7daf0066c553f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "539d2deef7ab4fa6ad8974edbe9e2de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d487a266b6c34fe7914af7db3ffdd7ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33366ba6c6d84a54bde37e034c70971c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35b385272a9c40e68810279f5a8a05cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31656c75189744698c9958c7701d89ba",
              "IPY_MODEL_20338b7fe27d45a1a1be6076fa1619e1",
              "IPY_MODEL_4fbf447ea26146329dc384c4d7d23b90"
            ],
            "layout": "IPY_MODEL_df9a9499d9f6407eb4ac6432eb4af3a0"
          }
        },
        "31656c75189744698c9958c7701d89ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76f7aeb5acb64dd29dd17e0d36cf3ba2",
            "placeholder": "​",
            "style": "IPY_MODEL_38d31d01fcec4b94b8311c12de0356f9",
            "value": "tokenizer.model: 100%"
          }
        },
        "20338b7fe27d45a1a1be6076fa1619e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23fbcbc628b44e8cb9644fab2a224ad6",
            "max": 4689074,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5712e062e88341b8b3739900c4e16a80",
            "value": 4689074
          }
        },
        "4fbf447ea26146329dc384c4d7d23b90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7368f44c58d647dbb6cf36ddefd0b8b6",
            "placeholder": "​",
            "style": "IPY_MODEL_dcd90484dcb2450a9680514df44b4c4e",
            "value": " 4.69M/4.69M [00:00&lt;00:00, 37.1MB/s]"
          }
        },
        "df9a9499d9f6407eb4ac6432eb4af3a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76f7aeb5acb64dd29dd17e0d36cf3ba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38d31d01fcec4b94b8311c12de0356f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23fbcbc628b44e8cb9644fab2a224ad6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5712e062e88341b8b3739900c4e16a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7368f44c58d647dbb6cf36ddefd0b8b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcd90484dcb2450a9680514df44b4c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bce86ab65bb249d3b63b700c97aa7fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6613e43ef6434c00b14ca15b45d2f2aa",
              "IPY_MODEL_8256e60a8a0d4f4c91ede2731d21a625",
              "IPY_MODEL_ef33d64b10414c36a88b9016139a991c"
            ],
            "layout": "IPY_MODEL_619e83688a6f4341b7de0de36566f34d"
          }
        },
        "6613e43ef6434c00b14ca15b45d2f2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7107887d0484de9b45613d2420e91bd",
            "placeholder": "​",
            "style": "IPY_MODEL_fdad4b04d84a42f08a0e8193c99af821",
            "value": "tokenizer.json: 100%"
          }
        },
        "8256e60a8a0d4f4c91ede2731d21a625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ade2abd16e34b4aa5095c45c150accd",
            "max": 33384570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ffaa71181eb4c0aae3aad3ff5969548",
            "value": 33384570
          }
        },
        "ef33d64b10414c36a88b9016139a991c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_274e7c7de4514d27bc78020e7fee24ef",
            "placeholder": "​",
            "style": "IPY_MODEL_190197ecfa8a42939349fdfeb8d9f332",
            "value": " 33.4M/33.4M [00:00&lt;00:00, 87.4MB/s]"
          }
        },
        "619e83688a6f4341b7de0de36566f34d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7107887d0484de9b45613d2420e91bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdad4b04d84a42f08a0e8193c99af821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ade2abd16e34b4aa5095c45c150accd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ffaa71181eb4c0aae3aad3ff5969548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "274e7c7de4514d27bc78020e7fee24ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "190197ecfa8a42939349fdfeb8d9f332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07175cfacb6e49c2a76cdc44ac0e68f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_248f01ee81044914b6d96a0a92b530bf",
              "IPY_MODEL_9721212601ee4007a9f3da7fac4a9400",
              "IPY_MODEL_c808c8b1a55d40329797192f0ad3a4bf"
            ],
            "layout": "IPY_MODEL_f43cca943bb54d2baa39d7b5b2e16771"
          }
        },
        "248f01ee81044914b6d96a0a92b530bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79183da6fb974a6db3093dafa3c17f09",
            "placeholder": "​",
            "style": "IPY_MODEL_34ce04a267d34b648347ef63acf81658",
            "value": "added_tokens.json: 100%"
          }
        },
        "9721212601ee4007a9f3da7fac4a9400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d48dddb73754bd3b8ff1f6572dc0b3d",
            "max": 35,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5a6cd8a8e674bffabce66003f0e328a",
            "value": 35
          }
        },
        "c808c8b1a55d40329797192f0ad3a4bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ca1c16e820047b1a08cf0d54e9c9088",
            "placeholder": "​",
            "style": "IPY_MODEL_e40506218cf94d2ea7c270dad3b2ba8a",
            "value": " 35.0/35.0 [00:00&lt;00:00, 2.28kB/s]"
          }
        },
        "f43cca943bb54d2baa39d7b5b2e16771": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79183da6fb974a6db3093dafa3c17f09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34ce04a267d34b648347ef63acf81658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d48dddb73754bd3b8ff1f6572dc0b3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5a6cd8a8e674bffabce66003f0e328a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ca1c16e820047b1a08cf0d54e9c9088": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e40506218cf94d2ea7c270dad3b2ba8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e511d20d7a194214b2aa755563e19d9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04422a8cadd44b7db068b5ea29392f0d",
              "IPY_MODEL_540b9d861acf4fad85cd730e2ea9d74c",
              "IPY_MODEL_d8aa2a2e2a6a442e8570562ac14a300e"
            ],
            "layout": "IPY_MODEL_f8af64d2485d485c8b35acf2abb9761f"
          }
        },
        "04422a8cadd44b7db068b5ea29392f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eee1b6c518d14f959b6882a50c2d1407",
            "placeholder": "​",
            "style": "IPY_MODEL_fbdb201b9fef41a89c5532e8346374be",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "540b9d861acf4fad85cd730e2ea9d74c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed3e13b144a14f5881695c337eedb8c3",
            "max": 662,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27157321c481412fa5de9b2691bc44cc",
            "value": 662
          }
        },
        "d8aa2a2e2a6a442e8570562ac14a300e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80d37eeceb12477990f0886fe075dff9",
            "placeholder": "​",
            "style": "IPY_MODEL_9d93872d47114ae9a5516cea7cf8b646",
            "value": " 662/662 [00:00&lt;00:00, 63.6kB/s]"
          }
        },
        "f8af64d2485d485c8b35acf2abb9761f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eee1b6c518d14f959b6882a50c2d1407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbdb201b9fef41a89c5532e8346374be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed3e13b144a14f5881695c337eedb8c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27157321c481412fa5de9b2691bc44cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80d37eeceb12477990f0886fe075dff9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d93872d47114ae9a5516cea7cf8b646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9CpRKEOrTPS",
        "outputId": "512872b0-3734-48bc-caf3-bb337a6e2fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 1 (REVISED): Installs and PyTorch/HuggingFace Imports\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"Installing/Updating PyTorch, Hugging Face, and related libraries for MedGemma...\")\n",
        "# Install PyTorch first (cu118 is common for Colab T4/V100 GPUs)\n",
        "!pip install -q -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Install Hugging Face and other necessary libraries\n",
        "# Let pip resolve numpy and scikit-learn based on these packages' needs\n",
        "!pip install -q -U transformers accelerate bitsandbytes peft pydicom pandas opencv-python Pillow scikit-learn\n",
        "\n",
        "# No explicit numpy install/uninstall here; let other packages specify their needs.\n",
        "# pydicom, pandas, opencv-python, Pillow are generally fine with default versions.\n",
        "\n",
        "print(\"\\nImporting libraries...\")\n",
        "# Python Standard Libraries\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "# Third-party Libraries\n",
        "import pandas as pd\n",
        "import numpy as np # Should be a compatible version now\n",
        "import pydicom\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Scikit-learn (should import fine after pip installs a compatible version)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Hugging Face Transformers\n",
        "from transformers import AutoProcessor\n",
        "\n",
        "# TensorFlow (still imported from your original code, we'll manage its numpy needs)\n",
        "# If you are ONLY using PyTorch for MedGemma, you can comment out TF imports later.\n",
        "# For now, keeping them to see if the environment stabilizes.\n",
        "import tensorflow as tf\n",
        "# from tensorflow.keras.applications import ResNet50V2 # Not needed for MedGemma\n",
        "# from tensorflow.keras.applications.resnet_v2 import preprocess_input as resnet_preprocess_input # Not needed\n",
        "# from tensorflow.keras.utils import Sequence # Not needed for PyTorch Dataset\n",
        "# from tensorflow.keras import layers, models # Not needed\n",
        "\n",
        "# Plotting (optional, but often useful)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Colab specific (if needed)\n",
        "from google.colab import drive # Moved drive mount to Cell 2\n",
        "\n",
        "print(\"--- Library Version Checks ---\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Scikit-learn version: {pd.__version__}\") # Oops, should be sklearn.__version__\n",
        "import sklearn\n",
        "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    print(f\"PyTorch CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU available for PyTorch: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"GPU not available for PyTorch, using CPU.\")\n",
        "print(f\"GPU Available for TensorFlow: {tf.config.list_physical_devices('GPU')}\")\n",
        "\n",
        "\n",
        "# For reproducibility\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "if 'torch' in globals(): # Check if torch was successfully imported\n",
        "    torch.manual_seed(RANDOM_SEED)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "print(\"\\nCell 1: Installs and Imports complete.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wX_Gvd72gl0",
        "outputId": "fcb4211b-abcb-45f5-b8d8-11993d581b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing/Updating PyTorch, Hugging Face, and related libraries for MedGemma...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m118.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m955.6/955.6 MB\u001b[0m \u001b[31m843.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "Importing libraries...\n",
            "--- Library Version Checks ---\n",
            "Pandas version: 2.2.3\n",
            "NumPy version: 2.0.2\n",
            "Scikit-learn version: 2.2.3\n",
            "Scikit-learn version: 1.6.1\n",
            "TensorFlow Version: 2.18.0\n",
            "PyTorch version: 2.7.0+cu118\n",
            "PyTorch CUDA version: 11.8\n",
            "GPU available for PyTorch: Tesla T4\n",
            "GPU Available for TensorFlow: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "\n",
            "Cell 1: Installs and Imports complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N0ZV9gGb4CL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------\n",
        "# Cell 2: Configuration and Unzip Data\n",
        "# (Your existing Cell 2 - ensure drive is mounted first if not done in Cell 1)\n",
        "# --------------------------------------------------\n",
        "if 'drive' not in globals(): # If drive wasn't imported/mounted in Cell 1\n",
        "    from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True) # force_remount if running again\n",
        "\n",
        "# --- Configuration ---\n",
        "DRIVE_CSV_PATH = \"/content/drive/MyDrive/cp.csv\"\n",
        "DRIVE_ZIP_PATH = \"/content/drive/MyDrive/1000-20250517T062750Z-1-001.zip\" # Your image ZIP on Drive\n",
        "\n",
        "LOCAL_EXTRACT_PATH = \"/content/medgemma_extracted_images\" # Using the MedGemma specific path\n",
        "LOCAL_IMAGES_ROOT = os.path.join(LOCAL_EXTRACT_PATH, \"1000\")\n",
        "LOCAL_CSV_PATH = \"/content/medgemma_cp.csv\" # Using the MedGemma specific path\n",
        "\n",
        "# --- Unzip Data (if not already done or if re-running) ---\n",
        "if os.path.exists(DRIVE_CSV_PATH):\n",
        "    shutil.copy(DRIVE_CSV_PATH, LOCAL_CSV_PATH)\n",
        "    print(f\"CSV copied to {LOCAL_CSV_PATH}\")\n",
        "else:\n",
        "    print(f\"ERROR: CSV file not found at {DRIVE_CSV_PATH}\")\n",
        "\n",
        "if os.path.exists(LOCAL_EXTRACT_PATH):\n",
        "    print(f\"Removing existing extraction directory: {LOCAL_EXTRACT_PATH}\")\n",
        "    shutil.rmtree(LOCAL_EXTRACT_PATH)\n",
        "os.makedirs(LOCAL_EXTRACT_PATH, exist_ok=True)\n",
        "print(f\"Created local extraction directory: {LOCAL_EXTRACT_PATH}\")\n",
        "\n",
        "if os.path.exists(DRIVE_ZIP_PATH):\n",
        "    print(f\"Unzipping {DRIVE_ZIP_PATH} to {LOCAL_EXTRACT_PATH}...\")\n",
        "    with zipfile.ZipFile(DRIVE_ZIP_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall(LOCAL_EXTRACT_PATH)\n",
        "    print(\"Unzipping complete.\")\n",
        "    if os.path.exists(LOCAL_IMAGES_ROOT):\n",
        "        print(f\"Image root folder found at: {LOCAL_IMAGES_ROOT}\")\n",
        "    else:\n",
        "        print(f\"ERROR: Expected image root folder '{LOCAL_IMAGES_ROOT}' not found after unzipping.\")\n",
        "else:\n",
        "    print(f\"ERROR: ZIP file not found at {DRIVE_ZIP_PATH}\")\n",
        "\n",
        "print(\"\\nCell 2: Data unzipping complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gx5YCYkyr7_i",
        "outputId": "eeab0a66-a8ba-492d-b757-061eb1a138a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "CSV copied to /content/medgemma_cp.csv\n",
            "Created local extraction directory: /content/medgemma_extracted_images\n",
            "Unzipping /content/drive/MyDrive/1000-20250517T062750Z-1-001.zip to /content/medgemma_extracted_images...\n",
            "Unzipping complete.\n",
            "Image root folder found at: /content/medgemma_extracted_images/1000\n",
            "\n",
            "Cell 2: Data unzipping complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------\n",
        "# Cell 3: Load and Filter Clinical Data to create image_df\n",
        "# (Your existing Cell 3 - adapted for clarity and robustness)\n",
        "# --------------------------------------------------\n",
        "image_df = pd.DataFrame() # Initialize to ensure it exists\n",
        "\n",
        "if not os.path.exists(LOCAL_CSV_PATH):\n",
        "    print(f\"FATAL ERROR: Clinical CSV file not found at the expected local path: {LOCAL_CSV_PATH}\")\n",
        "else:\n",
        "    df_raw_from_cell3 = pd.read_csv(LOCAL_CSV_PATH) # Use a distinct name to avoid confusion\n",
        "    print(f\"Initial number of rows in clinical data (Cell 3): {len(df_raw_from_cell3)}\")\n",
        "\n",
        "    # IMPORTANT: Verify these column names EXACTLY match your CSV file\n",
        "    person_id_col_name_c3 = 'person_id'\n",
        "    ldl_col_name_c3 = \"LDL Cholesterol Calculation (mg/dL)\"\n",
        "\n",
        "    if not (person_id_col_name_c3 in df_raw_from_cell3.columns and ldl_col_name_c3 in df_raw_from_cell3.columns):\n",
        "        print(f\"ERROR: Required columns ('{person_id_col_name_c3}' or '{ldl_col_name_c3}') not found in CSV.\")\n",
        "        print(f\"Available columns: {df_raw_from_cell3.columns.tolist()}\")\n",
        "    else:\n",
        "        # Select and clean\n",
        "        df_selected_c3 = df_raw_from_cell3[[person_id_col_name_c3, ldl_col_name_c3]].copy()\n",
        "        df_selected_c3.rename(columns={ldl_col_name_c3: 'LDL_temp'}, inplace=True) # Use temp name\n",
        "        df_selected_c3['LDL_temp'] = pd.to_numeric(df_selected_c3['LDL_temp'], errors='coerce')\n",
        "        df_selected_c3.dropna(subset=['LDL_temp'], inplace=True)\n",
        "        df_selected_c3 = df_selected_c3[df_selected_c3['LDL_temp'] > 0].copy()\n",
        "        df_selected_c3[person_id_col_name_c3] = df_selected_c3[person_id_col_name_c3].astype(str)\n",
        "        print(f\"Cleaned clinical data (positive LDLs only): {len(df_selected_c3)} records.\")\n",
        "\n",
        "        ldl_lookup_c3 = df_selected_c3.set_index(person_id_col_name_c3)['LDL_temp'].to_dict()\n",
        "\n",
        "        # Map to images\n",
        "        if not (os.path.exists(LOCAL_IMAGES_ROOT) and os.path.isdir(LOCAL_IMAGES_ROOT)):\n",
        "            print(f\"FATAL ERROR: Images root path '{LOCAL_IMAGES_ROOT}' does not exist or is not a directory.\")\n",
        "        else:\n",
        "            available_folders_c3 = set(os.listdir(LOCAL_IMAGES_ROOT))\n",
        "            valid_ids_clinical_c3 = set(ldl_lookup_c3.keys())\n",
        "            common_person_ids_c3 = sorted(list(valid_ids_clinical_c3 & available_folders_c3))\n",
        "            print(f\"Found {len(common_person_ids_c3)} common person_ids for mapping.\")\n",
        "\n",
        "            image_records_list = []\n",
        "            for pid_c3 in common_person_ids_c3:\n",
        "                folder_path_c3 = os.path.join(LOCAL_IMAGES_ROOT, pid_c3)\n",
        "                ldl_val_c3 = ldl_lookup_c3[pid_c3]\n",
        "                if os.path.isdir(folder_path_c3):\n",
        "                    for filename_c3 in os.listdir(folder_path_c3):\n",
        "                        if filename_c3.lower().endswith(\".dcm\"):\n",
        "                            image_path_c3 = os.path.join(folder_path_c3, filename_c3)\n",
        "                            image_records_list.append({\n",
        "                                \"person_id\": pid_c3, # Final column name\n",
        "                                \"image_path\": image_path_c3, # Final column name\n",
        "                                \"LDL\": ldl_val_c3 # Final column name\n",
        "                            })\n",
        "            image_df = pd.DataFrame(image_records_list) # Assign to the main image_df\n",
        "            if not image_df.empty:\n",
        "                print(f\"Final image_df created with {len(image_df)} image-LDL pairs.\")\n",
        "                print(image_df.head())\n",
        "                print(f\"LDL stats in final image_df: min={image_df['LDL'].min()}, max={image_df['LDL'].max()}, mean={image_df['LDL'].mean()}\")\n",
        "            else:\n",
        "                print(\"WARNING: image_df is empty after mapping. Check paths and IDs.\")\n",
        "print(\"\\nCell 3: image_df preparation complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp-fwDy-4qup",
        "outputId": "ae1bbc4b-b0aa-4e13-d225-f7d0f88c82df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial number of rows in clinical data (Cell 3): 1067\n",
            "Cleaned clinical data (positive LDLs only): 1025 records.\n",
            "Found 527 common person_ids for mapping.\n",
            "Final image_df created with 973 image-LDL pairs.\n",
            "  person_id                                         image_path         LDL\n",
            "0      1002  /content/medgemma_extracted_images/1000/1002/1...  133.485054\n",
            "1      1004  /content/medgemma_extracted_images/1000/1004/1...   59.674544\n",
            "2      1004  /content/medgemma_extracted_images/1000/1004/1...   59.674544\n",
            "3      1005  /content/medgemma_extracted_images/1000/1005/1...   74.956702\n",
            "4      1007  /content/medgemma_extracted_images/1000/1007/1...   92.278412\n",
            "LDL stats in final image_df: min=10.77327021, max=278.5634775, mean=92.26371915419321\n",
            "\n",
            "Cell 3: image_df preparation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 4: Verify image_df and Set MedGemma Model ID\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# VERIFY `image_df` IS READY FROM YOUR PREVIOUS CELLS\n",
        "if 'image_df' in locals() and isinstance(image_df, pd.DataFrame) and not image_df.empty:\n",
        "    print(f\"Continuing with 'image_df' which has {len(image_df)} records.\")\n",
        "    print(\"Columns in image_df:\", image_df.columns.tolist())\n",
        "    print(\"Sample of image_df:\")\n",
        "    display(image_df.head()) # Use display for better DataFrame formatting in Colab\n",
        "\n",
        "    required_cols = ['person_id', 'image_path', 'LDL']\n",
        "    if not all(col in image_df.columns for col in required_cols):\n",
        "        print(f\"ERROR: 'image_df' is missing one or more required columns: {required_cols}. Please re-run previous data preparation cells.\")\n",
        "    elif image_df['LDL'].min() <= 0:\n",
        "        print(f\"ERROR: 'image_df' still contains non-positive LDL values. LDL min: {image_df['LDL'].min()}. Please re-run filtering.\")\n",
        "    else:\n",
        "        print(\"'image_df' seems okay to proceed.\")\n",
        "else:\n",
        "    print(\"ERROR: 'image_df' not found or is empty. Please ensure your data preparation cells (your original Cells 1-3, now adapted) have been run successfully.\")\n",
        "    # In a real run, you'd stop and fix. For script flow, create empty to avoid NameError.\n",
        "    image_df = pd.DataFrame(columns=['person_id', 'image_path', 'LDL'])\n",
        "\n",
        "\n",
        "# --- MedGemma Model ID Configuration ---\n",
        "# ACTION: YOU MUST VERIFY THIS MODEL ID FROM HUGGING FACE HUB\n",
        "# Search on Hugging Face Hub: https://huggingface.co/models?search=google/medgemma\n",
        "# Look for the 4B \"pt\" (pre-trained) variant.\n",
        "# Common candidates: \"google/medgemma-4b-pt\" or \"google/medgem_vision_text_4b_pt\"\n",
        "MEDGEMMA_PT_MODEL_ID = \"google/medgemma-4b-pt\"  # <<<--- REPLACE WITH VERIFIED ID\n",
        "# Example: MEDGEMMA_PT_MODEL_ID = \"google/medgem_vision_text_4b_pt\" # If this is the correct one\n",
        "\n",
        "print(f\"\\nConfigured MEDGEMMA_PT_MODEL_ID: {MEDGEMMA_PT_MODEL_ID}\")\n",
        "if MEDGEMMA_PT_MODEL_ID == \"google/medgemma-4b-pt\": # Check if it's still the placeholder\n",
        "    print(\"WARNING: MEDGEMMA_PT_MODEL_ID might still be the placeholder. Please verify this ID on Hugging Face Hub.\")\n",
        "\n",
        "print(\"\\nCell 4: image_df verification and MedGemma Model ID configuration complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "eu0FWJLm5TK-",
        "outputId": "a6a25b2b-d32c-4a65-e910-a2813330e4a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Continuing with 'image_df' which has 973 records.\n",
            "Columns in image_df: ['person_id', 'image_path', 'LDL']\n",
            "Sample of image_df:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  person_id                                         image_path         LDL\n",
              "0      1002  /content/medgemma_extracted_images/1000/1002/1...  133.485054\n",
              "1      1004  /content/medgemma_extracted_images/1000/1004/1...   59.674544\n",
              "2      1004  /content/medgemma_extracted_images/1000/1004/1...   59.674544\n",
              "3      1005  /content/medgemma_extracted_images/1000/1005/1...   74.956702\n",
              "4      1007  /content/medgemma_extracted_images/1000/1007/1...   92.278412"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da28df11-44bd-4b78-a8ef-10591b1cfc3d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>person_id</th>\n",
              "      <th>image_path</th>\n",
              "      <th>LDL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1002</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1002/1...</td>\n",
              "      <td>133.485054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1004</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1004/1...</td>\n",
              "      <td>59.674544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1004</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1004/1...</td>\n",
              "      <td>59.674544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1005</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1005/1...</td>\n",
              "      <td>74.956702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1007</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1007/1...</td>\n",
              "      <td>92.278412</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da28df11-44bd-4b78-a8ef-10591b1cfc3d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-da28df11-44bd-4b78-a8ef-10591b1cfc3d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-da28df11-44bd-4b78-a8ef-10591b1cfc3d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e8d71506-cea2-4725-afc1-59c9f8ef3198\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8d71506-cea2-4725-afc1-59c9f8ef3198')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e8d71506-cea2-4725-afc1-59c9f8ef3198 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nCell 4: image_df verification and MedGemma Model ID configuration complete\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"person_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"1004\",\n          \"1007\",\n          \"1002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"/content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230809.2448.36605.dcm\",\n          \"/content/medgemma_extracted_images/1000/1007/1007_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230824.20355.67485.dcm\",\n          \"/content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_l_1.2.826.0.1.3680043.8.641.1.20230809.2436.96446.dcm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LDL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.751173059264335,\n        \"min\": 59.67454369,\n        \"max\": 133.4850537,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          59.67454369,\n          92.27841214,\n          133.4850537\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'image_df' seems okay to proceed.\n",
            "\n",
            "Configured MEDGEMMA_PT_MODEL_ID: google/medgemma-4b-pt\n",
            "WARNING: MEDGEMMA_PT_MODEL_ID might still be the placeholder. Please verify this ID on Hugging Face Hub.\n",
            "\n",
            "Cell 4: image_df verification and MedGemma Model ID configuration complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")"
      ],
      "metadata": {
        "id": "50QUF_ll8cOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 5: Load MedGemma Processor\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "medgemma_processor = None\n",
        "# Default target size from model card, will try to confirm/override from processor\n",
        "TARGET_SIZE_MEDGEMMA = (896, 896) # MedGemma model card specifies 896x896\n",
        "\n",
        "# Check if the model ID is still the placeholder\n",
        "if MEDGEMMA_PT_MODEL_ID == \"google/medgemma-4b-pt\" or \"YOUR_VERIFIED_MODEL_ID_HERE\" in MEDGEMMA_PT_MODEL_ID: # A more generic placeholder check\n",
        "    print(f\"WARNING: MEDGEMMA_PT_MODEL_ID ('{MEDGEMMA_PT_MODEL_ID}') looks like a placeholder.\")\n",
        "    print(\"Please verify and update it in Cell 4 with the correct model ID from Hugging Face Hub for the 4B pre-trained variant before proceeding.\")\n",
        "\n",
        "try:\n",
        "    print(f\"\\nAttempting to load MedGemma processor for: {MEDGEMMA_PT_MODEL_ID}...\")\n",
        "    # trust_remote_code=True is often needed for newer models or those with custom code (like Gemma family)\n",
        "    medgemma_processor = AutoProcessor.from_pretrained(MEDGEMMA_PT_MODEL_ID, trust_remote_code=True)\n",
        "    print(\"MedGemma Processor loaded successfully!\")\n",
        "\n",
        "    # Inspect the processor's image_processor component for expected size\n",
        "    if hasattr(medgemma_processor, 'image_processor') and hasattr(medgemma_processor.image_processor, 'size'):\n",
        "        img_proc_size_info = medgemma_processor.image_processor.size\n",
        "        print(f\"Processor's image_processor.size attribute: {img_proc_size_info}\")\n",
        "\n",
        "        parsed_h, parsed_w = None, None\n",
        "        if isinstance(img_proc_size_info, dict):\n",
        "            parsed_h = img_proc_size_info.get('height', img_proc_size_info.get('shortest_edge'))\n",
        "            if parsed_h is not None:\n",
        "                 parsed_w = img_proc_size_info.get('width', parsed_h if 'shortest_edge' in img_proc_size_info else None)\n",
        "        elif isinstance(img_proc_size_info, (list, tuple)) and len(img_proc_size_info) == 2:\n",
        "            parsed_h, parsed_w = img_proc_size_info[0], img_proc_size_info[1]\n",
        "        elif isinstance(img_proc_size_info, int):\n",
        "            parsed_h = parsed_w = img_proc_size_info\n",
        "\n",
        "        if parsed_h and parsed_w:\n",
        "            # Override TARGET_SIZE_MEDGEMMA if successfully parsed from processor\n",
        "            TARGET_SIZE_MEDGEMMA = (parsed_h, parsed_w)\n",
        "            print(f\"Target Image Size for MedGemma (from processor): {TARGET_SIZE_MEDGEMMA}\")\n",
        "            if TARGET_SIZE_MEDGEMMA != (896, 896): # Compare with model card expectation\n",
        "                print(f\"Note: Processor-derived size {TARGET_SIZE_MEDGEMMA} differs from model card's typical 896x896. Using processor's size.\")\n",
        "        else:\n",
        "            print(f\"Could not reliably parse size from processor.image_processor.size. Using default from model card: {TARGET_SIZE_MEDGEMMA}\")\n",
        "    else:\n",
        "        print(f\"Warning: MedGemma processor for {MEDGEMMA_PT_MODEL_ID} does not have 'image_processor.size'. Using default: {TARGET_SIZE_MEDGEMMA}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading MedGemma processor for '{MEDGEMMA_PT_MODEL_ID}': {e}\")\n",
        "    print(\"Ensure the MEDGEMMA_PT_MODEL_ID in Cell 4 is correct and you have internet access.\")\n",
        "    print(\"If the ID is correct, the model might require specific dependencies or there might be an issue with the Hugging Face Hub or the model's configuration.\")\n",
        "    # medgemma_processor will remain None\n",
        "\n",
        "print(\"\\nCell 5: MedGemma Processor loading attempt complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443,
          "referenced_widgets": [
            "0a4469a146a2420fbbb500f5a07417b1",
            "b4cd9e10b62546f38c26ea9b3e5dc40f",
            "d10e319c54914f50b11ac5acfce9060f",
            "385c93fb65cc4c04a79178e89757b670",
            "c9d10b15cca64191aac56be356eea9fc",
            "8639d7b282ea4390822976662ffaa203",
            "cc77c8366c3b4a98af63a2b98efff7e7",
            "a4ec4ae1d8174ffb839cfcef28807b23",
            "dbe278bc9ba743679c5e2a70197d199c",
            "a7c20dcb3af84712b6af8cc221bc6dbe",
            "491543afe7f9451c93cb3024e28d47e9",
            "d87ff41b5bc74d5a818e756bbbd6ebae",
            "634a89ab05e7414a84719db258fa1a12",
            "46ef9e6a37d64916b712cfd6bd27e718",
            "5e42e930be874650a578a8cd483d000b",
            "50b3947b3bc143f99a10492c15674843",
            "57f32ea3b9814de1b6951f75bc6d1bcb",
            "662461f8cadd4482875abc9eae7a765c",
            "a1cf2910784040d6a596f2cc55b872b2",
            "f576e84a25e645d386db78d3a0730be2",
            "3a59fb3858fc4a5bb01dfc176b64ff0e",
            "8cffab60c21c46a38ec4007e67e21d69",
            "0d06efde760d4d31843ba0cb7ab18b8a",
            "d156c5f2209d43e69247b2fdae2b67e5",
            "6d69675ded87462b8f317774d972a96c",
            "e419302173c24630a5d64a7868f5f1ac",
            "7611ac6954af44ff9669dd05aa78996e",
            "61c5cfff8f284343a0384e777eee43df",
            "ab00266a5212492a87065c974d5fd4b6",
            "b291468c5e4845a59f7daf0066c553f5",
            "539d2deef7ab4fa6ad8974edbe9e2de5",
            "d487a266b6c34fe7914af7db3ffdd7ea",
            "33366ba6c6d84a54bde37e034c70971c",
            "35b385272a9c40e68810279f5a8a05cf",
            "31656c75189744698c9958c7701d89ba",
            "20338b7fe27d45a1a1be6076fa1619e1",
            "4fbf447ea26146329dc384c4d7d23b90",
            "df9a9499d9f6407eb4ac6432eb4af3a0",
            "76f7aeb5acb64dd29dd17e0d36cf3ba2",
            "38d31d01fcec4b94b8311c12de0356f9",
            "23fbcbc628b44e8cb9644fab2a224ad6",
            "5712e062e88341b8b3739900c4e16a80",
            "7368f44c58d647dbb6cf36ddefd0b8b6",
            "dcd90484dcb2450a9680514df44b4c4e",
            "bce86ab65bb249d3b63b700c97aa7fd9",
            "6613e43ef6434c00b14ca15b45d2f2aa",
            "8256e60a8a0d4f4c91ede2731d21a625",
            "ef33d64b10414c36a88b9016139a991c",
            "619e83688a6f4341b7de0de36566f34d",
            "b7107887d0484de9b45613d2420e91bd",
            "fdad4b04d84a42f08a0e8193c99af821",
            "6ade2abd16e34b4aa5095c45c150accd",
            "3ffaa71181eb4c0aae3aad3ff5969548",
            "274e7c7de4514d27bc78020e7fee24ef",
            "190197ecfa8a42939349fdfeb8d9f332",
            "07175cfacb6e49c2a76cdc44ac0e68f0",
            "248f01ee81044914b6d96a0a92b530bf",
            "9721212601ee4007a9f3da7fac4a9400",
            "c808c8b1a55d40329797192f0ad3a4bf",
            "f43cca943bb54d2baa39d7b5b2e16771",
            "79183da6fb974a6db3093dafa3c17f09",
            "34ce04a267d34b648347ef63acf81658",
            "6d48dddb73754bd3b8ff1f6572dc0b3d",
            "d5a6cd8a8e674bffabce66003f0e328a",
            "8ca1c16e820047b1a08cf0d54e9c9088",
            "e40506218cf94d2ea7c270dad3b2ba8a",
            "e511d20d7a194214b2aa755563e19d9e",
            "04422a8cadd44b7db068b5ea29392f0d",
            "540b9d861acf4fad85cd730e2ea9d74c",
            "d8aa2a2e2a6a442e8570562ac14a300e",
            "f8af64d2485d485c8b35acf2abb9761f",
            "eee1b6c518d14f959b6882a50c2d1407",
            "fbdb201b9fef41a89c5532e8346374be",
            "ed3e13b144a14f5881695c337eedb8c3",
            "27157321c481412fa5de9b2691bc44cc",
            "80d37eeceb12477990f0886fe075dff9",
            "9d93872d47114ae9a5516cea7cf8b646"
          ]
        },
        "id": "7bw90k9f5nH1",
        "outputId": "474262f3-18f5-4c68-c928-018031124a7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: MEDGEMMA_PT_MODEL_ID ('google/medgemma-4b-pt') looks like a placeholder.\n",
            "Please verify and update it in Cell 4 with the correct model ID from Hugging Face Hub for the 4B pre-trained variant before proceeding.\n",
            "\n",
            "Attempting to load MedGemma processor for: google/medgemma-4b-pt...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "processor_config.json:   0%|          | 0.00/70.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a4469a146a2420fbbb500f5a07417b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d87ff41b5bc74d5a818e756bbbd6ebae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d06efde760d4d31843ba0cb7ab18b8a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35b385272a9c40e68810279f5a8a05cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bce86ab65bb249d3b63b700c97aa7fd9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07175cfacb6e49c2a76cdc44ac0e68f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e511d20d7a194214b2aa755563e19d9e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MedGemma Processor loaded successfully!\n",
            "Processor's image_processor.size attribute: {'height': 896, 'width': 896}\n",
            "Target Image Size for MedGemma (from processor): (896, 896)\n",
            "\n",
            "Cell 5: MedGemma Processor loading attempt complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(medgemma_processor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni0PNOiWoosg",
        "outputId": "0de9a9ee-3613-4e4e-e040-23b604080680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.models.gemma3.processing_gemma3.Gemma3Processor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 6: Data Splitting (Patient-Level) and LDL Normalization\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "train_df, val_df, test_df = pd.DataFrame(), pd.DataFrame(), pd.DataFrame() # Initialize\n",
        "ldl_scaler = None # Will store the fitted StandardScaler\n",
        "\n",
        "if 'image_df' in locals() and not image_df.empty:\n",
        "    print(f\"\\nStarting data splitting for {len(image_df)} image-LDL pairs...\")\n",
        "    if 'person_id' not in image_df.columns:\n",
        "        print(\"ERROR: 'person_id' column missing in image_df. Cannot perform patient-level split. Please check image_df preparation.\")\n",
        "    else:\n",
        "        unique_person_ids = image_df['person_id'].unique()\n",
        "        print(f\"Total unique patients for splitting: {len(unique_person_ids)}\")\n",
        "\n",
        "        if len(unique_person_ids) < 3:\n",
        "            print(\"Warning: Not enough unique patients for a robust 3-way (train/validation/test) split.\")\n",
        "            # Simplified split logic for few patients (adjust as needed for your minimum requirements)\n",
        "            if len(unique_person_ids) == 2:\n",
        "                train_pids, val_pids = train_test_split(unique_person_ids, test_size=0.5, random_state=RANDOM_SEED)\n",
        "                test_pids = np.array([]) # Empty array for consistency\n",
        "            elif len(unique_person_ids) == 1:\n",
        "                train_pids = unique_person_ids\n",
        "                val_pids, test_pids = np.array([]), np.array([])\n",
        "            else: # 0 patients\n",
        "                train_pids, val_pids, test_pids = np.array([]), np.array([]), np.array([])\n",
        "        else:\n",
        "            # Standard 70% train, 15% validation, 15% test split of person_ids\n",
        "            train_pids, temp_pids = train_test_split(\n",
        "                unique_person_ids, test_size=0.30, random_state=RANDOM_SEED\n",
        "            )\n",
        "            if len(temp_pids) > 1 : # Ensure there's at least 2 for val/test split\n",
        "                 val_pids, test_pids = train_test_split(\n",
        "                    temp_pids, test_size=0.50, random_state=RANDOM_SEED\n",
        "                )\n",
        "            elif len(temp_pids) == 1: # Only one patient left\n",
        "                val_pids = temp_pids\n",
        "                test_pids = np.array([])\n",
        "            else:\n",
        "                val_pids, test_pids = np.array([]), np.array([])\n",
        "\n",
        "\n",
        "        train_df = image_df[image_df['person_id'].isin(train_pids)].copy()\n",
        "        val_df = image_df[image_df['person_id'].isin(val_pids)].copy()\n",
        "        test_df = image_df[image_df['person_id'].isin(test_pids)].copy()\n",
        "\n",
        "        print(f\"Train set: {len(train_df)} samples from {len(train_pids)} patients.\")\n",
        "        print(f\"Validation set: {len(val_df)} samples from {len(val_pids)} patients.\")\n",
        "        print(f\"Test set: {len(test_df)} samples from {len(test_pids)} patients.\")\n",
        "\n",
        "        # Sanity check for patient overlap - important!\n",
        "        if len(train_pids)>0 and len(val_pids)>0: assert len(set(train_pids) & set(val_pids)) == 0, \"Patient overlap train/val!\"\n",
        "        if len(train_pids)>0 and len(test_pids)>0: assert len(set(train_pids) & set(test_pids)) == 0, \"Patient overlap train/test!\"\n",
        "        if len(val_pids)>0 and len(test_pids)>0: assert len(set(val_pids) & set(test_pids)) == 0, \"Patient overlap val/test!\"\n",
        "        print(\"Patient-level splits verified (no overlap if sets are non-empty).\")\n",
        "\n",
        "        # --- LDL Value Normalization ---\n",
        "        if not train_df.empty and 'LDL' in train_df.columns:\n",
        "            print(\"\\nNormalizing LDL values using StandardScaler...\")\n",
        "            ldl_scaler = StandardScaler()\n",
        "            # Fit the scaler ONLY on the training data's LDL values\n",
        "            train_df['LDL_scaled'] = ldl_scaler.fit_transform(train_df[['LDL']])\n",
        "\n",
        "            # Transform validation and test data using the FITTED scaler\n",
        "            if not val_df.empty:\n",
        "                val_df['LDL_scaled'] = ldl_scaler.transform(val_df[['LDL']])\n",
        "            else:\n",
        "                # Add LDL_scaled column even if empty, for consistency\n",
        "                val_df['LDL_scaled'] = pd.Series(dtype='float64')\n",
        "\n",
        "            if not test_df.empty:\n",
        "                test_df['LDL_scaled'] = ldl_scaler.transform(test_df[['LDL']])\n",
        "            else:\n",
        "                test_df['LDL_scaled'] = pd.Series(dtype='float64')\n",
        "\n",
        "\n",
        "            print(\"LDL normalization complete.\")\n",
        "            print(\"Scaled LDL stats in train_df (should be mean~0, std~1):\")\n",
        "            display(train_df['LDL_scaled'].describe())\n",
        "\n",
        "            # Save the scaler for later use during inference/evaluation\n",
        "            # import joblib\n",
        "            # scaler_filename = 'ldl_scaler_medgemma.joblib'\n",
        "            # joblib.dump(ldl_scaler, scaler_filename)\n",
        "            # print(f\"LDL scaler saved to {scaler_filename}\")\n",
        "        else:\n",
        "            print(\"Train DataFrame is empty or 'LDL' column missing. Skipping LDL normalization.\")\n",
        "else:\n",
        "    print(\"image_df is empty (from Cell 3). Skipping data splitting and LDL normalization.\")\n",
        "\n",
        "print(\"\\nCell 6: Data splitting and LDL normalization attempt complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "7If-OZBu8uzx",
        "outputId": "abf32144-2377-43e3-d77f-758a3435821e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting data splitting for 973 image-LDL pairs...\n",
            "Total unique patients for splitting: 527\n",
            "Train set: 681 samples from 368 patients.\n",
            "Validation set: 145 samples from 79 patients.\n",
            "Test set: 147 samples from 80 patients.\n",
            "Patient-level splits verified (no overlap if sets are non-empty).\n",
            "\n",
            "Normalizing LDL values using StandardScaler...\n",
            "LDL normalization complete.\n",
            "Scaled LDL stats in train_df (should be mean~0, std~1):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "count    6.810000e+02\n",
              "mean     2.086763e-16\n",
              "std      1.000735e+00\n",
              "min     -2.303724e+00\n",
              "25%     -7.148712e-01\n",
              "50%     -4.975462e-02\n",
              "75%      6.670533e-01\n",
              "max      2.756859e+00\n",
              "Name: LDL_scaled, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LDL_scaled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6.810000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.086763e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000735e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-2.303724e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-7.148712e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-4.975462e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.670533e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.756859e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cell 6: Data splitting and LDL normalization attempt complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5.1: Check medgemma_processor\n",
        "if 'medgemma_processor' in locals() and medgemma_processor is not None:\n",
        "    print(f\"Cell 5.1 Check: medgemma_processor IS LOADED. Type: {type(medgemma_processor)}\")\n",
        "    if hasattr(medgemma_processor, 'image_processor'):\n",
        "        print(f\"  It has an image_processor of type: {type(medgemma_processor.image_processor)}\")\n",
        "    else:\n",
        "        print(\"  WARNING: It does NOT have an image_processor attribute.\")\n",
        "else:\n",
        "    print(\"Cell 5.1 Check: medgemma_processor IS NOT LOADED or is None.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCu040Kbs1n5",
        "outputId": "9268f016-99b5-40fd-851b-7988039f4694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cell 5.1 Check: medgemma_processor IS LOADED. Type: <class 'transformers.models.gemma3.processing_gemma3.Gemma3Processor'>\n",
            "  It has an image_processor of type: <class 'transformers.models.gemma3.image_processing_gemma3.Gemma3ImageProcessor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def load_dicom_image_medgemma_DEBUG(path, processor_obj): # processor_obj is the main Gemma3Processor\n",
        "    print(f\"\\n--- Debugging load_dicom_image_medgemma_DEBUG for: {path} ---\")\n",
        "    if processor_obj is None:\n",
        "        print(f\"DEBUG: Main processor object (processor_obj) is None. Cannot proceed.\")\n",
        "        return None\n",
        "\n",
        "    # Check if the main processor has the image_processor component\n",
        "    if not hasattr(processor_obj, 'image_processor') or processor_obj.image_processor is None:\n",
        "        print(f\"DEBUG: processor_obj does not have a valid 'image_processor' attribute.\")\n",
        "        return None\n",
        "\n",
        "    actual_image_processor = processor_obj.image_processor # This is the specific image handler\n",
        "    print(f\"DEBUG: Using actual_image_processor: {type(actual_image_processor)}\")\n",
        "\n",
        "    pil_image_for_processor = None\n",
        "    numpy_array_for_processor = None\n",
        "\n",
        "    # 1. Pydicom Read\n",
        "    try:\n",
        "        # ... (pydicom reading and dcm.convert_pixel_data() logic remains the same as your last version) ...\n",
        "        print(\"DEBUG: Attempting pydicom.dcmread(path)...\")\n",
        "        dcm = pydicom.dcmread(path)\n",
        "        photometric_interpretation = dcm.get('PhotometricInterpretation', 'N/A')\n",
        "        print(f\"  DICOM PhotometricInterpretation: {photometric_interpretation}\")\n",
        "\n",
        "        print(\"DEBUG: Attempting to get pixel data via dcm.convert_pixel_data()...\")\n",
        "        dcm.convert_pixel_data()\n",
        "        img_array = dcm.pixel_array\n",
        "        print(f\"  DEBUG: dcm.pixel_array after convert_pixel_data(). Shape: {img_array.shape}, dtype: {img_array.dtype}\")\n",
        "        numpy_array_for_processor = img_array.astype(np.uint8).copy() # Keep as uint8 if convert_pixel_data worked well\n",
        "        img_array = img_array.astype(np.float32) # For normalization if needed\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"DEBUG: Pydicom read or convert_pixel_data error for {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "    # 2. Normalization to 0-255 range (if necessary after convert_pixel_data)\n",
        "    print(\"\\nDEBUG: Normalizing to 0-255 range (if necessary)...\")\n",
        "    img_min_val = np.min(img_array)\n",
        "    img_max_val = np.max(img_array)\n",
        "\n",
        "    # If convert_pixel_data results in uint8 0-255, this normalization might be redundant but harmless\n",
        "    if not (img_array.dtype == np.uint8 and img_min_val >= 0 and img_max_val <= 255):\n",
        "        if img_max_val - img_min_val > 1e-7:\n",
        "            img_normalized_255 = 255.0 * (img_array - img_min_val) / (img_max_val - img_min_val)\n",
        "            img_to_pil = img_normalized_255.astype(np.uint8)\n",
        "        else:\n",
        "            img_to_pil = np.zeros_like(img_array, dtype=np.uint8)\n",
        "    else:\n",
        "        img_to_pil = img_array.astype(np.uint8) # Already good\n",
        "\n",
        "    print(f\"  Array for PIL - Shape: {img_to_pil.shape}, dtype: {img_to_pil.dtype}\")\n",
        "    # numpy_array_for_processor = img_to_pil.copy() # This was already set after convert_pixel_data\n",
        "\n",
        "    # 3. PIL Image Conversion\n",
        "    print(\"\\nDEBUG: Converting to PIL Image...\")\n",
        "    try:\n",
        "        if len(img_to_pil.shape) == 3 and img_to_pil.shape[-1] == 3:\n",
        "            pil_image_for_processor = Image.fromarray(img_to_pil, mode='RGB')\n",
        "            print(f\"  PIL Image created. Mode: {pil_image_for_processor.mode}, Size: {pil_image_for_processor.size}\")\n",
        "            # (Save image logic can remain)\n",
        "            save_path = f\"/content/debug_pil_image_{os.path.basename(path)}.png\"\n",
        "            pil_image_for_processor.save(save_path)\n",
        "            print(f\"  DEBUG: Saved intermediate PIL image to {save_path}\")\n",
        "        else:\n",
        "            print(f\"  Array for PIL has unexpected shape: {img_to_pil.shape}. Cannot create RGB PIL image.\")\n",
        "            return None\n",
        "    except Exception as e_pil_create:\n",
        "        print(f\"  DEBUG: Error creating PIL image: {e_pil_create}\")\n",
        "        return None\n",
        "\n",
        "    # 4. MedGemma Processor - Attempt 1: Using direct image_processor with PIL Image\n",
        "    if pil_image_for_processor:\n",
        "        print(\"\\nDEBUG: Applying actual_image_processor (Attempt 1: with PIL Image)...\")\n",
        "        try:\n",
        "            # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "            # CRITICAL CHANGE: Use actual_image_processor directly\n",
        "            # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "            inputs_pil = actual_image_processor(images=pil_image_for_processor, return_tensors=\"pt\")\n",
        "            # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "\n",
        "            if inputs_pil is None: # Some image processors might return None on failure\n",
        "                print(\"  DEBUG (PIL with actual_image_processor): actual_image_processor returned None.\")\n",
        "                # Try with NumPy array if PIL failed\n",
        "            elif 'pixel_values' not in inputs_pil or inputs_pil['pixel_values'] is None:\n",
        "                print(\"  DEBUG (PIL with actual_image_processor): 'pixel_values' not in output or is None.\")\n",
        "                # Try with NumPy array\n",
        "            else:\n",
        "                processed_tensor_pil = inputs_pil['pixel_values'].squeeze(0) # Squeeze only if batched\n",
        "                if len(processed_tensor_pil.shape) == 4 and processed_tensor_pil.shape[0] == 1: # Check if it added a batch dim\n",
        "                    processed_tensor_pil = processed_tensor_pil.squeeze(0)\n",
        "\n",
        "                print(\"  DEBUG (PIL with actual_image_processor): Processing successful.\")\n",
        "                print(f\"    Processed tensor shape: {processed_tensor_pil.shape}, dtype: {processed_tensor_pil.dtype}\")\n",
        "                print(f\"    Processed tensor min: {processed_tensor_pil.min().item()}, max: {processed_tensor_pil.max().item()}\")\n",
        "                if not torch.all(processed_tensor_pil == 0):\n",
        "                    return processed_tensor_pil # SUCCESS!\n",
        "                else:\n",
        "                    print(\"    WARNING (PIL with actual_image_processor): Processed tensor is ALL ZEROS.\")\n",
        "                    # Fall through to try NumPy array\n",
        "        except Exception as e_proc_pil_direct:\n",
        "            print(f\"  DEBUG (PIL with actual_image_processor): Error: {e_proc_pil_direct}\")\n",
        "            # Fall through to try NumPy array\n",
        "\n",
        "    # 4. MedGemma Processor - Attempt 2: Using direct image_processor with NumPy array\n",
        "    if numpy_array_for_processor is not None and \\\n",
        "       (len(numpy_array_for_processor.shape) == 3 and numpy_array_for_processor.shape[-1] == 3):\n",
        "        print(\"\\nDEBUG: Applying actual_image_processor (Attempt 2: with NumPy Array)...\")\n",
        "        print(f\"  NumPy array shape: {numpy_array_for_processor.shape}, dtype: {numpy_array_for_processor.dtype} (This is likely uint8 HWC)\")\n",
        "        try:\n",
        "            # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "            # CRITICAL CHANGE: Use actual_image_processor directly\n",
        "            # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "            inputs_np = actual_image_processor(images=numpy_array_for_processor, return_tensors=\"pt\")\n",
        "            # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "\n",
        "            if inputs_np is None:\n",
        "                print(\"  DEBUG (NumPy with actual_image_processor): actual_image_processor returned None.\")\n",
        "                return None\n",
        "            elif 'pixel_values' not in inputs_np or inputs_np['pixel_values'] is None:\n",
        "                print(\"  DEBUG (NumPy with actual_image_processor): 'pixel_values' not in output or is None.\")\n",
        "                return None\n",
        "            else:\n",
        "                processed_tensor_np = inputs_np['pixel_values'] # Don't squeeze yet\n",
        "                if len(processed_tensor_np.shape) == 4 and processed_tensor_np.shape[0] == 1: # Check if it added a batch dim\n",
        "                    processed_tensor_np = processed_tensor_np.squeeze(0)\n",
        "\n",
        "                print(\"  DEBUG (NumPy with actual_image_processor): Processing successful.\")\n",
        "                print(f\"    Processed tensor shape: {processed_tensor_np.shape}, dtype: {processed_tensor_np.dtype}\")\n",
        "                print(f\"    Processed tensor min: {processed_tensor_np.min().item()}, max: {processed_tensor_np.max().item()}\")\n",
        "                if not torch.all(processed_tensor_np == 0):\n",
        "                    return processed_tensor_np # SUCCESS!\n",
        "                else:\n",
        "                    print(\"    WARNING (NumPy with actual_image_processor): Processed tensor is ALL ZEROS.\")\n",
        "                    return None # Return None if still zeros\n",
        "        except Exception as e_proc_np_direct:\n",
        "            print(f\"  DEBUG (NumPy with actual_image_processor): Error: {e_proc_np_direct}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"\\nDEBUG: NumPy array not suitable for processor attempt (not 3-channel RGB).\")\n",
        "        return None\n",
        "\n",
        "    print(\"DEBUG: All attempts with actual_image_processor failed or resulted in zeros.\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# --- The block to call the DEBUG function remains the same ---\n",
        "# (in Cell 7.1, after the function definition)\n",
        "if 'train_df' in locals() and not train_df.empty and medgemma_processor is not None:\n",
        "    if len(train_df) > 0:\n",
        "        path_to_debug = train_df.iloc[0]['image_path']\n",
        "        print(f\"\\n>>> Initiating DEBUG for path: {path_to_debug} <<<\")\n",
        "        debug_output_tensor = load_dicom_image_medgemma_DEBUG(path_to_debug, medgemma_processor) # Pass the main processor\n",
        "        if debug_output_tensor is not None:\n",
        "            print(f\"\\n>>> DEBUG Result for {path_to_debug}: Tensor received, shape {debug_output_tensor.shape}, min {debug_output_tensor.min().item():.2f}, max {debug_output_tensor.max().item():.2f}\")\n",
        "        else:\n",
        "            print(f\"\\n>>> DEBUG Result for {path_to_debug}: Function returned None (Error occurred)\")\n",
        "    else:\n",
        "        print(\"train_df is empty, cannot select a path for debugging.\")\n",
        "else:\n",
        "    print(\"Could not run debug: train_df or medgemma_processor (main) not available.\")\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3ihfaRw9KGq",
        "outputId": "c1d531c8-8bde-403a-ae78-e6b670795a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> Initiating DEBUG for path: /content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230809.2448.36605.dcm <<<\n",
            "\n",
            "--- Debugging load_dicom_image_medgemma_DEBUG for: /content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230809.2448.36605.dcm ---\n",
            "DEBUG: Using actual_image_processor: <class 'transformers.models.gemma3.image_processing_gemma3.Gemma3ImageProcessor'>\n",
            "DEBUG: Attempting pydicom.dcmread(path)...\n",
            "  DICOM PhotometricInterpretation: YBR_FULL_422\n",
            "DEBUG: Attempting to get pixel data via dcm.convert_pixel_data()...\n",
            "  DEBUG: dcm.pixel_array after convert_pixel_data(). Shape: (1804, 3223, 3), dtype: uint8\n",
            "\n",
            "DEBUG: Normalizing to 0-255 range (if necessary)...\n",
            "  Array for PIL - Shape: (1804, 3223, 3), dtype: uint8\n",
            "\n",
            "DEBUG: Converting to PIL Image...\n",
            "  PIL Image created. Mode: RGB, Size: (3223, 1804)\n",
            "  DEBUG: Saved intermediate PIL image to /content/debug_pil_image_1004_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230809.2448.36605.dcm.png\n",
            "\n",
            "DEBUG: Applying actual_image_processor (Attempt 1: with PIL Image)...\n",
            "  DEBUG (PIL with actual_image_processor): Processing successful.\n",
            "    Processed tensor shape: torch.Size([3, 896, 896]), dtype: torch.float32\n",
            "    Processed tensor min: -1.0, max: 1.0\n",
            "\n",
            ">>> DEBUG Result for /content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230809.2448.36605.dcm: Tensor received, shape torch.Size([3, 896, 896]), min -1.00, max 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 7: PyTorch Dataset and DataLoader Implementation\n",
        "# This cell contains the FINAL working versions of the image loading function\n",
        "# and the PyTorch Dataset class, based on our debugging.\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# --- FINAL Image Loading Function for MedGemma ---\n",
        "def load_dicom_image_medgemma(path, processor_obj): # processor_obj is the main Gemma3Processor\n",
        "    \"\"\"\n",
        "    Loads a DICOM image, handles photometric interpretation (via convert_pixel_data),\n",
        "    converts to PIL, and then preprocesses it using the MedGemma model's\n",
        "    specific image_processor component.\n",
        "    \"\"\"\n",
        "    if processor_obj is None:\n",
        "        # print(f\"Error: Main processor object is None for path {path}.\") # Optional: for verbose dataset error logging\n",
        "        return None\n",
        "\n",
        "    if not hasattr(processor_obj, 'image_processor') or processor_obj.image_processor is None:\n",
        "        # print(f\"Error: Main processor {type(processor_obj)} does not have 'image_processor' for path {path}.\") # Optional\n",
        "        return None\n",
        "\n",
        "    actual_image_processor = processor_obj.image_processor\n",
        "\n",
        "    # 1. Pydicom Read and convert_pixel_data\n",
        "    try:\n",
        "        dcm = pydicom.dcmread(path, force=True) # force=True can help with some slightly non-compliant files\n",
        "        # It's crucial to call convert_pixel_data() to apply Modality LUTs, VOI LUTs (if any),\n",
        "        # and handle Photometric Interpretation to get a displayable pixel array.\n",
        "        dcm.convert_pixel_data()\n",
        "        img_array = dcm.pixel_array # This should now be more directly usable (e.g., RGB or MONOCHROME)\n",
        "\n",
        "        # Ensure the array is uint8 for PIL conversion, common after convert_pixel_data for visual formats\n",
        "        # If it's not, there might be an issue with how convert_pixel_data handled this specific DICOM\n",
        "        if img_array.dtype != np.uint8:\n",
        "            # Attempt to scale to uint8 if it's a different type (e.g. int16, float)\n",
        "            # This is a basic scaling, more sophisticated windowing might be needed for some MONOCHROME images\n",
        "            # if dcm.PhotometricInterpretation in [\"MONOCHROME1\", \"MONOCHROME2\"]\n",
        "            if np.issubdtype(img_array.dtype, np.floating) or np.issubdtype(img_array.dtype, np.integer):\n",
        "                img_min = np.min(img_array)\n",
        "                img_max = np.max(img_array)\n",
        "                if img_max - img_min > 1e-6:\n",
        "                    img_array = 255.0 * (img_array - img_min) / (img_max - img_min)\n",
        "                else:\n",
        "                    img_array = np.zeros_like(img_array) # Flat image\n",
        "            img_array = img_array.astype(np.uint8)\n",
        "\n",
        "    except Exception: # as e_dicom:\n",
        "        # print(f\"Pydicom read or convert_pixel_data error for {path}: {e_dicom}\") # Optional\n",
        "        return None\n",
        "\n",
        "    # 2. PIL Image Conversion\n",
        "    pil_image = None\n",
        "    try:\n",
        "        if len(img_array.shape) == 3 and img_array.shape[-1] == 3: # Expecting HWC uint8 (RGB)\n",
        "            pil_image = Image.fromarray(img_array, mode='RGB')\n",
        "        elif len(img_array.shape) == 2: # Grayscale (e.g., MONOCHROME2)\n",
        "            pil_image = Image.fromarray(img_array, mode='L').convert('RGB') # Convert L to RGB for consistency\n",
        "        else:\n",
        "            # print(f\"Array for PIL has unexpected shape: {img_array.shape} for path {path}.\") # Optional\n",
        "            return None\n",
        "    except Exception: # as e_pil:\n",
        "        # print(f\"Error creating PIL image for {path}: {e_pil}\") # Optional\n",
        "        return None\n",
        "\n",
        "    if pil_image is None:\n",
        "        return None # Should have been caught by returns above, but as a safeguard\n",
        "\n",
        "    # 3. Using the actual_image_processor (e.g., Gemma3ImageProcessor's image_processor component)\n",
        "    try:\n",
        "        inputs = actual_image_processor(images=pil_image, return_tensors=\"pt\")\n",
        "\n",
        "        if inputs is None or 'pixel_values' not in inputs or inputs['pixel_values'] is None:\n",
        "            # print(f\"actual_image_processor returned None or no pixel_values for path {path}.\") # Optional\n",
        "            return None\n",
        "\n",
        "        processed_tensor = inputs['pixel_values']\n",
        "        # The processor might return a batched tensor [1, C, H, W] or unbatched [C, H, W]\n",
        "        # Squeeze if a batch dimension of 1 was added.\n",
        "        if len(processed_tensor.shape) == 4 and processed_tensor.shape[0] == 1:\n",
        "            processed_tensor = processed_tensor.squeeze(0)\n",
        "\n",
        "        # Final check for expected 3 dimensions [C,H,W]\n",
        "        if len(processed_tensor.shape) != 3:\n",
        "            # print(f\"Processed tensor has unexpected shape {processed_tensor.shape} for path {path}.\") # Optional\n",
        "            return None\n",
        "\n",
        "        return processed_tensor\n",
        "    except Exception: # as e_proc:\n",
        "        # print(f\"Error during actual_image_processor call for {path}: {e_proc}\") # Optional\n",
        "        return None\n",
        "\n",
        "# --- Custom PyTorch Dataset ---\n",
        "class RetinalLdlDatasetPyTorch(Dataset):\n",
        "    def __init__(self, df_input, processor_ref, scaled_ldl_col_name='LDL_scaled'):\n",
        "        self.df = df_input.reset_index(drop=True)\n",
        "        self.processor = processor_ref # This is the main medgemma_processor (Gemma3Processor instance)\n",
        "        self.scaled_ldl_col = scaled_ldl_col_name\n",
        "\n",
        "        if self.processor is None:\n",
        "            raise ValueError(\"MedGemma processor (processor_ref) has not been loaded or passed correctly. Check Cell 5.\")\n",
        "        if self.scaled_ldl_col not in self.df.columns:\n",
        "            raise ValueError(f\"Scaled LDL column '{self.scaled_ldl_col}' not found in DataFrame. Check Cell 6.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        row = self.df.iloc[idx]\n",
        "        image_path = row['image_path']\n",
        "\n",
        "        # Call the corrected image loading function\n",
        "        image_tensor = load_dicom_image_medgemma(image_path, self.processor)\n",
        "\n",
        "        if image_tensor is None:\n",
        "            # Fallback: return a placeholder (zeros)\n",
        "            # Use TARGET_SIZE_MEDGEMMA which should be set in Cell 5\n",
        "            num_channels = 3 # Assume 3 for RGB\n",
        "            if hasattr(self.processor, 'image_processor') and hasattr(self.processor.image_processor, 'num_channels'):\n",
        "                 num_channels = self.processor.image_processor.num_channels\n",
        "\n",
        "            height, width = TARGET_SIZE_MEDGEMMA # This variable is from Cell 5\n",
        "            # print(f\"Warning: Failed to load image {image_path} for index {idx}. Returning zeros of shape ({num_channels}, {height}, {width}).\") # Optional\n",
        "            image_tensor = torch.zeros((num_channels, height, width), dtype=torch.float32)\n",
        "            ldl_value_scaled = torch.tensor(0.0, dtype=torch.float32) # Neutral placeholder for label\n",
        "        else:\n",
        "            ldl_value_scaled = torch.tensor(row[self.scaled_ldl_col], dtype=torch.float32)\n",
        "\n",
        "        return {\"pixel_values\": image_tensor, \"labels\": ldl_value_scaled}\n",
        "\n",
        "# --- Create Dataset and DataLoader instances ---\n",
        "# These will be re-initialized here using the final load_dicom_image_medgemma\n",
        "train_dataset_pytorch, val_dataset_pytorch, test_dataset_pytorch = None, None, None\n",
        "train_dataloader, val_dataloader, test_dataloader = None, None, None\n",
        "\n",
        "# Ensure processor is loaded (from Cell 5) and DataFrames are ready (from Cell 6)\n",
        "if 'medgemma_processor' in locals() and medgemma_processor is not None:\n",
        "    MEDGEMMA_BATCH_SIZE = 4 # You can adjust this\n",
        "    print(f\"\\nRe-creating Datasets and DataLoaders with final image loading logic. Batch size: {MEDGEMMA_BATCH_SIZE}\")\n",
        "\n",
        "    if 'train_df' in locals() and not train_df.empty and 'LDL_scaled' in train_df.columns:\n",
        "        try:\n",
        "            train_dataset_pytorch = RetinalLdlDatasetPyTorch(\n",
        "                df_input=train_df,\n",
        "                processor_ref=medgemma_processor,\n",
        "                scaled_ldl_col_name='LDL_scaled'\n",
        "            )\n",
        "            # Set num_workers=0 if you encounter issues with multiprocessing on Colab, especially on CPU runtime\n",
        "            # For GPU, num_workers=2 is usually fine.\n",
        "            num_dataloader_workers = 2 if torch.cuda.is_available() else 0\n",
        "            train_dataloader = DataLoader(train_dataset_pytorch, batch_size=MEDGEMMA_BATCH_SIZE, shuffle=True, num_workers=num_dataloader_workers, pin_memory=torch.cuda.is_available(), drop_last=True)\n",
        "            print(f\"Train PyTorch Dataset created with {len(train_dataset_pytorch)} samples.\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Error creating train_dataset_pytorch: {e}\")\n",
        "    else:\n",
        "        print(\"Train DataFrame not ready or 'LDL_scaled' missing. Cannot create train_dataset_pytorch.\")\n",
        "\n",
        "    if 'val_df' in locals() and not val_df.empty and 'LDL_scaled' in val_df.columns:\n",
        "        try:\n",
        "            val_dataset_pytorch = RetinalLdlDatasetPyTorch(\n",
        "                df_input=val_df,\n",
        "                processor_ref=medgemma_processor,\n",
        "                scaled_ldl_col_name='LDL_scaled'\n",
        "            )\n",
        "            val_dataloader = DataLoader(val_dataset_pytorch, batch_size=MEDGEMMA_BATCH_SIZE, shuffle=False, num_workers=num_dataloader_workers, pin_memory=torch.cuda.is_available())\n",
        "            print(f\"Validation PyTorch Dataset created with {len(val_dataset_pytorch)} samples.\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Error creating val_dataset_pytorch: {e}\")\n",
        "    else:\n",
        "        print(\"Validation DataFrame not ready or 'LDL_scaled' missing. Cannot create val_dataset_pytorch.\")\n",
        "\n",
        "    # Test DataLoader is optional here but good for completeness\n",
        "    if 'test_df' in locals() and not test_df.empty and 'LDL_scaled' in test_df.columns:\n",
        "        try:\n",
        "            test_dataset_pytorch = RetinalLdlDatasetPyTorch(\n",
        "                df_input=test_df,\n",
        "                processor_ref=medgemma_processor,\n",
        "                scaled_ldl_col_name='LDL_scaled'\n",
        "            )\n",
        "            test_dataloader = DataLoader(test_dataset_pytorch, batch_size=MEDGEMMA_BATCH_SIZE, shuffle=False, num_workers=num_dataloader_workers, pin_memory=torch.cuda.is_available())\n",
        "            print(f\"Test PyTorch Dataset created with {len(test_dataset_pytorch)} samples.\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Error creating test_dataset_pytorch: {e}\")\n",
        "    else:\n",
        "        print(\"Test DataFrame not ready or 'LDL_scaled' missing. Cannot create test_dataset_pytorch.\")\n",
        "else:\n",
        "    print(\"MedGemma processor not loaded (Cell 5 likely failed). Cannot create PyTorch Datasets/DataLoaders.\")\n",
        "\n",
        "\n",
        "# --- Optional: Test one batch from DataLoader ---\n",
        "if train_dataloader is not None and len(train_dataloader) > 0:\n",
        "    print(\"\\nAttempting to get one batch from train_dataloader (with final logic)...\")\n",
        "    try:\n",
        "        sample_batch = next(iter(train_dataloader))\n",
        "        images = sample_batch['pixel_values']\n",
        "        labels = sample_batch['labels']\n",
        "        print(\"Sample batch loaded successfully.\")\n",
        "        print(f\"  Images shape: {images.shape}\")\n",
        "        print(f\"  Images dtype: {images.dtype}\")\n",
        "        print(f\"  Labels shape: {labels.shape}\")\n",
        "        print(f\"  Labels dtype: {labels.dtype}\")\n",
        "        if images.numel() > 0 : print(f\"  First image min/max/mean: {images[0].min().item():.2f} / {images[0].max().item():.2f} / {images[0].mean().item():.2f}\")\n",
        "        if labels.numel() > 0 : print(f\"  First label (scaled): {labels[0].item():.2f}\")\n",
        "\n",
        "        # Count how many images in the batch are all zeros (placeholders)\n",
        "        zero_images_in_batch = 0\n",
        "        for i in range(images.shape[0]):\n",
        "            if torch.all(images[i] == 0):\n",
        "                zero_images_in_batch += 1\n",
        "        if zero_images_in_batch > 0:\n",
        "            print(f\"  WARNING: {zero_images_in_batch}/{images.shape[0]} images in this batch are placeholders (all zeros).\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error while testing train_dataloader: {e}\")\n",
        "else:\n",
        "    print(\"\\nTrain DataLoader not created or is empty, cannot test a batch.\")\n",
        "\n",
        "print(\"\\nCell 7: Final PyTorch Dataset and DataLoader implementation complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sagg4NTCxoj1",
        "outputId": "58e6a19f-4dd1-4b81-eb1e-c6a5009b4136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Re-creating Datasets and DataLoaders with final image loading logic. Batch size: 4\n",
            "Train PyTorch Dataset created with 681 samples.\n",
            "Validation PyTorch Dataset created with 145 samples.\n",
            "Test PyTorch Dataset created with 147 samples.\n",
            "\n",
            "Attempting to get one batch from train_dataloader (with final logic)...\n",
            "Sample batch loaded successfully.\n",
            "  Images shape: torch.Size([4, 3, 896, 896])\n",
            "  Images dtype: torch.float32\n",
            "  Labels shape: torch.Size([4])\n",
            "  Labels dtype: torch.float32\n",
            "  First image min/max/mean: -1.00 / 1.00 / -0.54\n",
            "  First label (scaled): -0.13\n",
            "\n",
            "Cell 7: Final PyTorch Dataset and DataLoader implementation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Congratulations! You now have a fully functional, end-to-end PyTorch data pipeline that:\n",
        "Correctly loads your DICOM images.\n",
        "Handles the YBR_FULL_422 photometric interpretation using dcm.convert_pixel_data().\n",
        "Converts them to PIL images.\n",
        "Uses the specific image_processor component of the medgemma_processor (which is a Gemma3ImageProcessor configured for MedGemma's vision needs) to preprocess the images into the correct format, size, and normalization range for MedGemma.\n",
        "Normalizes your LDL target values.\n",
        "Batches the data efficiently using DataLoader.\n",
        "This is a major milestone. The \"data\" part, which is often the trickiest, is now solid.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "BwYi3pGMyJYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Ravikrishnan05/PrediscanMedtech_project.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paEIRY2Xz4pE",
        "outputId": "c1f74538-d636-461d-fdaa-a81e6f2967f7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PrediscanMedtech_project'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 9 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (9/9), 12.99 KiB | 302.00 KiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6UIdx0Z0Sww",
        "outputId": "750beaa3-e6eb-4471-818c-5ae800db8dd1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PrediscanMedtech_project  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv Megamma_from_scrach_with_google.ipynb PrediscanMedtech_project/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu5iP3Ef0Cn9",
        "outputId": "3ae494b1-fd3c-4d9d-f69a-b4628cd0e9f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'Megamma_from_scrach_with_google.ipynb': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add this temporarily after Cell 7 to inspect\n",
        "if train_dataset_pytorch:\n",
        "    print(\"\\nInspecting first few samples from train_dataset_pytorch:\")\n",
        "    for i in range(min(5, len(train_dataset_pytorch))):\n",
        "        try:\n",
        "            sample = train_dataset_pytorch[i]\n",
        "            img_tensor = sample['pixel_values']\n",
        "            lbl_tensor = sample['labels']\n",
        "            print(f\"Sample {i}: img_shape={img_tensor.shape}, img_min={img_tensor.min().item():.2f}, img_max={img_tensor.max().item():.2f}, scaled_label={lbl_tensor.item():.2f}\")\n",
        "            if img_tensor.min().item() == 0.0 and img_tensor.max().item() == 0.0 and lbl_tensor.item() == 0.0:\n",
        "                # Try to get the original path to see which image is causing issues\n",
        "                original_row = train_df.iloc[i]\n",
        "                print(f\"  ^-- Might be a placeholder. Original path: {original_row['image_path']}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error inspecting sample {i}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htJSpOeeBSAr",
        "outputId": "5bb56ec9-0fd9-4b0d-d165-8acacc63e17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Inspecting first few samples from train_dataset_pytorch:\n",
            "Sample 0: img_shape=torch.Size([3, 896, 896]), img_min=0.00, img_max=0.00, scaled_label=0.00\n",
            "  ^-- Might be a placeholder. Original path: /content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_l_1.2.826.0.1.3680043.8.641.1.20230809.2436.96446.dcm\n",
            "Sample 1: img_shape=torch.Size([3, 896, 896]), img_min=0.00, img_max=0.00, scaled_label=0.00\n",
            "  ^-- Might be a placeholder. Original path: /content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230809.2448.36605.dcm\n",
            "Sample 2: img_shape=torch.Size([3, 896, 896]), img_min=0.00, img_max=0.00, scaled_label=0.00\n",
            "  ^-- Might be a placeholder. Original path: /content/medgemma_extracted_images/1000/1007/1007_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230824.20355.67485.dcm\n",
            "Sample 3: img_shape=torch.Size([3, 896, 896]), img_min=0.00, img_max=0.00, scaled_label=0.00\n",
            "  ^-- Might be a placeholder. Original path: /content/medgemma_extracted_images/1000/1011/1011_eidon_mosaic_cfp_l_1.2.826.0.1.3680043.8.641.1.20230824.20119.99904.dcm\n",
            "Sample 4: img_shape=torch.Size([3, 896, 896]), img_min=0.00, img_max=0.00, scaled_label=0.00\n",
            "  ^-- Might be a placeholder. Original path: /content/medgemma_extracted_images/1000/1011/1011_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230824.20131.92049.dcm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1dphRbGC0BU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(LOCAL_CSV_PATH)\n",
        "#Drop everything column other than person id and LDL\n",
        "\n",
        "print(df.columns[20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIHjiw5VsAS_",
        "outputId": "0ff2729b-f184-4ae0-a04b-ae18dc06889a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDL Cholesterol Calculation (mg/dL)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"LDL Cholesterol Calculation (mg/dL)\"]\n",
        "print(df[\"LDL Cholesterol Calculation (mg/dL)\"].isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUgTulnLsGfI",
        "outputId": "ca0b6150-5d96-4e4b-faf3-46c5aeb05522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = df.dropna(subset=[\"LDL Cholesterol Calculation (mg/dL)\"])\n",
        "print(df_clean.shape)  # Should be 41 rows fewer\n",
        "\n",
        "print(df_clean[\"LDL Cholesterol Calculation (mg/dL)\"].isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdQRqv_VsKj0",
        "outputId": "604ad0ac-9b81-4fe3-8e6b-4f7001bac83d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1026, 111)\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#write code to find number of folders inside /content/extracted_images/1000\n",
        "import os\n",
        "folder_count = len(os.listdir(LOCAL_IMAGES_ROOT))\n",
        "print(f\"Number of folders in {LOCAL_IMAGES_ROOT}: {folder_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ntEBAS_sONb",
        "outputId": "76a0a902-1b8e-4c29-ff50-33241da9c0ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of folders in /content/extracted_images/1000: 541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------\n",
        "# Cell 3: Load and Filter Clinical Data (STEP 1)\n",
        "# --------------------------------------------------\n",
        "\n",
        "if not os.path.exists(clinical_csv_path):\n",
        "    print(f\"FATAL ERROR: Clinical CSV file not found at the expected local path: {clinical_csv_path}\")\n",
        "    # You might need to re-run Cell 2 or check paths\n",
        "else:\n",
        "    df = pd.read_csv(clinical_csv_path)\n",
        "    print(f\"Initial number of rows in clinical data: {len(df)}\")\n",
        "\n",
        "    ldl_column_name = \"LDL Cholesterol Calculation (mg/dL)\" # Make sure this matches your CSV header\n",
        "\n",
        "    # Data Cleaning\n",
        "    if ldl_column_name not in df.columns:\n",
        "        print(f\"ERROR: LDL column '{ldl_column_name}' not found in CSV. Available columns: {df.columns.tolist()}\")\n",
        "    else:\n",
        "        print(f\"Original LDL dtype: {df[ldl_column_name].dtype}\")\n",
        "        df[ldl_column_name] = pd.to_numeric(df[ldl_column_name], errors='coerce')\n",
        "        print(f\"Number of NaNs in '{ldl_column_name}' before explicit drop: {df[ldl_column_name].isnull().sum()}\")\n",
        "        df.dropna(subset=[ldl_column_name], inplace=True)\n",
        "        print(f\"Number of rows after dropping NaNs in '{ldl_column_name}': {len(df)}\")\n",
        "        if df[ldl_column_name].isnull().sum() > 0:\n",
        "            print(f\"WARNING: NaNs still present in '{ldl_column_name}' after dropna.\")\n",
        "        else:\n",
        "            print(f\"Successfully removed/handled NaNs from '{ldl_column_name}'.\")\n",
        "\n",
        "        # Ensure person_id is string for matching with folder names\n",
        "        if 'person_id' not in df.columns:\n",
        "            print(f\"ERROR: 'person_id' column not found in CSV. Available columns: {df.columns.tolist()}\")\n",
        "        else:\n",
        "            df['person_id'] = df['person_id'].astype(str)\n",
        "            ldl_lookup = df.set_index('person_id')[ldl_column_name].to_dict()\n",
        "\n",
        "            # Filter valid person_ids based on available image folders\n",
        "            if not os.path.exists(images_root_path) or not os.path.isdir(images_root_path):\n",
        "                print(f\"FATAL ERROR: Images root path '{images_root_path}' does not exist or is not a directory.\")\n",
        "            else:\n",
        "                available_folders = set(os.listdir(images_root_path))\n",
        "                print(f\"Found {len(available_folders)} folders in images_root_path: {list(available_folders)[:5]}...\") # Print a few\n",
        "\n",
        "                valid_ids_clinical = set(ldl_lookup.keys())\n",
        "                print(f\"Found {len(valid_ids_clinical)} unique person_ids with LDL data in CSV.\")\n",
        "\n",
        "                valid_ids = sorted(list(valid_ids_clinical & available_folders))\n",
        "                print(f\"Found {len(valid_ids)} common person_ids between CSV and image folders.\")\n",
        "\n",
        "                if not valid_ids:\n",
        "                    print(\"ERROR: No common person_ids found. Check 'person_id' format in CSV and folder names, and paths.\")\n",
        "                else:\n",
        "                    image_records = []\n",
        "                    for idx, person_id in enumerate(valid_ids, 1):\n",
        "                        folder_path = os.path.join(images_root_path, person_id)\n",
        "                        ldl_value = ldl_lookup[person_id]\n",
        "                        if pd.isna(ldl_value): continue # Should be caught already\n",
        "\n",
        "                        if os.path.isdir(folder_path): # Ensure it's a directory\n",
        "                            for filename in os.listdir(folder_path):\n",
        "                                if filename.lower().endswith(\".dcm\"):\n",
        "                                    image_path = os.path.join(folder_path, filename)\n",
        "                                    image_records.append({\n",
        "                                        \"person_id\": person_id,\n",
        "                                        \"image_path\": image_path,\n",
        "                                        \"LDL\": ldl_value\n",
        "                                    })\n",
        "                        if idx % (len(valid_ids)//10 if len(valid_ids) > 10 else 1) == 0 or idx == len(valid_ids): # Progress print\n",
        "                             print(f\"[{idx}/{len(valid_ids)}] Processed patient ID: {person_id}\")\n",
        "\n",
        "\n",
        "                    image_df = pd.DataFrame(image_records)\n",
        "                    print(f\"Total image samples mapped: {len(image_df)}\")\n",
        "                    if not image_df.empty:\n",
        "                        print(f\"Number of NaNs in final image_df['LDL']: {image_df['LDL'].isnull().sum()}\")\n",
        "                        if image_df['LDL'].isnull().sum() > 0:\n",
        "                            image_df.dropna(subset=['LDL'], inplace=True)\n",
        "                            print(f\"Total image samples after final LDL NaN drop: {len(image_df)}\")\n",
        "                        print(\"Sample of image_df:\")\n",
        "                        print(image_df.head())\n",
        "                    else:\n",
        "                        print(\"ERROR: image_df is empty. No DICOM images found or linked.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IobevGdHsQEC",
        "outputId": "1ada9fcd-f23e-46f8-ca74-be8b446c9a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial number of rows in clinical data: 1067\n",
            "Original LDL dtype: float64\n",
            "Number of NaNs in 'LDL Cholesterol Calculation (mg/dL)' before explicit drop: 41\n",
            "Number of rows after dropping NaNs in 'LDL Cholesterol Calculation (mg/dL)': 1026\n",
            "Successfully removed/handled NaNs from 'LDL Cholesterol Calculation (mg/dL)'.\n",
            "Found 541 folders in images_root_path: ['7162', '7398', '1157', '7192', '1072']...\n",
            "Found 1026 unique person_ids with LDL data in CSV.\n",
            "Found 528 common person_ids between CSV and image folders.\n",
            "[52/528] Processed patient ID: 1129\n",
            "[104/528] Processed patient ID: 1222\n",
            "[156/528] Processed patient ID: 1313\n",
            "[208/528] Processed patient ID: 4009\n",
            "[260/528] Processed patient ID: 4180\n",
            "[312/528] Processed patient ID: 4298\n",
            "[364/528] Processed patient ID: 7093\n",
            "[416/528] Processed patient ID: 7185\n",
            "[468/528] Processed patient ID: 7286\n",
            "[520/528] Processed patient ID: 7398\n",
            "[528/528] Processed patient ID: 7409\n",
            "Total image samples mapped: 974\n",
            "Number of NaNs in final image_df['LDL']: 0\n",
            "Sample of image_df:\n",
            "  person_id                                         image_path         LDL\n",
            "0      1002  /content/extracted_images/1000/1002/1002_eidon...  133.485054\n",
            "1      1004  /content/extracted_images/1000/1004/1004_eidon...   59.674544\n",
            "2      1004  /content/extracted_images/1000/1004/1004_eidon...   59.674544\n",
            "3      1005  /content/extracted_images/1000/1005/1005_eidon...   74.956702\n",
            "4      1007  /content/extracted_images/1000/1007/1007_eidon...   92.278412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_df.info()\n",
        "image_df.head(5)\n",
        "\n",
        "#print(image_df[image_df[\"LDL\"]<=0])\n",
        "\n",
        "#remove the negative ldl row and update the image_df\n",
        "#drop the row\n",
        "#give code\n",
        "\n",
        "image_df = image_df[image_df[\"LDL\"] > 0]\n",
        "print(image_df[image_df[\"LDL\"]<=0])\n",
        "print(image_df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3ugsdLQsXQW",
        "outputId": "0846266b-c40e-41f5-bc1a-679837f679de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 973 entries, 0 to 973\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   person_id   973 non-null    object \n",
            " 1   image_path  973 non-null    object \n",
            " 2   LDL         973 non-null    float64\n",
            "dtypes: float64(1), object(2)\n",
            "memory usage: 30.4+ KB\n",
            "Empty DataFrame\n",
            "Columns: [person_id, image_path, LDL]\n",
            "Index: []\n",
            "Empty DataFrame\n",
            "Columns: [person_id, image_path, LDL]\n",
            "Index: []\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 973 entries, 0 to 973\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   person_id   973 non-null    object \n",
            " 1   image_path  973 non-null    object \n",
            " 2   LDL         973 non-null    float64\n",
            "dtypes: float64(1), object(2)\n",
            "memory usage: 30.4+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zIV-66xzsbJj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}