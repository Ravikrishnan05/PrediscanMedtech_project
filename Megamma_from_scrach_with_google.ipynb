{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNYO9d8Rb7E3hicnBsDkQSv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bd8fd1272acc46d994cdcd4103370faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9f986847ba641fab65a234e9d1904b0",
              "IPY_MODEL_04d0e95d28514957aca9944b75ea1268",
              "IPY_MODEL_af89b9528dc844778d3b5179042706fe"
            ],
            "layout": "IPY_MODEL_37b9c19aa8984b69861d3fc676711ee3"
          }
        },
        "b9f986847ba641fab65a234e9d1904b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1bd4e0424aa44809c733022f1ce73f8",
            "placeholder": "​",
            "style": "IPY_MODEL_fe9a6943e8aa4c71b3f6ff6bced717fd",
            "value": "processor_config.json: 100%"
          }
        },
        "04d0e95d28514957aca9944b75ea1268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cee17d4fe7e7474bba6b8a2978d69caa",
            "max": 70,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7458c0ea2bfe4fcdab64df17d752a1e1",
            "value": 70
          }
        },
        "af89b9528dc844778d3b5179042706fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa7547c207b54983bcc1869c57b65fba",
            "placeholder": "​",
            "style": "IPY_MODEL_52a4f7d3dfb64386a045c0b366f3c280",
            "value": " 70.0/70.0 [00:00&lt;00:00, 7.41kB/s]"
          }
        },
        "37b9c19aa8984b69861d3fc676711ee3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1bd4e0424aa44809c733022f1ce73f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe9a6943e8aa4c71b3f6ff6bced717fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cee17d4fe7e7474bba6b8a2978d69caa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7458c0ea2bfe4fcdab64df17d752a1e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa7547c207b54983bcc1869c57b65fba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52a4f7d3dfb64386a045c0b366f3c280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c0d18fb277d4cca92bed4a4a346ffcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f63ac26289f548a88d75553b7f7257bf",
              "IPY_MODEL_872b9df246954c0aa0b4bc565cdd7b9a",
              "IPY_MODEL_12986ff6c787447e9e5c009a6ab62ef4"
            ],
            "layout": "IPY_MODEL_2e686d8fa5da4b2db722dc5ef8fef604"
          }
        },
        "f63ac26289f548a88d75553b7f7257bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05a498632da64653916b8cc58d4b9c5e",
            "placeholder": "​",
            "style": "IPY_MODEL_a916d2109e30456d86f2c9f0aaa03b03",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "872b9df246954c0aa0b4bc565cdd7b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23ccddf5ab664d9bbed2da4d3961c404",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_313c5c99b6e74ddd9fb0ea1892dbd0ec",
            "value": 570
          }
        },
        "12986ff6c787447e9e5c009a6ab62ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4284f9b4fba14b359812d02008879283",
            "placeholder": "​",
            "style": "IPY_MODEL_cfb6382212774dabb5e8a9cf0d755990",
            "value": " 570/570 [00:00&lt;00:00, 56.0kB/s]"
          }
        },
        "2e686d8fa5da4b2db722dc5ef8fef604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05a498632da64653916b8cc58d4b9c5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a916d2109e30456d86f2c9f0aaa03b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23ccddf5ab664d9bbed2da4d3961c404": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "313c5c99b6e74ddd9fb0ea1892dbd0ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4284f9b4fba14b359812d02008879283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfb6382212774dabb5e8a9cf0d755990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cd5d36d9cc54a33affe374570ce9028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf200b233eab40adae12162cf0afe2b4",
              "IPY_MODEL_cfac1ce0b7cd41ea80767be798fe6efc",
              "IPY_MODEL_a9a82490592b4e7384c570b9af9e6a02"
            ],
            "layout": "IPY_MODEL_4e4b2174da104264aaaa989579f087f6"
          }
        },
        "bf200b233eab40adae12162cf0afe2b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_111dda1440224e5ca42b24acff49f6e8",
            "placeholder": "​",
            "style": "IPY_MODEL_3c20b80d41b9451482a17fc204a038bc",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "cfac1ce0b7cd41ea80767be798fe6efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf3fcce0b7ac468bbc499c5776914e22",
            "max": 1155389,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33c783c6672a4d33b677355a4a4a31cd",
            "value": 1155389
          }
        },
        "a9a82490592b4e7384c570b9af9e6a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38e952e2b1e64f0db233a72d694fcfeb",
            "placeholder": "​",
            "style": "IPY_MODEL_ed766b5738664236ac201645469834c6",
            "value": " 1.16M/1.16M [00:00&lt;00:00, 18.7MB/s]"
          }
        },
        "4e4b2174da104264aaaa989579f087f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "111dda1440224e5ca42b24acff49f6e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c20b80d41b9451482a17fc204a038bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf3fcce0b7ac468bbc499c5776914e22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33c783c6672a4d33b677355a4a4a31cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38e952e2b1e64f0db233a72d694fcfeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed766b5738664236ac201645469834c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7323f01bd1aa44f198d375912e093d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c663ed542a643c79805085daff60798",
              "IPY_MODEL_bd64ecb1c0744739861450db524e13a3",
              "IPY_MODEL_c69408c1dd0049f388062a2e404176c3"
            ],
            "layout": "IPY_MODEL_e630e8107de2466b8368b99bd9bd604f"
          }
        },
        "6c663ed542a643c79805085daff60798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d653f50726d2498088ef2a3333a29e09",
            "placeholder": "​",
            "style": "IPY_MODEL_6a7e78ab81fc4910ae0f5f26720ba82b",
            "value": "tokenizer.model: 100%"
          }
        },
        "bd64ecb1c0744739861450db524e13a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e89d8ae059cb47829507e0ffec631e6c",
            "max": 4689074,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1885902b8a0f43e88d5b0c823856dc41",
            "value": 4689074
          }
        },
        "c69408c1dd0049f388062a2e404176c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_972ed66a26854b9f967b6794f086e6bf",
            "placeholder": "​",
            "style": "IPY_MODEL_e77ce609bb9d41c8addb12263ca1ccd3",
            "value": " 4.69M/4.69M [00:00&lt;00:00, 75.9MB/s]"
          }
        },
        "e630e8107de2466b8368b99bd9bd604f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d653f50726d2498088ef2a3333a29e09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a7e78ab81fc4910ae0f5f26720ba82b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e89d8ae059cb47829507e0ffec631e6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1885902b8a0f43e88d5b0c823856dc41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "972ed66a26854b9f967b6794f086e6bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e77ce609bb9d41c8addb12263ca1ccd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74c70889921442c69b71611c30bc4645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d966e7263fb4a229970ead86e1c810c",
              "IPY_MODEL_031512552eaa4e6c841f35f7b95ef39f",
              "IPY_MODEL_ce14cecf15784d208ba841682f613710"
            ],
            "layout": "IPY_MODEL_7f1db601823047ad98cee887c2488a0e"
          }
        },
        "5d966e7263fb4a229970ead86e1c810c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b6de85e5108469d9bbd16d8547fc9ed",
            "placeholder": "​",
            "style": "IPY_MODEL_bb11f72c77f4419fa2bd041e567add04",
            "value": "tokenizer.json: 100%"
          }
        },
        "031512552eaa4e6c841f35f7b95ef39f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2061e7ea8a1045a1a8d9b89c6fdd79ee",
            "max": 33384570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15c90875cd1744c8b032657217e11fa9",
            "value": 33384570
          }
        },
        "ce14cecf15784d208ba841682f613710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f89aef5bcc074edd880dc146afb867d3",
            "placeholder": "​",
            "style": "IPY_MODEL_bf225105da4c46c3ba051260f154f282",
            "value": " 33.4M/33.4M [00:00&lt;00:00, 283MB/s]"
          }
        },
        "7f1db601823047ad98cee887c2488a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b6de85e5108469d9bbd16d8547fc9ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb11f72c77f4419fa2bd041e567add04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2061e7ea8a1045a1a8d9b89c6fdd79ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15c90875cd1744c8b032657217e11fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f89aef5bcc074edd880dc146afb867d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf225105da4c46c3ba051260f154f282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77fde17b02c94153b48c185b5845470f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5afc13739724357a155c2442111a64f",
              "IPY_MODEL_d85d7fa569244711ad0992897cdc116e",
              "IPY_MODEL_4157b2a16fd34aaa9fcea27383208317"
            ],
            "layout": "IPY_MODEL_31a74a21520e4eec8b6fb527131fdacb"
          }
        },
        "a5afc13739724357a155c2442111a64f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25fedd523df7433fa7950b2875d9fc53",
            "placeholder": "​",
            "style": "IPY_MODEL_625a1ce33acf475cb5aacd5c98975ab4",
            "value": "added_tokens.json: 100%"
          }
        },
        "d85d7fa569244711ad0992897cdc116e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dadd13ffeaa4ae49a471f499dfac517",
            "max": 35,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20bd3d5809a6413f8be768de73e0c7ba",
            "value": 35
          }
        },
        "4157b2a16fd34aaa9fcea27383208317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_711570931d574fc28ce2d134d9a3b2d9",
            "placeholder": "​",
            "style": "IPY_MODEL_496c00bb0a304dbf9d671c6fbe1395dc",
            "value": " 35.0/35.0 [00:00&lt;00:00, 3.04kB/s]"
          }
        },
        "31a74a21520e4eec8b6fb527131fdacb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25fedd523df7433fa7950b2875d9fc53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "625a1ce33acf475cb5aacd5c98975ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dadd13ffeaa4ae49a471f499dfac517": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20bd3d5809a6413f8be768de73e0c7ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "711570931d574fc28ce2d134d9a3b2d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "496c00bb0a304dbf9d671c6fbe1395dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08214b8301a54bd0a99bb50b2e7a79d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40ae943d412f48238adb4f0eed0d4567",
              "IPY_MODEL_d9345c90becd4b59ba43e2f9dbdd5b0f",
              "IPY_MODEL_abbb36cdb64248f6af72457215e98e92"
            ],
            "layout": "IPY_MODEL_982d9c663df04775a8fd9522e39273df"
          }
        },
        "40ae943d412f48238adb4f0eed0d4567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf655612963e4cedaeb12cc9d73ca36e",
            "placeholder": "​",
            "style": "IPY_MODEL_7152959ed9eb4f3ebd22d476a2d9a4b1",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "d9345c90becd4b59ba43e2f9dbdd5b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4af44c7449bb4ffdafa2d94ca63c2e53",
            "max": 662,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1732407f5a442b7832d9253b7e9784e",
            "value": 662
          }
        },
        "abbb36cdb64248f6af72457215e98e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3d08b4ecace433a96b87ee164f1a167",
            "placeholder": "​",
            "style": "IPY_MODEL_a9bdb4be6e9041e199830052b3acc203",
            "value": " 662/662 [00:00&lt;00:00, 66.3kB/s]"
          }
        },
        "982d9c663df04775a8fd9522e39273df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf655612963e4cedaeb12cc9d73ca36e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7152959ed9eb4f3ebd22d476a2d9a4b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4af44c7449bb4ffdafa2d94ca63c2e53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1732407f5a442b7832d9253b7e9784e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3d08b4ecace433a96b87ee164f1a167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9bdb4be6e9041e199830052b3acc203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9230675becd849a7a3c8a9758ccf032f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_580d6463c46d43b28bb3ddb57481560c",
              "IPY_MODEL_bf2f0fd2042047bbb43d8d71443ba1fa",
              "IPY_MODEL_abce52bb4d2f4c46b7b63885323c886b"
            ],
            "layout": "IPY_MODEL_bec639c4cad4454eb2a027c378c484c2"
          }
        },
        "580d6463c46d43b28bb3ddb57481560c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b6597bef083451dad2f954a4beed374",
            "placeholder": "​",
            "style": "IPY_MODEL_909833f1ab1c48dd8c7c7b069d4fd658",
            "value": "config.json: 100%"
          }
        },
        "bf2f0fd2042047bbb43d8d71443ba1fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbf0b595802844df8b524ad7740dc50c",
            "max": 1570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_525313f2fcb6449f86f479802e40bd14",
            "value": 1570
          }
        },
        "abce52bb4d2f4c46b7b63885323c886b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_229f9c564a024614a4bde172e8373067",
            "placeholder": "​",
            "style": "IPY_MODEL_bf38b761d93241829fe19e11e6aa551d",
            "value": " 1.57k/1.57k [00:00&lt;00:00, 98.2kB/s]"
          }
        },
        "bec639c4cad4454eb2a027c378c484c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b6597bef083451dad2f954a4beed374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "909833f1ab1c48dd8c7c7b069d4fd658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbf0b595802844df8b524ad7740dc50c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "525313f2fcb6449f86f479802e40bd14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "229f9c564a024614a4bde172e8373067": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf38b761d93241829fe19e11e6aa551d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01c127cb5d3543be9c8bdd904dcfb1d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fcb8ed40ea3a4deab12893c61d119312",
              "IPY_MODEL_24a07f5df9d24e019c991426b76be043",
              "IPY_MODEL_430bcbc07cba4a26b38785364b5108cf"
            ],
            "layout": "IPY_MODEL_e3ac7db3168c4e02a120e38545bdbe67"
          }
        },
        "fcb8ed40ea3a4deab12893c61d119312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d91db277a7a14a0fb1e2f178de38a037",
            "placeholder": "​",
            "style": "IPY_MODEL_a992fda352a247af9d7409b93cd48604",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "24a07f5df9d24e019c991426b76be043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f6464ff66614f1abb97767855c42549",
            "max": 90558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_192e97777bdb471e85049402f31086a6",
            "value": 90558
          }
        },
        "430bcbc07cba4a26b38785364b5108cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bcf8cb86a9b4f26aaa9818d1c80eb63",
            "placeholder": "​",
            "style": "IPY_MODEL_b39daede10fc496ba1e9109fd5ed2c45",
            "value": " 90.6k/90.6k [00:00&lt;00:00, 7.05MB/s]"
          }
        },
        "e3ac7db3168c4e02a120e38545bdbe67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d91db277a7a14a0fb1e2f178de38a037": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a992fda352a247af9d7409b93cd48604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f6464ff66614f1abb97767855c42549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "192e97777bdb471e85049402f31086a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2bcf8cb86a9b4f26aaa9818d1c80eb63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b39daede10fc496ba1e9109fd5ed2c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bffddc07cf6c4dd8aeda0ff1c1ec0de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_739fdf2b8899413cb151c69d4801bf26",
              "IPY_MODEL_b517fa09542c49c1b439b42489ef3a10",
              "IPY_MODEL_b15a7de0b94e43daa640a998d52ecccf"
            ],
            "layout": "IPY_MODEL_8e04553311aa480bad044dac09132ff7"
          }
        },
        "739fdf2b8899413cb151c69d4801bf26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faa8bd8c245246f6a20b00cfc329cb18",
            "placeholder": "​",
            "style": "IPY_MODEL_67f3d6ebde9d4a94ad0557a8d74d8317",
            "value": "Fetching 2 files: 100%"
          }
        },
        "b517fa09542c49c1b439b42489ef3a10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b442dac410a447339422d30ab75b7f70",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_474cee0f30a045ecae8afae87f4a6537",
            "value": 2
          }
        },
        "b15a7de0b94e43daa640a998d52ecccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d2ea870326d4204ac4468b19345a72a",
            "placeholder": "​",
            "style": "IPY_MODEL_2eee7282d43f40ce9ffa50f3e895c7d7",
            "value": " 2/2 [00:57&lt;00:00, 57.25s/it]"
          }
        },
        "8e04553311aa480bad044dac09132ff7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faa8bd8c245246f6a20b00cfc329cb18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67f3d6ebde9d4a94ad0557a8d74d8317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b442dac410a447339422d30ab75b7f70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "474cee0f30a045ecae8afae87f4a6537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d2ea870326d4204ac4468b19345a72a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eee7282d43f40ce9ffa50f3e895c7d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfdac6bf5c914f6aa59e597af877c766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42243a1e717d474085b7b087bd2d5b19",
              "IPY_MODEL_79802bf064224fcf998e6c4c99d8d508",
              "IPY_MODEL_1bece0e4021e48b7b58bb06c3a3384a6"
            ],
            "layout": "IPY_MODEL_d7a963a1f3834a16bdafe4c3f755c79f"
          }
        },
        "42243a1e717d474085b7b087bd2d5b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4577572db2d243d495c490475d45a7ea",
            "placeholder": "​",
            "style": "IPY_MODEL_f746a6fcd8024bc4bea2e6537daf1033",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "79802bf064224fcf998e6c4c99d8d508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7f45040acbb4b37a2b6746cea26fab2",
            "max": 4961251752,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71fd71ea294c4cd2937a149199a6a0f5",
            "value": 4961251752
          }
        },
        "1bece0e4021e48b7b58bb06c3a3384a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d35a93974c2449e2bed6216f2243dca1",
            "placeholder": "​",
            "style": "IPY_MODEL_d4c3b51cc30442449d11277e7275dcc4",
            "value": " 4.96G/4.96G [00:56&lt;00:00, 82.4MB/s]"
          }
        },
        "d7a963a1f3834a16bdafe4c3f755c79f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4577572db2d243d495c490475d45a7ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f746a6fcd8024bc4bea2e6537daf1033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7f45040acbb4b37a2b6746cea26fab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71fd71ea294c4cd2937a149199a6a0f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d35a93974c2449e2bed6216f2243dca1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4c3b51cc30442449d11277e7275dcc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01e979a43d064c739df7437e1f9631cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3d5df125c9b479cb27f40a4a7300cab",
              "IPY_MODEL_ad7d079a0a814bdbb90c05a21fa71f07",
              "IPY_MODEL_1082eb1ae7014a4db44a6ea8c62f9e55"
            ],
            "layout": "IPY_MODEL_d85a346872d04d0e8c00c4fd5146cfcf"
          }
        },
        "a3d5df125c9b479cb27f40a4a7300cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88bde2460bdb4e029b021b428ff3c622",
            "placeholder": "​",
            "style": "IPY_MODEL_8f6b68b32ef042c1b65b52a7091a29be",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "ad7d079a0a814bdbb90c05a21fa71f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79ca206b7c0e409e8263052fa2f9b562",
            "max": 3639026128,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec800003203b46fea9e3d5554d612852",
            "value": 3639026128
          }
        },
        "1082eb1ae7014a4db44a6ea8c62f9e55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9109025efaae4f67928817709090b468",
            "placeholder": "​",
            "style": "IPY_MODEL_53fb12150c924daa844f0428a19c5d6c",
            "value": " 3.64G/3.64G [00:48&lt;00:00, 45.4MB/s]"
          }
        },
        "d85a346872d04d0e8c00c4fd5146cfcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88bde2460bdb4e029b021b428ff3c622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f6b68b32ef042c1b65b52a7091a29be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79ca206b7c0e409e8263052fa2f9b562": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec800003203b46fea9e3d5554d612852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9109025efaae4f67928817709090b468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53fb12150c924daa844f0428a19c5d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c545e6ddae9b4a22ae13c21183949dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a4abb04c76542b984916d011bcfab1c",
              "IPY_MODEL_090107fab9294d52bec4addc205ffec9",
              "IPY_MODEL_e3778a6158a24dc5bb356e1f190155bf"
            ],
            "layout": "IPY_MODEL_81c5f92ff085498eafdfbc2542c3c4d1"
          }
        },
        "1a4abb04c76542b984916d011bcfab1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0a23245d5214ad1bf51e839182beb78",
            "placeholder": "​",
            "style": "IPY_MODEL_a551185a81314219b6e028ed10a592eb",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "090107fab9294d52bec4addc205ffec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19012601584941fd9b2d9ce9c1d82133",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11277fc7bd8f4a91987bc3200fe9a535",
            "value": 2
          }
        },
        "e3778a6158a24dc5bb356e1f190155bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abc9c93bd8bc4af7a4e1d14887fee390",
            "placeholder": "​",
            "style": "IPY_MODEL_0d22d17f7d8c43b8b422de4fbb3185fd",
            "value": " 2/2 [00:43&lt;00:00, 21.03s/it]"
          }
        },
        "81c5f92ff085498eafdfbc2542c3c4d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0a23245d5214ad1bf51e839182beb78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a551185a81314219b6e028ed10a592eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19012601584941fd9b2d9ce9c1d82133": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11277fc7bd8f4a91987bc3200fe9a535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abc9c93bd8bc4af7a4e1d14887fee390": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d22d17f7d8c43b8b422de4fbb3185fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4df6fe7f177c4375ac65f6695661a1a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02c68d1fc2ba46849142a56840ff06bf",
              "IPY_MODEL_cfd5ef5c399a4375a349dc5f7cf2de31",
              "IPY_MODEL_b1ab5823e404491292019a862d9bb942"
            ],
            "layout": "IPY_MODEL_676bd0d04db74f558210f515aba3244b"
          }
        },
        "02c68d1fc2ba46849142a56840ff06bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fe46117c7474bcab1caee7d0996c912",
            "placeholder": "​",
            "style": "IPY_MODEL_5254a53525bf4eb8aee65949400b04fc",
            "value": "Epoch 1 [Train]:   0%"
          }
        },
        "cfd5ef5c399a4375a349dc5f7cf2de31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da2d93bd67244bbe83ad838bc79f6a73",
            "max": 170,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_600cfcd9dc3544d189da15039f9fb200",
            "value": 0
          }
        },
        "b1ab5823e404491292019a862d9bb942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28d3067ebcc54b6f893f9d63eb3f6011",
            "placeholder": "​",
            "style": "IPY_MODEL_6247d8faae7743bea8fac00425835f4c",
            "value": " 0/170 [00:08&lt;?, ?batch/s]"
          }
        },
        "676bd0d04db74f558210f515aba3244b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fe46117c7474bcab1caee7d0996c912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5254a53525bf4eb8aee65949400b04fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da2d93bd67244bbe83ad838bc79f6a73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "600cfcd9dc3544d189da15039f9fb200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28d3067ebcc54b6f893f9d63eb3f6011": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6247d8faae7743bea8fac00425835f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ravikrishnan05/PrediscanMedtech_project/blob/main/Megamma_from_scrach_with_google.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9CpRKEOrTPS",
        "outputId": "51e161a5-69ff-45fa-d88f-245289222729"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 1 (REVISED): Installs and PyTorch/HuggingFace Imports\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"Installing/Updating PyTorch, Hugging Face, and related libraries for MedGemma...\")\n",
        "# Install PyTorch first (cu118 is common for Colab T4/V100 GPUs)\n",
        "!pip install -q -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Install Hugging Face and other necessary libraries\n",
        "# Let pip resolve numpy and scikit-learn based on these packages' needs\n",
        "!pip install -q -U transformers accelerate bitsandbytes peft pydicom pandas opencv-python Pillow scikit-learn\n",
        "\n",
        "# No explicit numpy install/uninstall here; let other packages specify their needs.\n",
        "# pydicom, pandas, opencv-python, Pillow are generally fine with default versions.\n",
        "\n",
        "print(\"\\nImporting libraries...\")\n",
        "# Python Standard Libraries\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "# Third-party Libraries\n",
        "import pandas as pd\n",
        "import numpy as np # Should be a compatible version now\n",
        "import pydicom\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Scikit-learn (should import fine after pip installs a compatible version)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Hugging Face Transformers\n",
        "from transformers import AutoProcessor\n",
        "\n",
        "# TensorFlow (still imported from your original code, we'll manage its numpy needs)\n",
        "# If you are ONLY using PyTorch for MedGemma, you can comment out TF imports later.\n",
        "# For now, keeping them to see if the environment stabilizes.\n",
        "import tensorflow as tf\n",
        "# from tensorflow.keras.applications import ResNet50V2 # Not needed for MedGemma\n",
        "# from tensorflow.keras.applications.resnet_v2 import preprocess_input as resnet_preprocess_input # Not needed\n",
        "# from tensorflow.keras.utils import Sequence # Not needed for PyTorch Dataset\n",
        "# from tensorflow.keras import layers, models # Not needed\n",
        "\n",
        "# Plotting (optional, but often useful)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Colab specific (if needed)\n",
        "from google.colab import drive # Moved drive mount to Cell 2\n",
        "\n",
        "print(\"--- Library Version Checks ---\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Scikit-learn version: {pd.__version__}\") # Oops, should be sklearn.__version__\n",
        "import sklearn\n",
        "print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    print(f\"PyTorch CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU available for PyTorch: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"GPU not available for PyTorch, using CPU.\")\n",
        "print(f\"GPU Available for TensorFlow: {tf.config.list_physical_devices('GPU')}\")\n",
        "\n",
        "\n",
        "# For reproducibility\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "if 'torch' in globals(): # Check if torch was successfully imported\n",
        "    torch.manual_seed(RANDOM_SEED)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(RANDOM_SEED)\n",
        "\n",
        "print(\"\\nCell 1: Installs and Imports complete.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wX_Gvd72gl0",
        "outputId": "a132af41-2d0a-4ed5-8156-caea6522ecbe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing/Updating PyTorch, Hugging Face, and related libraries for MedGemma...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m955.6/955.6 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m123.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m124.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m188.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m126.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m119.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "Importing libraries...\n",
            "--- Library Version Checks ---\n",
            "Pandas version: 2.2.3\n",
            "NumPy version: 2.0.2\n",
            "Scikit-learn version: 2.2.3\n",
            "Scikit-learn version: 1.6.1\n",
            "TensorFlow Version: 2.18.0\n",
            "PyTorch version: 2.7.0+cu118\n",
            "PyTorch CUDA version: 11.8\n",
            "GPU available for PyTorch: Tesla T4\n",
            "GPU Available for TensorFlow: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "\n",
            "Cell 1: Installs and Imports complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N0ZV9gGb4CL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------\n",
        "# Cell 2: Configuration and Unzip Data\n",
        "# (Your existing Cell 2 - ensure drive is mounted first if not done in Cell 1)\n",
        "# --------------------------------------------------\n",
        "if 'drive' not in globals(): # If drive wasn't imported/mounted in Cell 1\n",
        "    from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True) # force_remount if running again\n",
        "\n",
        "# --- Configuration ---\n",
        "DRIVE_CSV_PATH = \"/content/drive/MyDrive/cp.csv\"\n",
        "DRIVE_ZIP_PATH = \"/content/drive/MyDrive/1000-20250517T062750Z-1-001.zip\" # Your image ZIP on Drive\n",
        "\n",
        "LOCAL_EXTRACT_PATH = \"/content/medgemma_extracted_images\" # Using the MedGemma specific path\n",
        "LOCAL_IMAGES_ROOT = os.path.join(LOCAL_EXTRACT_PATH, \"1000\")\n",
        "LOCAL_CSV_PATH = \"/content/medgemma_cp.csv\" # Using the MedGemma specific path\n",
        "\n",
        "# --- Unzip Data (if not already done or if re-running) ---\n",
        "if os.path.exists(DRIVE_CSV_PATH):\n",
        "    shutil.copy(DRIVE_CSV_PATH, LOCAL_CSV_PATH)\n",
        "    print(f\"CSV copied to {LOCAL_CSV_PATH}\")\n",
        "else:\n",
        "    print(f\"ERROR: CSV file not found at {DRIVE_CSV_PATH}\")\n",
        "\n",
        "if os.path.exists(LOCAL_EXTRACT_PATH):\n",
        "    print(f\"Removing existing extraction directory: {LOCAL_EXTRACT_PATH}\")\n",
        "    shutil.rmtree(LOCAL_EXTRACT_PATH)\n",
        "os.makedirs(LOCAL_EXTRACT_PATH, exist_ok=True)\n",
        "print(f\"Created local extraction directory: {LOCAL_EXTRACT_PATH}\")\n",
        "\n",
        "if os.path.exists(DRIVE_ZIP_PATH):\n",
        "    print(f\"Unzipping {DRIVE_ZIP_PATH} to {LOCAL_EXTRACT_PATH}...\")\n",
        "    with zipfile.ZipFile(DRIVE_ZIP_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall(LOCAL_EXTRACT_PATH)\n",
        "    print(\"Unzipping complete.\")\n",
        "    if os.path.exists(LOCAL_IMAGES_ROOT):\n",
        "        print(f\"Image root folder found at: {LOCAL_IMAGES_ROOT}\")\n",
        "    else:\n",
        "        print(f\"ERROR: Expected image root folder '{LOCAL_IMAGES_ROOT}' not found after unzipping.\")\n",
        "else:\n",
        "    print(f\"ERROR: ZIP file not found at {DRIVE_ZIP_PATH}\")\n",
        "\n",
        "print(\"\\nCell 2: Data unzipping complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gx5YCYkyr7_i",
        "outputId": "bebbdeb3-d2c4-45d9-dd6e-ee51eb47a13f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "CSV copied to /content/medgemma_cp.csv\n",
            "Created local extraction directory: /content/medgemma_extracted_images\n",
            "Unzipping /content/drive/MyDrive/1000-20250517T062750Z-1-001.zip to /content/medgemma_extracted_images...\n",
            "Unzipping complete.\n",
            "Image root folder found at: /content/medgemma_extracted_images/1000\n",
            "\n",
            "Cell 2: Data unzipping complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------\n",
        "# Cell 3: Load and Filter Clinical Data to create image_df\n",
        "# (Your existing Cell 3 - adapted for clarity and robustness)\n",
        "# --------------------------------------------------\n",
        "image_df = pd.DataFrame() # Initialize to ensure it exists\n",
        "\n",
        "if not os.path.exists(LOCAL_CSV_PATH):\n",
        "    print(f\"FATAL ERROR: Clinical CSV file not found at the expected local path: {LOCAL_CSV_PATH}\")\n",
        "else:\n",
        "    df_raw_from_cell3 = pd.read_csv(LOCAL_CSV_PATH) # Use a distinct name to avoid confusion\n",
        "    print(f\"Initial number of rows in clinical data (Cell 3): {len(df_raw_from_cell3)}\")\n",
        "\n",
        "    # IMPORTANT: Verify these column names EXACTLY match your CSV file\n",
        "    person_id_col_name_c3 = 'person_id'\n",
        "    ldl_col_name_c3 = \"LDL Cholesterol Calculation (mg/dL)\"\n",
        "\n",
        "    if not (person_id_col_name_c3 in df_raw_from_cell3.columns and ldl_col_name_c3 in df_raw_from_cell3.columns):\n",
        "        print(f\"ERROR: Required columns ('{person_id_col_name_c3}' or '{ldl_col_name_c3}') not found in CSV.\")\n",
        "        print(f\"Available columns: {df_raw_from_cell3.columns.tolist()}\")\n",
        "    else:\n",
        "        # Select and clean\n",
        "        df_selected_c3 = df_raw_from_cell3[[person_id_col_name_c3, ldl_col_name_c3]].copy()\n",
        "        df_selected_c3.rename(columns={ldl_col_name_c3: 'LDL_temp'}, inplace=True) # Use temp name\n",
        "        df_selected_c3['LDL_temp'] = pd.to_numeric(df_selected_c3['LDL_temp'], errors='coerce')\n",
        "        df_selected_c3.dropna(subset=['LDL_temp'], inplace=True)\n",
        "        df_selected_c3 = df_selected_c3[df_selected_c3['LDL_temp'] > 0].copy()\n",
        "        df_selected_c3[person_id_col_name_c3] = df_selected_c3[person_id_col_name_c3].astype(str)\n",
        "        print(f\"Cleaned clinical data (positive LDLs only): {len(df_selected_c3)} records.\")\n",
        "\n",
        "        ldl_lookup_c3 = df_selected_c3.set_index(person_id_col_name_c3)['LDL_temp'].to_dict()\n",
        "\n",
        "        # Map to images\n",
        "        if not (os.path.exists(LOCAL_IMAGES_ROOT) and os.path.isdir(LOCAL_IMAGES_ROOT)):\n",
        "            print(f\"FATAL ERROR: Images root path '{LOCAL_IMAGES_ROOT}' does not exist or is not a directory.\")\n",
        "        else:\n",
        "            available_folders_c3 = set(os.listdir(LOCAL_IMAGES_ROOT))\n",
        "            valid_ids_clinical_c3 = set(ldl_lookup_c3.keys())\n",
        "            common_person_ids_c3 = sorted(list(valid_ids_clinical_c3 & available_folders_c3))\n",
        "            print(f\"Found {len(common_person_ids_c3)} common person_ids for mapping.\")\n",
        "\n",
        "            image_records_list = []\n",
        "            for pid_c3 in common_person_ids_c3:\n",
        "                folder_path_c3 = os.path.join(LOCAL_IMAGES_ROOT, pid_c3)\n",
        "                ldl_val_c3 = ldl_lookup_c3[pid_c3]\n",
        "                if os.path.isdir(folder_path_c3):\n",
        "                    for filename_c3 in os.listdir(folder_path_c3):\n",
        "                        if filename_c3.lower().endswith(\".dcm\"):\n",
        "                            image_path_c3 = os.path.join(folder_path_c3, filename_c3)\n",
        "                            image_records_list.append({\n",
        "                                \"person_id\": pid_c3, # Final column name\n",
        "                                \"image_path\": image_path_c3, # Final column name\n",
        "                                \"LDL\": ldl_val_c3 # Final column name\n",
        "                            })\n",
        "            image_df = pd.DataFrame(image_records_list) # Assign to the main image_df\n",
        "            if not image_df.empty:\n",
        "                print(f\"Final image_df created with {len(image_df)} image-LDL pairs.\")\n",
        "                print(image_df.head())\n",
        "                print(f\"LDL stats in final image_df: min={image_df['LDL'].min()}, max={image_df['LDL'].max()}, mean={image_df['LDL'].mean()}\")\n",
        "            else:\n",
        "                print(\"WARNING: image_df is empty after mapping. Check paths and IDs.\")\n",
        "print(\"\\nCell 3: image_df preparation complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp-fwDy-4qup",
        "outputId": "dd5d6f5a-54f6-41ab-d4dd-44cedec25835"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial number of rows in clinical data (Cell 3): 1067\n",
            "Cleaned clinical data (positive LDLs only): 1025 records.\n",
            "Found 527 common person_ids for mapping.\n",
            "Final image_df created with 973 image-LDL pairs.\n",
            "  person_id                                         image_path         LDL\n",
            "0      1002  /content/medgemma_extracted_images/1000/1002/1...  133.485054\n",
            "1      1004  /content/medgemma_extracted_images/1000/1004/1...   59.674544\n",
            "2      1004  /content/medgemma_extracted_images/1000/1004/1...   59.674544\n",
            "3      1005  /content/medgemma_extracted_images/1000/1005/1...   74.956702\n",
            "4      1007  /content/medgemma_extracted_images/1000/1007/1...   92.278412\n",
            "LDL stats in final image_df: min=10.77327021, max=278.5634775, mean=92.26371915419321\n",
            "\n",
            "Cell 3: image_df preparation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 4: Verify image_df and Set MedGemma Model ID\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# VERIFY `image_df` IS READY FROM YOUR PREVIOUS CELLS\n",
        "if 'image_df' in locals() and isinstance(image_df, pd.DataFrame) and not image_df.empty:\n",
        "    print(f\"Continuing with 'image_df' which has {len(image_df)} records.\")\n",
        "    print(\"Columns in image_df:\", image_df.columns.tolist())\n",
        "    print(\"Sample of image_df:\")\n",
        "    display(image_df.head()) # Use display for better DataFrame formatting in Colab\n",
        "\n",
        "    required_cols = ['person_id', 'image_path', 'LDL']\n",
        "    if not all(col in image_df.columns for col in required_cols):\n",
        "        print(f\"ERROR: 'image_df' is missing one or more required columns: {required_cols}. Please re-run previous data preparation cells.\")\n",
        "    elif image_df['LDL'].min() <= 0:\n",
        "        print(f\"ERROR: 'image_df' still contains non-positive LDL values. LDL min: {image_df['LDL'].min()}. Please re-run filtering.\")\n",
        "    else:\n",
        "        print(\"'image_df' seems okay to proceed.\")\n",
        "else:\n",
        "    print(\"ERROR: 'image_df' not found or is empty. Please ensure your data preparation cells (your original Cells 1-3, now adapted) have been run successfully.\")\n",
        "    # In a real run, you'd stop and fix. For script flow, create empty to avoid NameError.\n",
        "    image_df = pd.DataFrame(columns=['person_id', 'image_path', 'LDL'])\n",
        "\n",
        "\n",
        "# --- MedGemma Model ID Configuration ---\n",
        "# ACTION: YOU MUST VERIFY THIS MODEL ID FROM HUGGING FACE HUB\n",
        "# Search on Hugging Face Hub: https://huggingface.co/models?search=google/medgemma\n",
        "# Look for the 4B \"pt\" (pre-trained) variant.\n",
        "# Common candidates: \"google/medgemma-4b-pt\" or \"google/medgem_vision_text_4b_pt\"\n",
        "MEDGEMMA_PT_MODEL_ID = \"google/medgemma-4b-pt\"  # <<<--- REPLACE WITH VERIFIED ID\n",
        "# Example: MEDGEMMA_PT_MODEL_ID = \"google/medgem_vision_text_4b_pt\" # If this is the correct one\n",
        "\n",
        "print(f\"\\nConfigured MEDGEMMA_PT_MODEL_ID: {MEDGEMMA_PT_MODEL_ID}\")\n",
        "if MEDGEMMA_PT_MODEL_ID == \"google/medgemma-4b-pt\": # Check if it's still the placeholder\n",
        "    print(\"WARNING: MEDGEMMA_PT_MODEL_ID might still be the placeholder. Please verify this ID on Hugging Face Hub.\")\n",
        "\n",
        "print(\"\\nCell 4: image_df verification and MedGemma Model ID configuration complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "eu0FWJLm5TK-",
        "outputId": "ddf6f035-58ca-4648-c539-27de2b53ff88"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Continuing with 'image_df' which has 973 records.\n",
            "Columns in image_df: ['person_id', 'image_path', 'LDL']\n",
            "Sample of image_df:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  person_id                                         image_path         LDL\n",
              "0      1002  /content/medgemma_extracted_images/1000/1002/1...  133.485054\n",
              "1      1004  /content/medgemma_extracted_images/1000/1004/1...   59.674544\n",
              "2      1004  /content/medgemma_extracted_images/1000/1004/1...   59.674544\n",
              "3      1005  /content/medgemma_extracted_images/1000/1005/1...   74.956702\n",
              "4      1007  /content/medgemma_extracted_images/1000/1007/1...   92.278412"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc9c1671-0209-4343-9717-24c0111b73e2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>person_id</th>\n",
              "      <th>image_path</th>\n",
              "      <th>LDL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1002</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1002/1...</td>\n",
              "      <td>133.485054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1004</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1004/1...</td>\n",
              "      <td>59.674544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1004</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1004/1...</td>\n",
              "      <td>59.674544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1005</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1005/1...</td>\n",
              "      <td>74.956702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1007</td>\n",
              "      <td>/content/medgemma_extracted_images/1000/1007/1...</td>\n",
              "      <td>92.278412</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc9c1671-0209-4343-9717-24c0111b73e2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fc9c1671-0209-4343-9717-24c0111b73e2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fc9c1671-0209-4343-9717-24c0111b73e2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-547aa895-bf78-4ca3-9a78-6e1087da076f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-547aa895-bf78-4ca3-9a78-6e1087da076f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-547aa895-bf78-4ca3-9a78-6e1087da076f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\nCell 4: image_df verification and MedGemma Model ID configuration complete\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"person_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"1004\",\n          \"1007\",\n          \"1002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"/content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230809.2448.36605.dcm\",\n          \"/content/medgemma_extracted_images/1000/1007/1007_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230824.20355.67485.dcm\",\n          \"/content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_l_1.2.826.0.1.3680043.8.641.1.20230809.2436.96446.dcm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LDL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.751173059264335,\n        \"min\": 59.67454369,\n        \"max\": 133.4850537,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          59.67454369,\n          92.27841214,\n          133.4850537\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'image_df' seems okay to proceed.\n",
            "\n",
            "Configured MEDGEMMA_PT_MODEL_ID: google/medgemma-4b-pt\n",
            "WARNING: MEDGEMMA_PT_MODEL_ID might still be the placeholder. Please verify this ID on Hugging Face Hub.\n",
            "\n",
            "Cell 4: image_df verification and MedGemma Model ID configuration complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")"
      ],
      "metadata": {
        "id": "50QUF_ll8cOn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 5: Load MedGemma Processor\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "medgemma_processor = None\n",
        "# Default target size from model card, will try to confirm/override from processor\n",
        "TARGET_SIZE_MEDGEMMA = (896, 896) # MedGemma model card specifies 896x896\n",
        "\n",
        "# Check if the model ID is still the placeholder\n",
        "if MEDGEMMA_PT_MODEL_ID == \"google/medgemma-4b-pt\" or \"YOUR_VERIFIED_MODEL_ID_HERE\" in MEDGEMMA_PT_MODEL_ID: # A more generic placeholder check\n",
        "    print(f\"WARNING: MEDGEMMA_PT_MODEL_ID ('{MEDGEMMA_PT_MODEL_ID}') looks like a placeholder.\")\n",
        "    print(\"Please verify and update it in Cell 4 with the correct model ID from Hugging Face Hub for the 4B pre-trained variant before proceeding.\")\n",
        "\n",
        "try:\n",
        "    print(f\"\\nAttempting to load MedGemma processor for: {MEDGEMMA_PT_MODEL_ID}...\")\n",
        "    # trust_remote_code=True is often needed for newer models or those with custom code (like Gemma family)\n",
        "    medgemma_processor = AutoProcessor.from_pretrained(MEDGEMMA_PT_MODEL_ID, trust_remote_code=True)\n",
        "    print(\"MedGemma Processor loaded successfully!\")\n",
        "\n",
        "    # Inspect the processor's image_processor component for expected size\n",
        "    if hasattr(medgemma_processor, 'image_processor') and hasattr(medgemma_processor.image_processor, 'size'):\n",
        "        img_proc_size_info = medgemma_processor.image_processor.size\n",
        "        print(f\"Processor's image_processor.size attribute: {img_proc_size_info}\")\n",
        "\n",
        "        parsed_h, parsed_w = None, None\n",
        "        if isinstance(img_proc_size_info, dict):\n",
        "            parsed_h = img_proc_size_info.get('height', img_proc_size_info.get('shortest_edge'))\n",
        "            if parsed_h is not None:\n",
        "                 parsed_w = img_proc_size_info.get('width', parsed_h if 'shortest_edge' in img_proc_size_info else None)\n",
        "        elif isinstance(img_proc_size_info, (list, tuple)) and len(img_proc_size_info) == 2:\n",
        "            parsed_h, parsed_w = img_proc_size_info[0], img_proc_size_info[1]\n",
        "        elif isinstance(img_proc_size_info, int):\n",
        "            parsed_h = parsed_w = img_proc_size_info\n",
        "\n",
        "        if parsed_h and parsed_w:\n",
        "            # Override TARGET_SIZE_MEDGEMMA if successfully parsed from processor\n",
        "            TARGET_SIZE_MEDGEMMA = (parsed_h, parsed_w)\n",
        "            print(f\"Target Image Size for MedGemma (from processor): {TARGET_SIZE_MEDGEMMA}\")\n",
        "            if TARGET_SIZE_MEDGEMMA != (896, 896): # Compare with model card expectation\n",
        "                print(f\"Note: Processor-derived size {TARGET_SIZE_MEDGEMMA} differs from model card's typical 896x896. Using processor's size.\")\n",
        "        else:\n",
        "            print(f\"Could not reliably parse size from processor.image_processor.size. Using default from model card: {TARGET_SIZE_MEDGEMMA}\")\n",
        "    else:\n",
        "        print(f\"Warning: MedGemma processor for {MEDGEMMA_PT_MODEL_ID} does not have 'image_processor.size'. Using default: {TARGET_SIZE_MEDGEMMA}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error loading MedGemma processor for '{MEDGEMMA_PT_MODEL_ID}': {e}\")\n",
        "    print(\"Ensure the MEDGEMMA_PT_MODEL_ID in Cell 4 is correct and you have internet access.\")\n",
        "    print(\"If the ID is correct, the model might require specific dependencies or there might be an issue with the Hugging Face Hub or the model's configuration.\")\n",
        "    # medgemma_processor will remain None\n",
        "\n",
        "print(\"\\nCell 5: MedGemma Processor loading attempt complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443,
          "referenced_widgets": [
            "bd8fd1272acc46d994cdcd4103370faa",
            "b9f986847ba641fab65a234e9d1904b0",
            "04d0e95d28514957aca9944b75ea1268",
            "af89b9528dc844778d3b5179042706fe",
            "37b9c19aa8984b69861d3fc676711ee3",
            "e1bd4e0424aa44809c733022f1ce73f8",
            "fe9a6943e8aa4c71b3f6ff6bced717fd",
            "cee17d4fe7e7474bba6b8a2978d69caa",
            "7458c0ea2bfe4fcdab64df17d752a1e1",
            "fa7547c207b54983bcc1869c57b65fba",
            "52a4f7d3dfb64386a045c0b366f3c280",
            "1c0d18fb277d4cca92bed4a4a346ffcf",
            "f63ac26289f548a88d75553b7f7257bf",
            "872b9df246954c0aa0b4bc565cdd7b9a",
            "12986ff6c787447e9e5c009a6ab62ef4",
            "2e686d8fa5da4b2db722dc5ef8fef604",
            "05a498632da64653916b8cc58d4b9c5e",
            "a916d2109e30456d86f2c9f0aaa03b03",
            "23ccddf5ab664d9bbed2da4d3961c404",
            "313c5c99b6e74ddd9fb0ea1892dbd0ec",
            "4284f9b4fba14b359812d02008879283",
            "cfb6382212774dabb5e8a9cf0d755990",
            "9cd5d36d9cc54a33affe374570ce9028",
            "bf200b233eab40adae12162cf0afe2b4",
            "cfac1ce0b7cd41ea80767be798fe6efc",
            "a9a82490592b4e7384c570b9af9e6a02",
            "4e4b2174da104264aaaa989579f087f6",
            "111dda1440224e5ca42b24acff49f6e8",
            "3c20b80d41b9451482a17fc204a038bc",
            "bf3fcce0b7ac468bbc499c5776914e22",
            "33c783c6672a4d33b677355a4a4a31cd",
            "38e952e2b1e64f0db233a72d694fcfeb",
            "ed766b5738664236ac201645469834c6",
            "7323f01bd1aa44f198d375912e093d7b",
            "6c663ed542a643c79805085daff60798",
            "bd64ecb1c0744739861450db524e13a3",
            "c69408c1dd0049f388062a2e404176c3",
            "e630e8107de2466b8368b99bd9bd604f",
            "d653f50726d2498088ef2a3333a29e09",
            "6a7e78ab81fc4910ae0f5f26720ba82b",
            "e89d8ae059cb47829507e0ffec631e6c",
            "1885902b8a0f43e88d5b0c823856dc41",
            "972ed66a26854b9f967b6794f086e6bf",
            "e77ce609bb9d41c8addb12263ca1ccd3",
            "74c70889921442c69b71611c30bc4645",
            "5d966e7263fb4a229970ead86e1c810c",
            "031512552eaa4e6c841f35f7b95ef39f",
            "ce14cecf15784d208ba841682f613710",
            "7f1db601823047ad98cee887c2488a0e",
            "1b6de85e5108469d9bbd16d8547fc9ed",
            "bb11f72c77f4419fa2bd041e567add04",
            "2061e7ea8a1045a1a8d9b89c6fdd79ee",
            "15c90875cd1744c8b032657217e11fa9",
            "f89aef5bcc074edd880dc146afb867d3",
            "bf225105da4c46c3ba051260f154f282",
            "77fde17b02c94153b48c185b5845470f",
            "a5afc13739724357a155c2442111a64f",
            "d85d7fa569244711ad0992897cdc116e",
            "4157b2a16fd34aaa9fcea27383208317",
            "31a74a21520e4eec8b6fb527131fdacb",
            "25fedd523df7433fa7950b2875d9fc53",
            "625a1ce33acf475cb5aacd5c98975ab4",
            "7dadd13ffeaa4ae49a471f499dfac517",
            "20bd3d5809a6413f8be768de73e0c7ba",
            "711570931d574fc28ce2d134d9a3b2d9",
            "496c00bb0a304dbf9d671c6fbe1395dc",
            "08214b8301a54bd0a99bb50b2e7a79d5",
            "40ae943d412f48238adb4f0eed0d4567",
            "d9345c90becd4b59ba43e2f9dbdd5b0f",
            "abbb36cdb64248f6af72457215e98e92",
            "982d9c663df04775a8fd9522e39273df",
            "bf655612963e4cedaeb12cc9d73ca36e",
            "7152959ed9eb4f3ebd22d476a2d9a4b1",
            "4af44c7449bb4ffdafa2d94ca63c2e53",
            "b1732407f5a442b7832d9253b7e9784e",
            "a3d08b4ecace433a96b87ee164f1a167",
            "a9bdb4be6e9041e199830052b3acc203"
          ]
        },
        "id": "7bw90k9f5nH1",
        "outputId": "a890ebad-b9de-493d-d040-fffeb9aa0f31"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: MEDGEMMA_PT_MODEL_ID ('google/medgemma-4b-pt') looks like a placeholder.\n",
            "Please verify and update it in Cell 4 with the correct model ID from Hugging Face Hub for the 4B pre-trained variant before proceeding.\n",
            "\n",
            "Attempting to load MedGemma processor for: google/medgemma-4b-pt...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "processor_config.json:   0%|          | 0.00/70.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd8fd1272acc46d994cdcd4103370faa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c0d18fb277d4cca92bed4a4a346ffcf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cd5d36d9cc54a33affe374570ce9028"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7323f01bd1aa44f198d375912e093d7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74c70889921442c69b71611c30bc4645"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77fde17b02c94153b48c185b5845470f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08214b8301a54bd0a99bb50b2e7a79d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MedGemma Processor loaded successfully!\n",
            "Processor's image_processor.size attribute: {'height': 896, 'width': 896}\n",
            "Target Image Size for MedGemma (from processor): (896, 896)\n",
            "\n",
            "Cell 5: MedGemma Processor loading attempt complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(medgemma_processor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni0PNOiWoosg",
        "outputId": "1a7ecafc-4dfb-4dae-f65e-a375ca37537c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.models.gemma3.processing_gemma3.Gemma3Processor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 6: Data Splitting (Patient-Level) and LDL Normalization\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "train_df, val_df, test_df = pd.DataFrame(), pd.DataFrame(), pd.DataFrame() # Initialize\n",
        "ldl_scaler = None # Will store the fitted StandardScaler\n",
        "\n",
        "if 'image_df' in locals() and not image_df.empty:\n",
        "    print(f\"\\nStarting data splitting for {len(image_df)} image-LDL pairs...\")\n",
        "    if 'person_id' not in image_df.columns:\n",
        "        print(\"ERROR: 'person_id' column missing in image_df. Cannot perform patient-level split. Please check image_df preparation.\")\n",
        "    else:\n",
        "        unique_person_ids = image_df['person_id'].unique()\n",
        "        print(f\"Total unique patients for splitting: {len(unique_person_ids)}\")\n",
        "\n",
        "        if len(unique_person_ids) < 3:\n",
        "            print(\"Warning: Not enough unique patients for a robust 3-way (train/validation/test) split.\")\n",
        "            # Simplified split logic for few patients (adjust as needed for your minimum requirements)\n",
        "            if len(unique_person_ids) == 2:\n",
        "                train_pids, val_pids = train_test_split(unique_person_ids, test_size=0.5, random_state=RANDOM_SEED)\n",
        "                test_pids = np.array([]) # Empty array for consistency\n",
        "            elif len(unique_person_ids) == 1:\n",
        "                train_pids = unique_person_ids\n",
        "                val_pids, test_pids = np.array([]), np.array([])\n",
        "            else: # 0 patients\n",
        "                train_pids, val_pids, test_pids = np.array([]), np.array([]), np.array([])\n",
        "        else:\n",
        "            # Standard 70% train, 15% validation, 15% test split of person_ids\n",
        "            train_pids, temp_pids = train_test_split(\n",
        "                unique_person_ids, test_size=0.30, random_state=RANDOM_SEED\n",
        "            )\n",
        "            if len(temp_pids) > 1 : # Ensure there's at least 2 for val/test split\n",
        "                 val_pids, test_pids = train_test_split(\n",
        "                    temp_pids, test_size=0.50, random_state=RANDOM_SEED\n",
        "                )\n",
        "            elif len(temp_pids) == 1: # Only one patient left\n",
        "                val_pids = temp_pids\n",
        "                test_pids = np.array([])\n",
        "            else:\n",
        "                val_pids, test_pids = np.array([]), np.array([])\n",
        "\n",
        "\n",
        "        train_df = image_df[image_df['person_id'].isin(train_pids)].copy()\n",
        "        val_df = image_df[image_df['person_id'].isin(val_pids)].copy()\n",
        "        test_df = image_df[image_df['person_id'].isin(test_pids)].copy()\n",
        "\n",
        "        print(f\"Train set: {len(train_df)} samples from {len(train_pids)} patients.\")\n",
        "        print(f\"Validation set: {len(val_df)} samples from {len(val_pids)} patients.\")\n",
        "        print(f\"Test set: {len(test_df)} samples from {len(test_pids)} patients.\")\n",
        "\n",
        "        # Sanity check for patient overlap - important!\n",
        "        if len(train_pids)>0 and len(val_pids)>0: assert len(set(train_pids) & set(val_pids)) == 0, \"Patient overlap train/val!\"\n",
        "        if len(train_pids)>0 and len(test_pids)>0: assert len(set(train_pids) & set(test_pids)) == 0, \"Patient overlap train/test!\"\n",
        "        if len(val_pids)>0 and len(test_pids)>0: assert len(set(val_pids) & set(test_pids)) == 0, \"Patient overlap val/test!\"\n",
        "        print(\"Patient-level splits verified (no overlap if sets are non-empty).\")\n",
        "\n",
        "        # --- LDL Value Normalization ---\n",
        "        if not train_df.empty and 'LDL' in train_df.columns:\n",
        "            print(\"\\nNormalizing LDL values using StandardScaler...\")\n",
        "            ldl_scaler = StandardScaler()\n",
        "            # Fit the scaler ONLY on the training data's LDL values\n",
        "            train_df['LDL_scaled'] = ldl_scaler.fit_transform(train_df[['LDL']])\n",
        "\n",
        "            # Transform validation and test data using the FITTED scaler\n",
        "            if not val_df.empty:\n",
        "                val_df['LDL_scaled'] = ldl_scaler.transform(val_df[['LDL']])\n",
        "            else:\n",
        "                # Add LDL_scaled column even if empty, for consistency\n",
        "                val_df['LDL_scaled'] = pd.Series(dtype='float64')\n",
        "\n",
        "            if not test_df.empty:\n",
        "                test_df['LDL_scaled'] = ldl_scaler.transform(test_df[['LDL']])\n",
        "            else:\n",
        "                test_df['LDL_scaled'] = pd.Series(dtype='float64')\n",
        "\n",
        "\n",
        "            print(\"LDL normalization complete.\")\n",
        "            print(\"Scaled LDL stats in train_df (should be mean~0, std~1):\")\n",
        "            display(train_df['LDL_scaled'].describe())\n",
        "\n",
        "            # Save the scaler for later use during inference/evaluation\n",
        "            # import joblib\n",
        "            # scaler_filename = 'ldl_scaler_medgemma.joblib'\n",
        "            # joblib.dump(ldl_scaler, scaler_filename)\n",
        "            # print(f\"LDL scaler saved to {scaler_filename}\")\n",
        "        else:\n",
        "            print(\"Train DataFrame is empty or 'LDL' column missing. Skipping LDL normalization.\")\n",
        "else:\n",
        "    print(\"image_df is empty (from Cell 3). Skipping data splitting and LDL normalization.\")\n",
        "\n",
        "print(\"\\nCell 6: Data splitting and LDL normalization attempt complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "7If-OZBu8uzx",
        "outputId": "de251e6f-03ee-4756-cba3-83cfb28b7e49"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting data splitting for 973 image-LDL pairs...\n",
            "Total unique patients for splitting: 527\n",
            "Train set: 681 samples from 368 patients.\n",
            "Validation set: 145 samples from 79 patients.\n",
            "Test set: 147 samples from 80 patients.\n",
            "Patient-level splits verified (no overlap if sets are non-empty).\n",
            "\n",
            "Normalizing LDL values using StandardScaler...\n",
            "LDL normalization complete.\n",
            "Scaled LDL stats in train_df (should be mean~0, std~1):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "count    6.810000e+02\n",
              "mean     2.086763e-16\n",
              "std      1.000735e+00\n",
              "min     -2.303724e+00\n",
              "25%     -7.148712e-01\n",
              "50%     -4.975462e-02\n",
              "75%      6.670533e-01\n",
              "max      2.756859e+00\n",
              "Name: LDL_scaled, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LDL_scaled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>6.810000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.086763e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000735e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-2.303724e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-7.148712e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-4.975462e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.670533e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.756859e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cell 6: Data splitting and LDL normalization attempt complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5.1: Check medgemma_processor\n",
        "if 'medgemma_processor' in locals() and medgemma_processor is not None:\n",
        "    print(f\"Cell 5.1 Check: medgemma_processor IS LOADED. Type: {type(medgemma_processor)}\")\n",
        "    if hasattr(medgemma_processor, 'image_processor'):\n",
        "        print(f\"  It has an image_processor of type: {type(medgemma_processor.image_processor)}\")\n",
        "    else:\n",
        "        print(\"  WARNING: It does NOT have an image_processor attribute.\")\n",
        "else:\n",
        "    print(\"Cell 5.1 Check: medgemma_processor IS NOT LOADED or is None.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCu040Kbs1n5",
        "outputId": "9e61ef9f-d55b-479e-c1f0-1f3d3d597a6e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cell 5.1 Check: medgemma_processor IS LOADED. Type: <class 'transformers.models.gemma3.processing_gemma3.Gemma3Processor'>\n",
            "  It has an image_processor of type: <class 'transformers.models.gemma3.image_processing_gemma3.Gemma3ImageProcessor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def load_dicom_image_medgemma_DEBUG(path, processor_obj): # processor_obj is the main Gemma3Processor\n",
        "    print(f\"\\n--- Debugging load_dicom_image_medgemma_DEBUG for: {path} ---\")\n",
        "    if processor_obj is None:\n",
        "        print(f\"DEBUG: Main processor object (processor_obj) is None. Cannot proceed.\")\n",
        "        return None\n",
        "\n",
        "    # Check if the main processor has the image_processor component\n",
        "    if not hasattr(processor_obj, 'image_processor') or processor_obj.image_processor is None:\n",
        "        print(f\"DEBUG: processor_obj does not have a valid 'image_processor' attribute.\")\n",
        "        return None\n",
        "\n",
        "    actual_image_processor = processor_obj.image_processor # This is the specific image handler\n",
        "    print(f\"DEBUG: Using actual_image_processor: {type(actual_image_processor)}\")\n",
        "\n",
        "    pil_image_for_processor = None\n",
        "    numpy_array_for_processor = None\n",
        "\n",
        "    # 1. Pydicom Read\n",
        "    try:\n",
        "        # ... (pydicom reading and dcm.convert_pixel_data() logic remains the same as your last version) ...\n",
        "        print(\"DEBUG: Attempting pydicom.dcmread(path)...\")\n",
        "        dcm = pydicom.dcmread(path)\n",
        "        photometric_interpretation = dcm.get('PhotometricInterpretation', 'N/A')\n",
        "        print(f\"  DICOM PhotometricInterpretation: {photometric_interpretation}\")\n",
        "\n",
        "        print(\"DEBUG: Attempting to get pixel data via dcm.convert_pixel_data()...\")\n",
        "        dcm.convert_pixel_data()\n",
        "        img_array = dcm.pixel_array\n",
        "        print(f\"  DEBUG: dcm.pixel_array after convert_pixel_data(). Shape: {img_array.shape}, dtype: {img_array.dtype}\")\n",
        "        numpy_array_for_processor = img_array.astype(np.uint8).copy() # Keep as uint8 if convert_pixel_data worked well\n",
        "        img_array = img_array.astype(np.float32) # For normalization if needed\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"DEBUG: Pydicom read or convert_pixel_data error for {path}: {e}\")\n",
        "        return None\n",
        "\n",
        "    # 2. Normalization to 0-255 range (if necessary after convert_pixel_data)\n",
        "    print(\"\\nDEBUG: Normalizing to 0-255 range (if necessary)...\")\n",
        "    img_min_val = np.min(img_array)\n",
        "    img_max_val = np.max(img_array)\n",
        "\n",
        "    # If convert_pixel_data results in uint8 0-255, this normalization might be redundant but harmless\n",
        "    if not (img_array.dtype == np.uint8 and img_min_val >= 0 and img_max_val <= 255):\n",
        "        if img_max_val - img_min_val > 1e-7:\n",
        "            img_normalized_255 = 255.0 * (img_array - img_min_val) / (img_max_val - img_min_val)\n",
        "            img_to_pil = img_normalized_255.astype(np.uint8)\n",
        "        else:\n",
        "            img_to_pil = np.zeros_like(img_array, dtype=np.uint8)\n",
        "    else:\n",
        "        img_to_pil = img_array.astype(np.uint8) # Already good\n",
        "\n",
        "    print(f\"  Array for PIL - Shape: {img_to_pil.shape}, dtype: {img_to_pil.dtype}\")\n",
        "    # numpy_array_for_processor = img_to_pil.copy() # This was already set after convert_pixel_data\n",
        "\n",
        "    # 3. PIL Image Conversion\n",
        "    print(\"\\nDEBUG: Converting to PIL Image...\")\n",
        "    try:\n",
        "        if len(img_to_pil.shape) == 3 and img_to_pil.shape[-1] == 3:\n",
        "            pil_image_for_processor = Image.fromarray(img_to_pil, mode='RGB')\n",
        "            print(f\"  PIL Image created. Mode: {pil_image_for_processor.mode}, Size: {pil_image_for_processor.size}\")\n",
        "            # (Save image logic can remain)\n",
        "            save_path = f\"/content/debug_pil_image_{os.path.basename(path)}.png\"\n",
        "            pil_image_for_processor.save(save_path)\n",
        "            print(f\"  DEBUG: Saved intermediate PIL image to {save_path}\")\n",
        "        else:\n",
        "            print(f\"  Array for PIL has unexpected shape: {img_to_pil.shape}. Cannot create RGB PIL image.\")\n",
        "            return None\n",
        "    except Exception as e_pil_create:\n",
        "        print(f\"  DEBUG: Error creating PIL image: {e_pil_create}\")\n",
        "        return None\n",
        "\n",
        "    # 4. MedGemma Processor - Attempt 1: Using direct image_processor with PIL Image\n",
        "    if pil_image_for_processor:\n",
        "        print(\"\\nDEBUG: Applying actual_image_processor (Attempt 1: with PIL Image)...\")\n",
        "        try:\n",
        "            # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "            # CRITICAL CHANGE: Use actual_image_processor directly\n",
        "            # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "            inputs_pil = actual_image_processor(images=pil_image_for_processor, return_tensors=\"pt\")\n",
        "            # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "\n",
        "            if inputs_pil is None: # Some image processors might return None on failure\n",
        "                print(\"  DEBUG (PIL with actual_image_processor): actual_image_processor returned None.\")\n",
        "                # Try with NumPy array if PIL failed\n",
        "            elif 'pixel_values' not in inputs_pil or inputs_pil['pixel_values'] is None:\n",
        "                print(\"  DEBUG (PIL with actual_image_processor): 'pixel_values' not in output or is None.\")\n",
        "                # Try with NumPy array\n",
        "            else:\n",
        "                processed_tensor_pil = inputs_pil['pixel_values'].squeeze(0) # Squeeze only if batched\n",
        "                if len(processed_tensor_pil.shape) == 4 and processed_tensor_pil.shape[0] == 1: # Check if it added a batch dim\n",
        "                    processed_tensor_pil = processed_tensor_pil.squeeze(0)\n",
        "\n",
        "                print(\"  DEBUG (PIL with actual_image_processor): Processing successful.\")\n",
        "                print(f\"    Processed tensor shape: {processed_tensor_pil.shape}, dtype: {processed_tensor_pil.dtype}\")\n",
        "                print(f\"    Processed tensor min: {processed_tensor_pil.min().item()}, max: {processed_tensor_pil.max().item()}\")\n",
        "                if not torch.all(processed_tensor_pil == 0):\n",
        "                    return processed_tensor_pil # SUCCESS!\n",
        "                else:\n",
        "                    print(\"    WARNING (PIL with actual_image_processor): Processed tensor is ALL ZEROS.\")\n",
        "                    # Fall through to try NumPy array\n",
        "        except Exception as e_proc_pil_direct:\n",
        "            print(f\"  DEBUG (PIL with actual_image_processor): Error: {e_proc_pil_direct}\")\n",
        "            # Fall through to try NumPy array\n",
        "\n",
        "    # 4. MedGemma Processor - Attempt 2: Using direct image_processor with NumPy array\n",
        "    if numpy_array_for_processor is not None and \\\n",
        "       (len(numpy_array_for_processor.shape) == 3 and numpy_array_for_processor.shape[-1] == 3):\n",
        "        print(\"\\nDEBUG: Applying actual_image_processor (Attempt 2: with NumPy Array)...\")\n",
        "        print(f\"  NumPy array shape: {numpy_array_for_processor.shape}, dtype: {numpy_array_for_processor.dtype} (This is likely uint8 HWC)\")\n",
        "        try:\n",
        "            # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "            # CRITICAL CHANGE: Use actual_image_processor directly\n",
        "            # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "            inputs_np = actual_image_processor(images=numpy_array_for_processor, return_tensors=\"pt\")\n",
        "            # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "\n",
        "            if inputs_np is None:\n",
        "                print(\"  DEBUG (NumPy with actual_image_processor): actual_image_processor returned None.\")\n",
        "                return None\n",
        "            elif 'pixel_values' not in inputs_np or inputs_np['pixel_values'] is None:\n",
        "                print(\"  DEBUG (NumPy with actual_image_processor): 'pixel_values' not in output or is None.\")\n",
        "                return None\n",
        "            else:\n",
        "                processed_tensor_np = inputs_np['pixel_values'] # Don't squeeze yet\n",
        "                if len(processed_tensor_np.shape) == 4 and processed_tensor_np.shape[0] == 1: # Check if it added a batch dim\n",
        "                    processed_tensor_np = processed_tensor_np.squeeze(0)\n",
        "\n",
        "                print(\"  DEBUG (NumPy with actual_image_processor): Processing successful.\")\n",
        "                print(f\"    Processed tensor shape: {processed_tensor_np.shape}, dtype: {processed_tensor_np.dtype}\")\n",
        "                print(f\"    Processed tensor min: {processed_tensor_np.min().item()}, max: {processed_tensor_np.max().item()}\")\n",
        "                if not torch.all(processed_tensor_np == 0):\n",
        "                    return processed_tensor_np # SUCCESS!\n",
        "                else:\n",
        "                    print(\"    WARNING (NumPy with actual_image_processor): Processed tensor is ALL ZEROS.\")\n",
        "                    return None # Return None if still zeros\n",
        "        except Exception as e_proc_np_direct:\n",
        "            print(f\"  DEBUG (NumPy with actual_image_processor): Error: {e_proc_np_direct}\")\n",
        "            return None\n",
        "    else:\n",
        "        print(\"\\nDEBUG: NumPy array not suitable for processor attempt (not 3-channel RGB).\")\n",
        "        return None\n",
        "\n",
        "    print(\"DEBUG: All attempts with actual_image_processor failed or resulted in zeros.\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# --- The block to call the DEBUG function remains the same ---\n",
        "# (in Cell 7.1, after the function definition)\n",
        "if 'train_df' in locals() and not train_df.empty and medgemma_processor is not None:\n",
        "    if len(train_df) > 0:\n",
        "        path_to_debug = train_df.iloc[0]['image_path']\n",
        "        print(f\"\\n>>> Initiating DEBUG for path: {path_to_debug} <<<\")\n",
        "        debug_output_tensor = load_dicom_image_medgemma_DEBUG(path_to_debug, medgemma_processor) # Pass the main processor\n",
        "        if debug_output_tensor is not None:\n",
        "            print(f\"\\n>>> DEBUG Result for {path_to_debug}: Tensor received, shape {debug_output_tensor.shape}, min {debug_output_tensor.min().item():.2f}, max {debug_output_tensor.max().item():.2f}\")\n",
        "        else:\n",
        "            print(f\"\\n>>> DEBUG Result for {path_to_debug}: Function returned None (Error occurred)\")\n",
        "    else:\n",
        "        print(\"train_df is empty, cannot select a path for debugging.\")\n",
        "else:\n",
        "    print(\"Could not run debug: train_df or medgemma_processor (main) not available.\")\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3ihfaRw9KGq",
        "outputId": "c1d531c8-8bde-403a-ae78-e6b670795a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> Initiating DEBUG for path: /content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230809.2448.36605.dcm <<<\n",
            "\n",
            "--- Debugging load_dicom_image_medgemma_DEBUG for: /content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230809.2448.36605.dcm ---\n",
            "DEBUG: Using actual_image_processor: <class 'transformers.models.gemma3.image_processing_gemma3.Gemma3ImageProcessor'>\n",
            "DEBUG: Attempting pydicom.dcmread(path)...\n",
            "  DICOM PhotometricInterpretation: YBR_FULL_422\n",
            "DEBUG: Attempting to get pixel data via dcm.convert_pixel_data()...\n",
            "  DEBUG: dcm.pixel_array after convert_pixel_data(). Shape: (1804, 3223, 3), dtype: uint8\n",
            "\n",
            "DEBUG: Normalizing to 0-255 range (if necessary)...\n",
            "  Array for PIL - Shape: (1804, 3223, 3), dtype: uint8\n",
            "\n",
            "DEBUG: Converting to PIL Image...\n",
            "  PIL Image created. Mode: RGB, Size: (3223, 1804)\n",
            "  DEBUG: Saved intermediate PIL image to /content/debug_pil_image_1004_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230809.2448.36605.dcm.png\n",
            "\n",
            "DEBUG: Applying actual_image_processor (Attempt 1: with PIL Image)...\n",
            "  DEBUG (PIL with actual_image_processor): Processing successful.\n",
            "    Processed tensor shape: torch.Size([3, 896, 896]), dtype: torch.float32\n",
            "    Processed tensor min: -1.0, max: 1.0\n",
            "\n",
            ">>> DEBUG Result for /content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230809.2448.36605.dcm: Tensor received, shape torch.Size([3, 896, 896]), min -1.00, max 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 7: PyTorch Dataset and DataLoader Implementation\n",
        "# This cell contains the FINAL working versions of the image loading function\n",
        "# and the PyTorch Dataset class, based on our debugging.\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# --- FINAL Image Loading Function for MedGemma ---\n",
        "def load_dicom_image_medgemma(path, processor_obj): # processor_obj is the main Gemma3Processor\n",
        "    \"\"\"\n",
        "    Loads a DICOM image, handles photometric interpretation (via convert_pixel_data),\n",
        "    converts to PIL, and then preprocesses it using the MedGemma model's\n",
        "    specific image_processor component.\n",
        "    \"\"\"\n",
        "    if processor_obj is None:\n",
        "        # print(f\"Error: Main processor object is None for path {path}.\") # Optional: for verbose dataset error logging\n",
        "        return None\n",
        "\n",
        "    if not hasattr(processor_obj, 'image_processor') or processor_obj.image_processor is None:\n",
        "        # print(f\"Error: Main processor {type(processor_obj)} does not have 'image_processor' for path {path}.\") # Optional\n",
        "        return None\n",
        "\n",
        "    actual_image_processor = processor_obj.image_processor\n",
        "\n",
        "    # 1. Pydicom Read and convert_pixel_data\n",
        "    try:\n",
        "        dcm = pydicom.dcmread(path, force=True) # force=True can help with some slightly non-compliant files\n",
        "        # It's crucial to call convert_pixel_data() to apply Modality LUTs, VOI LUTs (if any),\n",
        "        # and handle Photometric Interpretation to get a displayable pixel array.\n",
        "        dcm.convert_pixel_data()\n",
        "        img_array = dcm.pixel_array # This should now be more directly usable (e.g., RGB or MONOCHROME)\n",
        "\n",
        "        # Ensure the array is uint8 for PIL conversion, common after convert_pixel_data for visual formats\n",
        "        # If it's not, there might be an issue with how convert_pixel_data handled this specific DICOM\n",
        "        if img_array.dtype != np.uint8:\n",
        "            # Attempt to scale to uint8 if it's a different type (e.g. int16, float)\n",
        "            # This is a basic scaling, more sophisticated windowing might be needed for some MONOCHROME images\n",
        "            # if dcm.PhotometricInterpretation in [\"MONOCHROME1\", \"MONOCHROME2\"]\n",
        "            if np.issubdtype(img_array.dtype, np.floating) or np.issubdtype(img_array.dtype, np.integer):\n",
        "                img_min = np.min(img_array)\n",
        "                img_max = np.max(img_array)\n",
        "                if img_max - img_min > 1e-6:\n",
        "                    img_array = 255.0 * (img_array - img_min) / (img_max - img_min)\n",
        "                else:\n",
        "                    img_array = np.zeros_like(img_array) # Flat image\n",
        "            img_array = img_array.astype(np.uint8)\n",
        "\n",
        "    except Exception: # as e_dicom:\n",
        "        # print(f\"Pydicom read or convert_pixel_data error for {path}: {e_dicom}\") # Optional\n",
        "        return None\n",
        "\n",
        "    # 2. PIL Image Conversion\n",
        "    pil_image = None\n",
        "    try:\n",
        "        if len(img_array.shape) == 3 and img_array.shape[-1] == 3: # Expecting HWC uint8 (RGB)\n",
        "            pil_image = Image.fromarray(img_array, mode='RGB')\n",
        "        elif len(img_array.shape) == 2: # Grayscale (e.g., MONOCHROME2)\n",
        "            pil_image = Image.fromarray(img_array, mode='L').convert('RGB') # Convert L to RGB for consistency\n",
        "        else:\n",
        "            # print(f\"Array for PIL has unexpected shape: {img_array.shape} for path {path}.\") # Optional\n",
        "            return None\n",
        "    except Exception: # as e_pil:\n",
        "        # print(f\"Error creating PIL image for {path}: {e_pil}\") # Optional\n",
        "        return None\n",
        "\n",
        "    if pil_image is None:\n",
        "        return None # Should have been caught by returns above, but as a safeguard\n",
        "\n",
        "    # 3. Using the actual_image_processor (e.g., Gemma3ImageProcessor's image_processor component)\n",
        "    try:\n",
        "        inputs = actual_image_processor(images=pil_image, return_tensors=\"pt\")\n",
        "\n",
        "        if inputs is None or 'pixel_values' not in inputs or inputs['pixel_values'] is None:\n",
        "            # print(f\"actual_image_processor returned None or no pixel_values for path {path}.\") # Optional\n",
        "            return None\n",
        "\n",
        "        processed_tensor = inputs['pixel_values']\n",
        "        # The processor might return a batched tensor [1, C, H, W] or unbatched [C, H, W]\n",
        "        # Squeeze if a batch dimension of 1 was added.\n",
        "        if len(processed_tensor.shape) == 4 and processed_tensor.shape[0] == 1:\n",
        "            processed_tensor = processed_tensor.squeeze(0)\n",
        "\n",
        "        # Final check for expected 3 dimensions [C,H,W]\n",
        "        if len(processed_tensor.shape) != 3:\n",
        "            # print(f\"Processed tensor has unexpected shape {processed_tensor.shape} for path {path}.\") # Optional\n",
        "            return None\n",
        "\n",
        "        return processed_tensor\n",
        "    except Exception: # as e_proc:\n",
        "        # print(f\"Error during actual_image_processor call for {path}: {e_proc}\") # Optional\n",
        "        return None\n",
        "\n",
        "# --- Custom PyTorch Dataset ---\n",
        "class RetinalLdlDatasetPyTorch(Dataset):\n",
        "    def __init__(self, df_input, processor_ref, scaled_ldl_col_name='LDL_scaled'):\n",
        "        self.df = df_input.reset_index(drop=True)\n",
        "        self.processor = processor_ref # This is the main medgemma_processor (Gemma3Processor instance)\n",
        "        self.scaled_ldl_col = scaled_ldl_col_name\n",
        "\n",
        "        if self.processor is None:\n",
        "            raise ValueError(\"MedGemma processor (processor_ref) has not been loaded or passed correctly. Check Cell 5.\")\n",
        "        if self.scaled_ldl_col not in self.df.columns:\n",
        "            raise ValueError(f\"Scaled LDL column '{self.scaled_ldl_col}' not found in DataFrame. Check Cell 6.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        row = self.df.iloc[idx]\n",
        "        image_path = row['image_path']\n",
        "\n",
        "        # Call the corrected image loading function\n",
        "        image_tensor = load_dicom_image_medgemma(image_path, self.processor)\n",
        "\n",
        "        if image_tensor is None:\n",
        "            # Fallback: return a placeholder (zeros)\n",
        "            # Use TARGET_SIZE_MEDGEMMA which should be set in Cell 5\n",
        "            num_channels = 3 # Assume 3 for RGB\n",
        "            if hasattr(self.processor, 'image_processor') and hasattr(self.processor.image_processor, 'num_channels'):\n",
        "                 num_channels = self.processor.image_processor.num_channels\n",
        "\n",
        "            height, width = TARGET_SIZE_MEDGEMMA # This variable is from Cell 5\n",
        "            # print(f\"Warning: Failed to load image {image_path} for index {idx}. Returning zeros of shape ({num_channels}, {height}, {width}).\") # Optional\n",
        "            image_tensor = torch.zeros((num_channels, height, width), dtype=torch.float32)\n",
        "            ldl_value_scaled = torch.tensor(0.0, dtype=torch.float32) # Neutral placeholder for label\n",
        "        else:\n",
        "            ldl_value_scaled = torch.tensor(row[self.scaled_ldl_col], dtype=torch.float32)\n",
        "\n",
        "        return {\"pixel_values\": image_tensor, \"labels\": ldl_value_scaled}\n",
        "\n",
        "# --- Create Dataset and DataLoader instances ---\n",
        "# These will be re-initialized here using the final load_dicom_image_medgemma\n",
        "train_dataset_pytorch, val_dataset_pytorch, test_dataset_pytorch = None, None, None\n",
        "train_dataloader, val_dataloader, test_dataloader = None, None, None\n",
        "\n",
        "# Ensure processor is loaded (from Cell 5) and DataFrames are ready (from Cell 6)\n",
        "if 'medgemma_processor' in locals() and medgemma_processor is not None:\n",
        "    MEDGEMMA_BATCH_SIZE = 4 # You can adjust this\n",
        "    print(f\"\\nRe-creating Datasets and DataLoaders with final image loading logic. Batch size: {MEDGEMMA_BATCH_SIZE}\")\n",
        "\n",
        "    if 'train_df' in locals() and not train_df.empty and 'LDL_scaled' in train_df.columns:\n",
        "        try:\n",
        "            train_dataset_pytorch = RetinalLdlDatasetPyTorch(\n",
        "                df_input=train_df,\n",
        "                processor_ref=medgemma_processor,\n",
        "                scaled_ldl_col_name='LDL_scaled'\n",
        "            )\n",
        "            # Set num_workers=0 if you encounter issues with multiprocessing on Colab, especially on CPU runtime\n",
        "            # For GPU, num_workers=2 is usually fine.\n",
        "            num_dataloader_workers = 2 if torch.cuda.is_available() else 0\n",
        "            train_dataloader = DataLoader(train_dataset_pytorch, batch_size=MEDGEMMA_BATCH_SIZE, shuffle=True, num_workers=num_dataloader_workers, pin_memory=torch.cuda.is_available(), drop_last=True)\n",
        "            print(f\"Train PyTorch Dataset created with {len(train_dataset_pytorch)} samples.\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Error creating train_dataset_pytorch: {e}\")\n",
        "    else:\n",
        "        print(\"Train DataFrame not ready or 'LDL_scaled' missing. Cannot create train_dataset_pytorch.\")\n",
        "\n",
        "    if 'val_df' in locals() and not val_df.empty and 'LDL_scaled' in val_df.columns:\n",
        "        try:\n",
        "            val_dataset_pytorch = RetinalLdlDatasetPyTorch(\n",
        "                df_input=val_df,\n",
        "                processor_ref=medgemma_processor,\n",
        "                scaled_ldl_col_name='LDL_scaled'\n",
        "            )\n",
        "            val_dataloader = DataLoader(val_dataset_pytorch, batch_size=MEDGEMMA_BATCH_SIZE, shuffle=False, num_workers=num_dataloader_workers, pin_memory=torch.cuda.is_available())\n",
        "            print(f\"Validation PyTorch Dataset created with {len(val_dataset_pytorch)} samples.\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Error creating val_dataset_pytorch: {e}\")\n",
        "    else:\n",
        "        print(\"Validation DataFrame not ready or 'LDL_scaled' missing. Cannot create val_dataset_pytorch.\")\n",
        "\n",
        "    # Test DataLoader is optional here but good for completeness\n",
        "    if 'test_df' in locals() and not test_df.empty and 'LDL_scaled' in test_df.columns:\n",
        "        try:\n",
        "            test_dataset_pytorch = RetinalLdlDatasetPyTorch(\n",
        "                df_input=test_df,\n",
        "                processor_ref=medgemma_processor,\n",
        "                scaled_ldl_col_name='LDL_scaled'\n",
        "            )\n",
        "            test_dataloader = DataLoader(test_dataset_pytorch, batch_size=MEDGEMMA_BATCH_SIZE, shuffle=False, num_workers=num_dataloader_workers, pin_memory=torch.cuda.is_available())\n",
        "            print(f\"Test PyTorch Dataset created with {len(test_dataset_pytorch)} samples.\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Error creating test_dataset_pytorch: {e}\")\n",
        "    else:\n",
        "        print(\"Test DataFrame not ready or 'LDL_scaled' missing. Cannot create test_dataset_pytorch.\")\n",
        "else:\n",
        "    print(\"MedGemma processor not loaded (Cell 5 likely failed). Cannot create PyTorch Datasets/DataLoaders.\")\n",
        "\n",
        "\n",
        "# --- Optional: Test one batch from DataLoader ---\n",
        "if train_dataloader is not None and len(train_dataloader) > 0:\n",
        "    print(\"\\nAttempting to get one batch from train_dataloader (with final logic)...\")\n",
        "    try:\n",
        "        sample_batch = next(iter(train_dataloader))\n",
        "        images = sample_batch['pixel_values']\n",
        "        labels = sample_batch['labels']\n",
        "        print(\"Sample batch loaded successfully.\")\n",
        "        print(f\"  Images shape: {images.shape}\")\n",
        "        print(f\"  Images dtype: {images.dtype}\")\n",
        "        print(f\"  Labels shape: {labels.shape}\")\n",
        "        print(f\"  Labels dtype: {labels.dtype}\")\n",
        "        if images.numel() > 0 : print(f\"  First image min/max/mean: {images[0].min().item():.2f} / {images[0].max().item():.2f} / {images[0].mean().item():.2f}\")\n",
        "        if labels.numel() > 0 : print(f\"  First label (scaled): {labels[0].item():.2f}\")\n",
        "\n",
        "        # Count how many images in the batch are all zeros (placeholders)\n",
        "        zero_images_in_batch = 0\n",
        "        for i in range(images.shape[0]):\n",
        "            if torch.all(images[i] == 0):\n",
        "                zero_images_in_batch += 1\n",
        "        if zero_images_in_batch > 0:\n",
        "            print(f\"  WARNING: {zero_images_in_batch}/{images.shape[0]} images in this batch are placeholders (all zeros).\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error while testing train_dataloader: {e}\")\n",
        "else:\n",
        "    print(\"\\nTrain DataLoader not created or is empty, cannot test a batch.\")\n",
        "\n",
        "print(\"\\nCell 7: Final PyTorch Dataset and DataLoader implementation complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sagg4NTCxoj1",
        "outputId": "56358891-6492-42ec-e1e8-e4bcc7fb0800"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Re-creating Datasets and DataLoaders with final image loading logic. Batch size: 4\n",
            "Train PyTorch Dataset created with 681 samples.\n",
            "Validation PyTorch Dataset created with 145 samples.\n",
            "Test PyTorch Dataset created with 147 samples.\n",
            "\n",
            "Attempting to get one batch from train_dataloader (with final logic)...\n",
            "Sample batch loaded successfully.\n",
            "  Images shape: torch.Size([4, 3, 896, 896])\n",
            "  Images dtype: torch.float32\n",
            "  Labels shape: torch.Size([4])\n",
            "  Labels dtype: torch.float32\n",
            "  First image min/max/mean: -1.00 / 1.00 / -0.54\n",
            "  First label (scaled): -0.13\n",
            "\n",
            "Cell 7: Final PyTorch Dataset and DataLoader implementation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Congratulations! You now have a fully functional, end-to-end PyTorch data pipeline that:\n",
        "Correctly loads your DICOM images.\n",
        "Handles the YBR_FULL_422 photometric interpretation using dcm.convert_pixel_data().\n",
        "Converts them to PIL images.\n",
        "Uses the specific image_processor component of the medgemma_processor (which is a Gemma3ImageProcessor configured for MedGemma's vision needs) to preprocess the images into the correct format, size, and normalization range for MedGemma.\n",
        "Normalizes your LDL target values.\n",
        "Batches the data efficiently using DataLoader.\n",
        "This is a major milestone. The \"data\" part, which is often the trickiest, is now solid.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "BwYi3pGMyJYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# -----------------------------------------------------------------------------\n",
        "# Cell 8 (REVISED ATTEMPT 2): Load Pre-trained MedGemma Model and Prepare Vision Tower for PEFT\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"--- Cell 8 (REVISED ATTEMPT 2): Loading MedGemma Model & Preparing Vision Tower ---\")\n",
        "\n",
        "import torch # Ensure torch is imported for nn.Module check\n",
        "import torch.nn as nn # For isinstance check\n",
        "\n",
        "# Ensure previous necessary variables are available\n",
        "if 'MEDGEMMA_PT_MODEL_ID' not in locals():\n",
        "    print(\"ERROR: MEDGEMMA_PT_MODEL_ID not defined. Please re-run Cell 4.\")\n",
        "    MEDGEMMA_PT_MODEL_ID = \"google/medgemma-4b-pt\" # Fallback\n",
        "\n",
        "if 'torch' not in locals() or not torch.cuda.is_available():\n",
        "    print(\"ERROR: PyTorch or CUDA not available. Ensure Cell 1 ran correctly and a GPU runtime is selected.\")\n",
        "    device = torch.device(\"cpu\")\n",
        "else:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"Using device: {device} ({torch.cuda.get_device_name(0)})\")\n",
        "\n",
        "from transformers import AutoModel, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "print(f\"Quantization config: {quantization_config}\")\n",
        "\n",
        "medgemma_base_model = None\n",
        "medgemma_peft_vision_model = None\n",
        "actual_vision_encoder = None # Define here for clarity\n",
        "\n",
        "try:\n",
        "    print(f\"\\nLoading MedGemma model: {MEDGEMMA_PT_MODEL_ID} with 4-bit quantization using AutoModel...\")\n",
        "    medgemma_base_model = AutoModel.from_pretrained(\n",
        "        MEDGEMMA_PT_MODEL_ID,\n",
        "        quantization_config=quantization_config,\n",
        "        trust_remote_code=True,\n",
        "    )\n",
        "    print(f\"MedGemma model loaded successfully with AutoModel. Type: {type(medgemma_base_model)}\")\n",
        "\n",
        "    # --- Directly access the vision_tower component ---\n",
        "    if hasattr(medgemma_base_model, 'vision_tower'):\n",
        "        actual_vision_encoder = medgemma_base_model.vision_tower\n",
        "        print(f\"Successfully accessed vision component: medgemma_base_model.vision_tower\")\n",
        "        print(f\"Type of actual_vision_encoder: {type(actual_vision_encoder)}\")\n",
        "    else:\n",
        "        print(\"ERROR: The loaded medgemma_base_model does not have a 'vision_tower' attribute as expected from previous inspection.\")\n",
        "        # Print structure again if it fails, in case something changed or my interpretation was off\n",
        "        print(medgemma_base_model)\n",
        "        raise AttributeError(\"Could not find 'vision_tower' in medgemma_base_model.\")\n",
        "\n",
        "    # The actual_vision_encoder is SiglipVisionModel. We want to apply LoRA to its internal\n",
        "    # SiglipVisionTransformer, or more specifically, layers within it.\n",
        "    # Let's print the structure of actual_vision_encoder to confirm target modules\n",
        "    print(\"\\nStructure of actual_vision_encoder (medgemma_base_model.vision_tower):\")\n",
        "    print(actual_vision_encoder)\n",
        "\n",
        "    # --- Prepare Model for k-bit Training ---\n",
        "    # It's generally safer to prepare the component that will have PEFT adapters applied.\n",
        "    print(\"\\nPreparing actual_vision_encoder for k-bit training (PEFT)...\")\n",
        "    actual_vision_encoder_prepared = prepare_model_for_kbit_training(actual_vision_encoder)\n",
        "    # Note: prepare_model_for_kbit_training often returns the same model modified in-place,\n",
        "    # but assigning it back is safer.\n",
        "    print(\"Vision encoder prepared for k-bit training.\")\n",
        "\n",
        "\n",
        "    # --- LoRA Configuration ---\n",
        "    # Based on inspection: \"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\" in SiglipAttention\n",
        "    # We can also target \"fc1\", \"fc2\" in SiglipMLP if desired for more trainable params,\n",
        "    # but let's start with attention layers.\n",
        "    LORA_TARGET_MODULES_VISION = [\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\"]\n",
        "    print(f\"\\nLoRA target modules for vision encoder: {LORA_TARGET_MODULES_VISION}\")\n",
        "\n",
        "    # Verify target modules exist (optional but good for sanity check)\n",
        "    found_target_modules = False\n",
        "    for name, module in actual_vision_encoder_prepared.named_modules():\n",
        "        if isinstance(module, nn.Linear) or \"Linear4bit\" in str(type(module)): # Check for Linear or Linear4bit\n",
        "            if any(target_substring == name.split('.')[-1] for target_substring in LORA_TARGET_MODULES_VISION): # Check last part of name\n",
        "                print(f\"  Confirmed LoRA target: {name} of type {type(module)}\")\n",
        "                found_target_modules = True\n",
        "    if not found_target_modules:\n",
        "         print(f\"WARNING: Could not confirm all LoRA target modules {LORA_TARGET_MODULES_VISION} within the vision encoder. LoRA might not be applied effectively. Please double-check names from the printed structure.\")\n",
        "\n",
        "\n",
        "    lora_config = LoraConfig(\n",
        "        r=16,\n",
        "        lora_alpha=32,\n",
        "        target_modules=LORA_TARGET_MODULES_VISION,\n",
        "        lora_dropout=0.05,\n",
        "        bias=\"none\",\n",
        "        task_type=\"FEATURE_EXTRACTION\", # SiglipVisionModel is for feature extraction\n",
        "                                       # If this gives issues, can try omitting task_type.\n",
        "    )\n",
        "    print(f\"\\nLoRA config: {lora_config}\")\n",
        "\n",
        "    print(\"Applying LoRA to the actual_vision_encoder_prepared component...\")\n",
        "    # We apply PEFT to the actual_vision_encoder_prepared (which is medgemma_base_model.vision_tower)\n",
        "    medgemma_peft_vision_model = get_peft_model(actual_vision_encoder_prepared, lora_config)\n",
        "    print(\"LoRA applied successfully to the vision_model component.\")\n",
        "    medgemma_peft_vision_model.print_trainable_parameters()\n",
        "\n",
        "    # For Cell 9, we will use 'medgemma_peft_vision_model' as the vision encoder.\n",
        "    # The base model 'medgemma_base_model' now contains the PEFT-adapted vision_tower.\n",
        "    # So, medgemma_base_model.vision_tower IS medgemma_peft_vision_model.\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during MedGemma model loading or PEFT setup: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    medgemma_base_model = None\n",
        "    medgemma_peft_vision_model = None\n",
        "    actual_vision_encoder = None # Clear on error\n",
        "\n",
        "print(\"\\n--- Cell 8 (REVISED ATTEMPT 2): MedGemma Model loading and PEFT preparation attempt complete. ---\")\n",
        "\"\"\"\n",
        "# -----------------------------------------------------------------------------\n",
        "# Cell 8 (REVISED ATTEMPT 2 - DEBUG): Load Pre-trained MedGemma Model and Prepare Vision Tower for PEFT\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"--- Cell 8 (REVISED ATTEMPT 2 - DEBUG): Loading MedGemma Model & Preparing Vision Tower ---\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "if 'MEDGEMMA_PT_MODEL_ID' not in locals():\n",
        "    print(\"ERROR: MEDGEMMA_PT_MODEL_ID not defined. Please re-run Cell 4.\")\n",
        "    MEDGEMMA_PT_MODEL_ID = \"google/medgemma-4b-pt\"\n",
        "\n",
        "if 'torch' not in locals() or not torch.cuda.is_available():\n",
        "    print(\"ERROR: PyTorch or CUDA not available. Ensure Cell 1 ran correctly and a GPU runtime is selected.\")\n",
        "    device = torch.device(\"cpu\")\n",
        "else:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"Using device: {device} ({torch.cuda.get_device_name(0)})\")\n",
        "\n",
        "from transformers import AutoModel, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "print(f\"Quantization config: {quantization_config}\")\n",
        "\n",
        "medgemma_base_model = None\n",
        "medgemma_peft_vision_model = None\n",
        "actual_vision_encoder = None\n",
        "\n",
        "try:\n",
        "    print(f\"\\nLoading MedGemma model: {MEDGEMMA_PT_MODEL_ID} with 4-bit quantization using AutoModel...\")\n",
        "    medgemma_base_model = AutoModel.from_pretrained(\n",
        "        MEDGEMMA_PT_MODEL_ID,\n",
        "        quantization_config=quantization_config,\n",
        "        trust_remote_code=True,\n",
        "    )\n",
        "    print(f\"MedGemma model loaded successfully with AutoModel. Type: {type(medgemma_base_model)}\")\n",
        "\n",
        "    if hasattr(medgemma_base_model, 'vision_tower'):\n",
        "        actual_vision_encoder = medgemma_base_model.vision_tower\n",
        "        print(f\"Successfully accessed vision component: medgemma_base_model.vision_tower\")\n",
        "        print(f\"Type of actual_vision_encoder: {type(actual_vision_encoder)}\")\n",
        "    else:\n",
        "        print(\"ERROR: The loaded medgemma_base_model does not have a 'vision_tower' attribute.\")\n",
        "        print(medgemma_base_model)\n",
        "        raise AttributeError(\"Could not find 'vision_tower' in medgemma_base_model.\")\n",
        "\n",
        "    # print(\"\\nStructure of actual_vision_encoder (medgemma_base_model.vision_tower):\") # Already seen this\n",
        "    # print(actual_vision_encoder)\n",
        "\n",
        "    print(\"\\nPreparing actual_vision_encoder for k-bit training (PEFT)...\")\n",
        "    actual_vision_encoder_prepared = prepare_model_for_kbit_training(actual_vision_encoder)\n",
        "    print(\"Vision encoder prepared for k-bit training.\")\n",
        "\n",
        "    LORA_TARGET_MODULES_VISION = [\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\"]\n",
        "    # print(f\"\\nLoRA target modules for vision encoder: {LORA_TARGET_MODULES_VISION}\") # Already seen\n",
        "\n",
        "    # ... (LoRA target module verification can be commented out for brevity now) ...\n",
        "\n",
        "    lora_config = LoraConfig(\n",
        "        r=16,\n",
        "        lora_alpha=32,\n",
        "        target_modules=LORA_TARGET_MODULES_VISION,\n",
        "        lora_dropout=0.05,\n",
        "        bias=\"none\",\n",
        "        task_type=\"FEATURE_EXTRACTION\",\n",
        "    )\n",
        "    # print(f\"\\nLoRA config: {lora_config}\") # Already seen\n",
        "\n",
        "    print(\"Applying LoRA to the actual_vision_encoder_prepared component...\")\n",
        "    medgemma_peft_vision_model = get_peft_model(actual_vision_encoder_prepared, lora_config)\n",
        "    print(\"LoRA applied successfully to the vision_model component.\")\n",
        "\n",
        "    print(\"\\nIMMEDIATE CHECK of medgemma_peft_vision_model in Cell 8:\")\n",
        "    medgemma_peft_vision_model.print_trainable_parameters() # <<<< FIRST CHECKPOINT\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during MedGemma model loading or PEFT setup: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    medgemma_base_model = None\n",
        "    medgemma_peft_vision_model = None\n",
        "    actual_vision_encoder = None\n",
        "\n",
        "print(\"\\n--- Cell 8 (REVISED ATTEMPT 2 - DEBUG): MedGemma Model loading and PEFT preparation attempt complete. ---\")\n",
        "# Add a final check at the very end of Cell 8's logical execution path\n",
        "if medgemma_peft_vision_model is not None:\n",
        "    print(\"\\nFINAL CHECK of medgemma_peft_vision_model AT THE END OF CELL 8:\")\n",
        "    medgemma_peft_vision_model.print_trainable_parameters() # <<<< SECOND CHECKPOINT\n",
        "else:\n",
        "    print(\"\\nmedgemma_peft_vision_model is None at the end of Cell 8.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862,
          "referenced_widgets": [
            "9230675becd849a7a3c8a9758ccf032f",
            "580d6463c46d43b28bb3ddb57481560c",
            "bf2f0fd2042047bbb43d8d71443ba1fa",
            "abce52bb4d2f4c46b7b63885323c886b",
            "bec639c4cad4454eb2a027c378c484c2",
            "2b6597bef083451dad2f954a4beed374",
            "909833f1ab1c48dd8c7c7b069d4fd658",
            "dbf0b595802844df8b524ad7740dc50c",
            "525313f2fcb6449f86f479802e40bd14",
            "229f9c564a024614a4bde172e8373067",
            "bf38b761d93241829fe19e11e6aa551d",
            "01c127cb5d3543be9c8bdd904dcfb1d1",
            "fcb8ed40ea3a4deab12893c61d119312",
            "24a07f5df9d24e019c991426b76be043",
            "430bcbc07cba4a26b38785364b5108cf",
            "e3ac7db3168c4e02a120e38545bdbe67",
            "d91db277a7a14a0fb1e2f178de38a037",
            "a992fda352a247af9d7409b93cd48604",
            "0f6464ff66614f1abb97767855c42549",
            "192e97777bdb471e85049402f31086a6",
            "2bcf8cb86a9b4f26aaa9818d1c80eb63",
            "b39daede10fc496ba1e9109fd5ed2c45",
            "bffddc07cf6c4dd8aeda0ff1c1ec0de5",
            "739fdf2b8899413cb151c69d4801bf26",
            "b517fa09542c49c1b439b42489ef3a10",
            "b15a7de0b94e43daa640a998d52ecccf",
            "8e04553311aa480bad044dac09132ff7",
            "faa8bd8c245246f6a20b00cfc329cb18",
            "67f3d6ebde9d4a94ad0557a8d74d8317",
            "b442dac410a447339422d30ab75b7f70",
            "474cee0f30a045ecae8afae87f4a6537",
            "7d2ea870326d4204ac4468b19345a72a",
            "2eee7282d43f40ce9ffa50f3e895c7d7",
            "cfdac6bf5c914f6aa59e597af877c766",
            "42243a1e717d474085b7b087bd2d5b19",
            "79802bf064224fcf998e6c4c99d8d508",
            "1bece0e4021e48b7b58bb06c3a3384a6",
            "d7a963a1f3834a16bdafe4c3f755c79f",
            "4577572db2d243d495c490475d45a7ea",
            "f746a6fcd8024bc4bea2e6537daf1033",
            "d7f45040acbb4b37a2b6746cea26fab2",
            "71fd71ea294c4cd2937a149199a6a0f5",
            "d35a93974c2449e2bed6216f2243dca1",
            "d4c3b51cc30442449d11277e7275dcc4",
            "01e979a43d064c739df7437e1f9631cc",
            "a3d5df125c9b479cb27f40a4a7300cab",
            "ad7d079a0a814bdbb90c05a21fa71f07",
            "1082eb1ae7014a4db44a6ea8c62f9e55",
            "d85a346872d04d0e8c00c4fd5146cfcf",
            "88bde2460bdb4e029b021b428ff3c622",
            "8f6b68b32ef042c1b65b52a7091a29be",
            "79ca206b7c0e409e8263052fa2f9b562",
            "ec800003203b46fea9e3d5554d612852",
            "9109025efaae4f67928817709090b468",
            "53fb12150c924daa844f0428a19c5d6c",
            "c545e6ddae9b4a22ae13c21183949dd2",
            "1a4abb04c76542b984916d011bcfab1c",
            "090107fab9294d52bec4addc205ffec9",
            "e3778a6158a24dc5bb356e1f190155bf",
            "81c5f92ff085498eafdfbc2542c3c4d1",
            "c0a23245d5214ad1bf51e839182beb78",
            "a551185a81314219b6e028ed10a592eb",
            "19012601584941fd9b2d9ce9c1d82133",
            "11277fc7bd8f4a91987bc3200fe9a535",
            "abc9c93bd8bc4af7a4e1d14887fee390",
            "0d22d17f7d8c43b8b422de4fbb3185fd"
          ]
        },
        "id": "FPELkcW0ZQRQ",
        "outputId": "1a6a7c69-4bcb-4f3e-ebc3-57d40c42ae84"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Cell 8 (REVISED ATTEMPT 2 - DEBUG): Loading MedGemma Model & Preparing Vision Tower ---\n",
            "Using device: cuda (Tesla T4)\n",
            "Quantization config: BitsAndBytesConfig {\n",
            "  \"_load_in_4bit\": true,\n",
            "  \"_load_in_8bit\": false,\n",
            "  \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
            "  \"bnb_4bit_quant_storage\": \"uint8\",\n",
            "  \"bnb_4bit_quant_type\": \"nf4\",\n",
            "  \"bnb_4bit_use_double_quant\": true,\n",
            "  \"llm_int8_enable_fp32_cpu_offload\": false,\n",
            "  \"llm_int8_has_fp16_weight\": false,\n",
            "  \"llm_int8_skip_modules\": null,\n",
            "  \"llm_int8_threshold\": 6.0,\n",
            "  \"load_in_4bit\": true,\n",
            "  \"load_in_8bit\": false,\n",
            "  \"quant_method\": \"bitsandbytes\"\n",
            "}\n",
            "\n",
            "\n",
            "Loading MedGemma model: google/medgemma-4b-pt with 4-bit quantization using AutoModel...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.57k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9230675becd849a7a3c8a9758ccf032f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/90.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01c127cb5d3543be9c8bdd904dcfb1d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bffddc07cf6c4dd8aeda0ff1c1ec0de5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfdac6bf5c914f6aa59e597af877c766"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.64G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01e979a43d064c739df7437e1f9631cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c545e6ddae9b4a22ae13c21183949dd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MedGemma model loaded successfully with AutoModel. Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Model'>\n",
            "Successfully accessed vision component: medgemma_base_model.vision_tower\n",
            "Type of actual_vision_encoder: <class 'transformers.models.siglip.modeling_siglip.SiglipVisionModel'>\n",
            "\n",
            "Preparing actual_vision_encoder for k-bit training (PEFT)...\n",
            "Vision encoder prepared for k-bit training.\n",
            "Applying LoRA to the actual_vision_encoder_prepared component...\n",
            "LoRA applied successfully to the vision_model component.\n",
            "\n",
            "IMMEDIATE CHECK of medgemma_peft_vision_model in Cell 8:\n",
            "trainable params: 3,981,312 || all params: 420,847,344 || trainable%: 0.9460\n",
            "\n",
            "--- Cell 8 (REVISED ATTEMPT 2 - DEBUG): MedGemma Model loading and PEFT preparation attempt complete. ---\n",
            "\n",
            "FINAL CHECK of medgemma_peft_vision_model AT THE END OF CELL 8:\n",
            "trainable params: 3,981,312 || all params: 420,847,344 || trainable%: 0.9460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\"\n",
        "\n",
        "# # -----------------------------------------------------------------------------\n",
        "# # Cell 9: Define Custom Regression Head and Combined Model\n",
        "# # -----------------------------------------------------------------------------\n",
        "# print(\"\\n--- Cell 9: Defining Custom Regression Head and Combined Model ---\")\n",
        "\n",
        "# import torch.nn as nn\n",
        "\n",
        "# # --- Define the Custom Regression Head ---\n",
        "# class RegressionHead(nn.Module):\n",
        "#     \"\"\"\n",
        "#     #A simple regression head to predict a single continuous value (e.g., scaled LDL)\n",
        "#     #from image embeddings.\n",
        "#     \"\"\"\n",
        "#     def __init__(self, embedding_dim, hidden_dim=512, dropout_rate=0.1):\n",
        "#         \"\"\"\n",
        "#         #Args:\n",
        "#         #    embedding_dim (int): Dimensionality of the input image embeddings.\n",
        "#         #    hidden_dim (int): Size of the hidden layer.\n",
        "#         #    dropout_rate (float): Dropout rate for regularization.\n",
        "#         \"\"\"\n",
        "#         super().__init__()\n",
        "#         self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.dropout = nn.Dropout(dropout_rate)\n",
        "#         self.fc2 = nn.Linear(hidden_dim, 1) # Output a single value\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.fc1(x)\n",
        "#         x = self.relu(x)\n",
        "#         x = self.dropout(x)\n",
        "#         x = self.fc2(x)\n",
        "#         return x\n",
        "\n",
        "# # --- Define the Combined Model (MedGemma Vision Encoder + Regression Head) ---\n",
        "# class MedGemmaForLDLRegression(nn.Module):\n",
        "#     \"\"\"\n",
        "#     #Combines the PEFT-adapted MedGemma vision encoder with a custom regression head.\n",
        "#     \"\"\"\n",
        "#     def __init__(self, medgemma_peft_vision_encoder, regression_head_instance):\n",
        "\n",
        "#      #   Args:\n",
        "#       #      medgemma_peft_vision_encoder: The PEFT-adapted vision model component\n",
        "#        #                                  (e.g., medgemma_vision_model.vision_model after get_peft_model).\n",
        "#         #    regression_head_instance: An instance of the RegressionHead.\n",
        "\n",
        "#         #super().__init__()\n",
        "#         self.vision_encoder = medgemma_peft_vision_encoder\n",
        "#         self.regression_head = regression_head_instance\n",
        "\n",
        "#         # Freeze the entire vision encoder except for the LoRA parameters (and any other modules\n",
        "#         # explicitly made trainable by PEFT, like layernorms if prepare_model_for_kbit_training did that).\n",
        "#         # The get_peft_model function already handles freezing most weights and making\n",
        "#         # only LoRA adapters trainable. So, explicit freezing here might be redundant\n",
        "#         # if PEFT is correctly applied, but it's a good sanity check.\n",
        "#         for param in self.vision_encoder.parameters():\n",
        "#             if not getattr(param, 'is_lora_param', False): # Check if it's a LoRA parameter\n",
        "#                  param.requires_grad = False\n",
        "\n",
        "#         # Ensure the regression head parameters are trainable\n",
        "#         for param in self.regression_head.parameters():\n",
        "#             param.requires_grad = True\n",
        "\n",
        "#     def forward(self, pixel_values):\n",
        "#         \"\"\"\n",
        "#        # Args:\n",
        "#         #    pixel_values (torch.Tensor): Batch of preprocessed images,\n",
        "#          #                                shape (batch_size, channels, height, width).\n",
        "#        # Returns:\n",
        "#         #    torch.Tensor: Predicted (scaled) LDL values, shape (batch_size, 1).\n",
        "#         \"\"\"\n",
        "#         # Get image embeddings from the MedGemma vision encoder.\n",
        "#         # The exact way to get image embeddings can vary.\n",
        "#         # For Vision2Seq models, it's often model.vision_model(...) or model.encode_image(...)\n",
        "#         # Since self.vision_encoder is medgemma_vision_model.vision_model (PEFT adapted),\n",
        "#         # we call it directly.\n",
        "#         # The output is typically a BaseModelOutputWithPooling or similar,\n",
        "#         # from which we need to extract the pooled output or last hidden state.\n",
        "\n",
        "#         # Option 1: Using .last_hidden_state and taking the [CLS] token embedding (if applicable)\n",
        "#         # vision_outputs = self.vision_encoder(pixel_values=pixel_values)\n",
        "#         # image_embeds = vision_outputs.last_hidden_state[:, 0, :] # Assuming [CLS] token at pos 0\n",
        "\n",
        "#         # Option 2: Using .pooler_output (if the model has a pooling layer)\n",
        "#         # vision_outputs = self.vision_encoder(pixel_values=pixel_values)\n",
        "#         # image_embeds = vision_outputs.pooler_output\n",
        "\n",
        "#         # Let's try to determine the most common way for SigLIP-based encoders within Vision2Seq\n",
        "#         # Typically, vision_model(pixel_values).last_hidden_state gives sequence of patch embeddings.\n",
        "#         # We might need to average them or use the [CLS] token's embedding if one exists.\n",
        "#         # Or, some models provide a specific 'image_features' output.\n",
        "\n",
        "#         # For many Hugging Face vision models, the vision_model part returns outputs\n",
        "#         # where last_hidden_state contains patch embeddings.\n",
        "#         # We often take the embedding of the special [CLS] token (if used, usually at index 0)\n",
        "#         # or average all patch embeddings.\n",
        "#         # Let's assume for now the vision encoder output's last_hidden_state can be pooled.\n",
        "#         # A common approach for SigLIP is to use the [CLS] token embedding.\n",
        "#         # The output of `medgemma_vision_model.vision_model(pixel_values)` should be an object\n",
        "#         # that has a `last_hidden_state` attribute (B, SequenceLength, EmbeddingDim)\n",
        "#         # and often a `pooler_output` (B, EmbeddingDim) which is usually the [CLS] token embedding passed through a Linear layer and Tanh.\n",
        "\n",
        "#         vision_outputs = self.vision_encoder(pixel_values=pixel_values, return_dict=True)\n",
        "\n",
        "#         # Attempt to get pooled_output, common in SigLipVisionModel\n",
        "#         if hasattr(vision_outputs, 'image_embeds') and vision_outputs.image_embeds is not None:\n",
        "#             # This is ideal if MedGemma's vision_model's forward pass directly gives 'image_embeds'\n",
        "#             # which is common for contrastive pre-training like SigLIP.\n",
        "#             image_embeds = vision_outputs.image_embeds # Expected shape: (batch_size, embedding_dim)\n",
        "#         elif hasattr(vision_outputs, 'pooler_output') and vision_outputs.pooler_output is not None:\n",
        "#             image_embeds = vision_outputs.pooler_output # Expected shape: (batch_size, embedding_dim)\n",
        "#         elif hasattr(vision_outputs, 'last_hidden_state'):\n",
        "#             # If no direct pooler_output or image_embeds, use the [CLS] token from last_hidden_state\n",
        "#             # This assumes the first token is the [CLS] token, common in ViT architectures.\n",
        "#             image_embeds = vision_outputs.last_hidden_state[:, 0, :] # (batch_size, embedding_dim)\n",
        "#             print(\"Warning: Using last_hidden_state[:, 0, :] as image embedding. Verify this is appropriate for MedGemma's vision encoder.\")\n",
        "#         else:\n",
        "#             raise AttributeError(\"Could not extract image embeddings. Vision encoder output does not have 'image_embeds', 'pooler_output', or 'last_hidden_state'.\")\n",
        "\n",
        "#         # Pass embeddings through the regression head\n",
        "#         predictions = self.regression_head(image_embeds)\n",
        "#         return predictions\n",
        "\n",
        "# # --- Instantiate the Combined Model (after Cell 8 has run) ---\n",
        "# # We need the embedding dimension from the MedGemma vision model.\n",
        "# # This is typically model.config.hidden_size for LLMs or model.config.vision_config.hidden_size for vision parts.\n",
        "# ldl_prediction_model = None\n",
        "\n",
        "# if 'medgemma_peft_vision_model' in locals() and medgemma_peft_vision_model is not None:\n",
        "#     try:\n",
        "#         # Get embedding dimension from the config of the vision_model component\n",
        "#         # The PEFT model wraps the original model, so config should still be accessible.\n",
        "#         # The original model before PEFT was medgemma_vision_model.vision_model\n",
        "#         # The PEFT model is medgemma_peft_vision_model\n",
        "#         if hasattr(medgemma_peft_vision_model, 'config') and hasattr(medgemma_peft_vision_model.config, 'hidden_size'):\n",
        "#              # This assumes the PEFT model directly has the config, or we access the original underlying model's config\n",
        "#             vision_embedding_dim = medgemma_peft_vision_model.config.hidden_size\n",
        "#         else:\n",
        "#             # Fallback: try to get it from the main medgemma_vision_model's vision_config\n",
        "#             # This path might be more reliable if medgemma_peft_vision_model is just the nn.Module part.\n",
        "#             # medgemma_vision_model is the full AutoModelForVision2Seq\n",
        "#             original_vision_model_config = medgemma_vision_model.vision_model.config\n",
        "#             vision_embedding_dim = original_vision_model_config.hidden_size\n",
        "\n",
        "#         print(f\"Determined Vision Embedding Dimension: {vision_embedding_dim}\")\n",
        "\n",
        "#         # Instantiate the regression head\n",
        "#         custom_head = RegressionHead(embedding_dim=vision_embedding_dim)\n",
        "#         print(f\"Custom regression head instantiated: {custom_head}\")\n",
        "\n",
        "#         # Instantiate the combined LDL prediction model\n",
        "#         ldl_prediction_model = MedGemmaForLDLRegression(\n",
        "#             medgemma_peft_vision_encoder=medgemma_peft_vision_model, # This is the PEFT-adapted vision_model\n",
        "#             regression_head_instance=custom_head\n",
        "#         )\n",
        "#         ldl_prediction_model.to(device) # Move the entire model to the GPU\n",
        "#         print(f\"Combined LDL prediction model instantiated and moved to {device}.\")\n",
        "\n",
        "#         # Verify trainable parameters in the combined model\n",
        "#         # Only LoRA adapters in vision_encoder and all params in regression_head should be trainable.\n",
        "#         total_params = 0\n",
        "#         trainable_params = 0\n",
        "#         print(\"\\nTrainable parameters in ldl_prediction_model:\")\n",
        "#         for name, param in ldl_prediction_model.named_parameters():\n",
        "#             total_params += param.numel()\n",
        "#             if param.requires_grad:\n",
        "#                 trainable_params += param.numel()\n",
        "#                 # print(f\"  Trainable: {name}, Size: {param.size()}, Numel: {param.numel()}\")\n",
        "\n",
        "#         print(f\"Total parameters in ldl_prediction_model: {total_params:,}\")\n",
        "#         print(f\"Trainable parameters in ldl_prediction_model: {trainable_params:,} ({100 * trainable_params / total_params:.4f}%)\")\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error during combined model instantiation: {e}\")\n",
        "#         import traceback\n",
        "#         traceback.print_exc()\n",
        "#         ldl_prediction_model = None\n",
        "# else:\n",
        "#     print(\"MedGemma PEFT vision model (medgemma_peft_vision_model) not available from Cell 8. Cannot instantiate combined model.\")\n",
        "\n",
        "\n",
        "# print(\"\\n--- Cell 9: Custom Regression Head and Combined Model definition complete. ---\")\n",
        "\n",
        "# \"\"\""
      ],
      "metadata": {
        "id": "K4ELGXPhYvvH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# -----------------------------------------------------------------------------\n",
        "# Cell 9 (REVISED ATTEMPT 3): Define Custom Regression Head and Combined Model\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n--- Cell 9 (REVISED ATTEMPT 3): Defining Custom Regression Head and Combined Model ---\")\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "# --- Define the Custom Regression Head ---\n",
        "class RegressionHead(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim=512, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# --- Define the Combined Model (MedGemma Vision Encoder + Regression Head) ---\n",
        "class MedGemmaForLDLRegression(nn.Module):\n",
        "    def __init__(self, peft_vision_encoder_model, regression_head_instance): # Renamed arg for clarity\n",
        "        super().__init__()\n",
        "        # peft_vision_encoder_model IS the PeftModel instance from Cell 8\n",
        "        self.vision_encoder = peft_vision_encoder_model\n",
        "        self.regression_head = regression_head_instance\n",
        "\n",
        "        # regression_head_instance parameters are trainable by default.\n",
        "        # The peft_vision_encoder_model (PeftModel) should have its LoRA params trainable.\n",
        "\n",
        "    def forward(self, pixel_values):\n",
        "        # Call the vision_encoder (which is the PeftModel)\n",
        "        # The PeftModel's forward will internally call the base model's forward (SiglipVisionModel)\n",
        "        vision_outputs = self.vision_encoder(pixel_values=pixel_values, return_dict=True)\n",
        "\n",
        "        image_embeds = None\n",
        "        # Extract embeddings (same logic as before)\n",
        "        if hasattr(vision_outputs, 'image_embeds') and vision_outputs.image_embeds is not None:\n",
        "            image_embeds = vision_outputs.image_embeds\n",
        "        elif hasattr(vision_outputs, 'pooler_output') and vision_outputs.pooler_output is not None:\n",
        "            image_embeds = vision_outputs.pooler_output\n",
        "        elif hasattr(vision_outputs, 'last_hidden_state'):\n",
        "            image_embeds = vision_outputs.last_hidden_state[:, 0, :]\n",
        "        else:\n",
        "            if hasattr(vision_outputs, 'keys'): print(f\"DEBUG: vision_outputs keys: {vision_outputs.keys()}\")\n",
        "            raise AttributeError(\"Could not extract image embeddings from vision_encoder output.\")\n",
        "\n",
        "        predictions = self.regression_head(image_embeds)\n",
        "        return predictions\n",
        "\n",
        "# --- Instantiate the Combined Model (after Cell 8 has run) ---\n",
        "ldl_prediction_model = None\n",
        "\n",
        "if 'medgemma_peft_vision_model' in locals() and medgemma_peft_vision_model is not None and \\\n",
        "   'device' in locals():\n",
        "    try:\n",
        "        print(\"Status of 'medgemma_peft_vision_model' (from Cell 8) BEFORE passing to MedGemmaForLDLRegression:\")\n",
        "        medgemma_peft_vision_model.print_trainable_parameters() # Should show ~3.98M trainable\n",
        "\n",
        "        vision_embedding_dim = medgemma_peft_vision_model.config.hidden_size # Assumes PeftModel exposes base config\n",
        "        print(f\"Determined Vision Embedding Dimension: {vision_embedding_dim}\")\n",
        "\n",
        "        custom_head = RegressionHead(embedding_dim=vision_embedding_dim)\n",
        "        print(f\"Custom regression head instantiated: {custom_head}\")\n",
        "\n",
        "        # Instantiate the combined model\n",
        "        ldl_prediction_model = MedGemmaForLDLRegression(\n",
        "            peft_vision_encoder_model=medgemma_peft_vision_model, # Pass the PeftModel directly\n",
        "            regression_head_instance=custom_head\n",
        "        )\n",
        "\n",
        "        print(\"\\nStatus of 'vision_encoder' attribute INSIDE ldl_prediction_model IMMEDIATELY AFTER INSTANTIATION:\")\n",
        "        if hasattr(ldl_prediction_model, 'vision_encoder'):\n",
        "            ldl_prediction_model.vision_encoder.print_trainable_parameters() # Check if it changed\n",
        "        else:\n",
        "            print(\"'vision_encoder' attribute not found in ldl_prediction_model!\")\n",
        "\n",
        "        ldl_prediction_model.to(device)\n",
        "        print(f\"\\nCombined LDL prediction model instantiated and moved to {device}.\")\n",
        "\n",
        "        # Put model in training mode - this is important for layers like Dropout, BatchNorm,\n",
        "        # and potentially for how PEFT models behave or report.\n",
        "        ldl_prediction_model.train()\n",
        "        print(\"Called ldl_prediction_model.train()\")\n",
        "\n",
        "        print(\"\\nStatus of 'vision_encoder' attribute AFTER ldl_prediction_model.train():\")\n",
        "        if hasattr(ldl_prediction_model, 'vision_encoder'):\n",
        "            ldl_prediction_model.vision_encoder.print_trainable_parameters()\n",
        "        else:\n",
        "            print(\"'vision_encoder' attribute not found!\")\n",
        "\n",
        "\n",
        "        # Verify trainable parameters in the ENTIRE combined model using a manual loop\n",
        "        total_params_combined = 0\n",
        "        trainable_params_combined = 0\n",
        "        print(\"\\nTrainable parameters in ldl_prediction_model (manual loop):\")\n",
        "        for name, param in ldl_prediction_model.named_parameters():\n",
        "            total_params_combined += param.numel()\n",
        "            if param.requires_grad:\n",
        "                trainable_params_combined += param.numel()\n",
        "                # print(f\"  Trainable: {name}\") # Can be verbose\n",
        "\n",
        "        print(f\"Total parameters in ldl_prediction_model (manual count): {total_params_combined:,}\")\n",
        "        print(f\"Trainable parameters in ldl_prediction_model (manual count): {trainable_params_combined:,} ({100 * trainable_params_combined / total_params_combined if total_params_combined > 0 else 0:.4f}%)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during combined model instantiation: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        ldl_prediction_model = None\n",
        "else:\n",
        "    print(\"One or more required variables (medgemma_peft_vision_model, device) not available. Cannot instantiate combined model.\")\n",
        "\n",
        "print(\"\\n--- Cell 9 (REVISED ATTEMPT 3): Custom Regression Head and Combined Model definition complete. ---\")\n",
        "\"\"\"\n",
        "# -----------------------------------------------------------------------------\n",
        "# Cell 9 (REVISED ATTEMPT 3 - DEBUG): Define Custom Regression Head and Combined Model\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n--- Cell 9 (REVISED ATTEMPT 3 - DEBUG): Defining Custom Regression Head and Combined Model ---\")\n",
        "\n",
        "import torch.nn as nn # Ensure nn is imported\n",
        "\n",
        "# VERY FIRST THING IN CELL 9 after imports/prints: Check the object from Cell 8\n",
        "if 'medgemma_peft_vision_model' in locals() and medgemma_peft_vision_model is not None:\n",
        "    print(\"\\nIMMEDIATE CHECK of medgemma_peft_vision_model AT THE START OF CELL 9:\")\n",
        "    medgemma_peft_vision_model.print_trainable_parameters() # <<<< THIRD CHECKPOINT\n",
        "    # Also, let's check its training mode\n",
        "    if hasattr(medgemma_peft_vision_model, 'training'):\n",
        "        print(f\"  medgemma_peft_vision_model.training mode: {medgemma_peft_vision_model.training}\")\n",
        "    else:\n",
        "        print(\"  medgemma_peft_vision_model has no 'training' attribute.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nmedgemma_peft_vision_model not available or is None at the start of Cell 9.\")\n",
        "\n",
        "\n",
        "# --- Define the Custom Regression Head ---\n",
        "# ... (RegressionHead class remains the same) ...\n",
        "class RegressionHead(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim=512, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "# --- Define the Combined Model (MedGemma Vision Encoder + Regression Head) ---\n",
        "# ... (MedGemmaForLDLRegression class remains the same as in Attempt 3) ...\n",
        "class MedGemmaForLDLRegression(nn.Module):\n",
        "    def __init__(self, peft_vision_encoder_model, regression_head_instance): # Renamed arg for clarity\n",
        "        super().__init__()\n",
        "        self.vision_encoder = peft_vision_encoder_model\n",
        "        self.regression_head = regression_head_instance\n",
        "\n",
        "    def forward(self, pixel_values):\n",
        "        vision_outputs = self.vision_encoder(pixel_values=pixel_values, return_dict=True)\n",
        "        image_embeds = None\n",
        "        if hasattr(vision_outputs, 'image_embeds') and vision_outputs.image_embeds is not None:\n",
        "            image_embeds = vision_outputs.image_embeds\n",
        "        elif hasattr(vision_outputs, 'pooler_output') and vision_outputs.pooler_output is not None:\n",
        "            image_embeds = vision_outputs.pooler_output\n",
        "        elif hasattr(vision_outputs, 'last_hidden_state'):\n",
        "            image_embeds = vision_outputs.last_hidden_state[:, 0, :]\n",
        "        else:\n",
        "            if hasattr(vision_outputs, 'keys'): print(f\"DEBUG: vision_outputs keys: {vision_outputs.keys()}\")\n",
        "            raise AttributeError(\"Could not extract image embeddings from vision_encoder output.\")\n",
        "        predictions = self.regression_head(image_embeds)\n",
        "        return predictions\n",
        "# --- Instantiate the Combined Model (after Cell 8 has run) ---\n",
        "ldl_prediction_model = None\n",
        "\n",
        "# We only proceed if medgemma_peft_vision_model is confirmed to be good at the start of this cell.\n",
        "if 'medgemma_peft_vision_model' in locals() and medgemma_peft_vision_model is not None and \\\n",
        "   'device' in locals():\n",
        "\n",
        "    # Re-check here, just before using it in the constructor\n",
        "    print(\"\\nRe-checking 'medgemma_peft_vision_model' BEFORE passing to MedGemmaForLDLRegression constructor:\")\n",
        "    medgemma_peft_vision_model.print_trainable_parameters() # <<<< FOURTH CHECKPOINT\n",
        "\n",
        "    try:\n",
        "        vision_embedding_dim = medgemma_peft_vision_model.config.hidden_size\n",
        "        print(f\"Determined Vision Embedding Dimension: {vision_embedding_dim}\")\n",
        "\n",
        "        custom_head = RegressionHead(embedding_dim=vision_embedding_dim)\n",
        "        print(f\"Custom regression head instantiated: {custom_head}\")\n",
        "\n",
        "        ldl_prediction_model = MedGemmaForLDLRegression(\n",
        "            peft_vision_encoder_model=medgemma_peft_vision_model,\n",
        "            regression_head_instance=custom_head\n",
        "        )\n",
        "\n",
        "        print(\"\\nStatus of 'vision_encoder' attribute INSIDE ldl_prediction_model IMMEDIATELY AFTER INSTANTIATION:\")\n",
        "        if hasattr(ldl_prediction_model, 'vision_encoder'):\n",
        "            ldl_prediction_model.vision_encoder.print_trainable_parameters() # <<<< FIFTH CHECKPOINT\n",
        "        else:\n",
        "            print(\"'vision_encoder' attribute not found in ldl_prediction_model!\")\n",
        "\n",
        "        ldl_prediction_model.to(device)\n",
        "        print(f\"\\nCombined LDL prediction model instantiated and moved to {device}.\")\n",
        "\n",
        "        ldl_prediction_model.train() # Set to train mode\n",
        "        print(\"Called ldl_prediction_model.train()\")\n",
        "\n",
        "        print(\"\\nStatus of 'vision_encoder' attribute AFTER ldl_prediction_model.train():\")\n",
        "        if hasattr(ldl_prediction_model, 'vision_encoder'):\n",
        "            ldl_prediction_model.vision_encoder.print_trainable_parameters() # <<<< SIXTH CHECKPOINT\n",
        "        else:\n",
        "            print(\"'vision_encoder' attribute not found!\")\n",
        "\n",
        "        total_params_combined = 0\n",
        "        trainable_params_combined = 0\n",
        "        print(\"\\nTrainable parameters in ldl_prediction_model (manual loop):\")\n",
        "        for name, param in ldl_prediction_model.named_parameters():\n",
        "            total_params_combined += param.numel()\n",
        "            if param.requires_grad:\n",
        "                trainable_params_combined += param.numel()\n",
        "\n",
        "        print(f\"Total parameters in ldl_prediction_model (manual count): {total_params_combined:,}\")\n",
        "        print(f\"Trainable parameters in ldl_prediction_model (manual count): {trainable_params_combined:,} ({100 * trainable_params_combined / total_params_combined if total_params_combined > 0 else 0:.4f}%)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during combined model instantiation: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        ldl_prediction_model = None\n",
        "else:\n",
        "    print(\"One or more required variables (medgemma_peft_vision_model, device) not available or medgemma_peft_vision_model had 0 trainable params at start of cell. Cannot instantiate combined model.\")\n",
        "\n",
        "print(\"\\n--- Cell 9 (REVISED ATTEMPT 3 - DEBUG): Custom Regression Head and Combined Model definition complete. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LJBGKt6aOHv",
        "outputId": "8a3c3260-1448-41aa-8f95-a8c64b9ec3ad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Cell 9 (REVISED ATTEMPT 3 - DEBUG): Defining Custom Regression Head and Combined Model ---\n",
            "\n",
            "IMMEDIATE CHECK of medgemma_peft_vision_model AT THE START OF CELL 9:\n",
            "trainable params: 3,981,312 || all params: 420,847,344 || trainable%: 0.9460\n",
            "  medgemma_peft_vision_model.training mode: True\n",
            "\n",
            "Re-checking 'medgemma_peft_vision_model' BEFORE passing to MedGemmaForLDLRegression constructor:\n",
            "trainable params: 3,981,312 || all params: 420,847,344 || trainable%: 0.9460\n",
            "Determined Vision Embedding Dimension: 1152\n",
            "Custom regression head instantiated: RegressionHead(\n",
            "  (fc1): Linear(in_features=1152, out_features=512, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "Status of 'vision_encoder' attribute INSIDE ldl_prediction_model IMMEDIATELY AFTER INSTANTIATION:\n",
            "trainable params: 3,981,312 || all params: 420,847,344 || trainable%: 0.9460\n",
            "\n",
            "Combined LDL prediction model instantiated and moved to cuda.\n",
            "Called ldl_prediction_model.train()\n",
            "\n",
            "Status of 'vision_encoder' attribute AFTER ldl_prediction_model.train():\n",
            "trainable params: 3,981,312 || all params: 420,847,344 || trainable%: 0.9460\n",
            "\n",
            "Trainable parameters in ldl_prediction_model (manual loop):\n",
            "Total parameters in ldl_prediction_model (manual count): 215,902,961\n",
            "Trainable parameters in ldl_prediction_model (manual count): 4,572,161 (2.1177%)\n",
            "\n",
            "--- Cell 9 (REVISED ATTEMPT 3 - DEBUG): Custom Regression Head and Combined Model definition complete. ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 10: Define Loss Function, Optimizer, and Learning Rate Scheduler\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n--- Cell 10: Defining Loss Function, Optimizer, and Learning Rate Scheduler ---\")\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from transformers import get_linear_schedule_with_warmup # For the LR scheduler\n",
        "\n",
        "# Ensure ldl_prediction_model and train_dataloader are available from previous cells\n",
        "if 'ldl_prediction_model' not in locals() or ldl_prediction_model is None:\n",
        "    print(\"ERROR: ldl_prediction_model not found or is None. Please ensure Cell 9 ran successfully.\")\n",
        "    # To prevent NameError if this cell is run standalone without Cell 9\n",
        "    # This is a placeholder; in a real run, Cell 9 must succeed.\n",
        "    class PlaceholderModel(nn.Module):\n",
        "        def __init__(self): super().__init__(); self.dummy = nn.Linear(1,1)\n",
        "        def parameters(self): return self.dummy.parameters()\n",
        "    ldl_prediction_model = PlaceholderModel()\n",
        "    # This will likely cause issues later if Cell 9 didn't run, but avoids immediate crash.\n",
        "\n",
        "if 'train_dataloader' not in locals() or train_dataloader is None:\n",
        "    print(\"ERROR: train_dataloader not found or is None. Please ensure Cell 7 ran successfully.\")\n",
        "    # Placeholder to prevent crash, assuming a small dummy dataloader for calculation\n",
        "    class DummyDL: __len__ = lambda self: 10\n",
        "    train_dataloader = DummyDL()\n",
        "\n",
        "\n",
        "# --- 1. Loss Function ---\n",
        "# For regression, Mean Squared Error is appropriate.\n",
        "loss_function = nn.MSELoss()\n",
        "print(f\"Loss function: {loss_function}\")\n",
        "\n",
        "# --- 2. Optimizer ---\n",
        "LEARNING_RATE = 1e-4\n",
        "# AdamW is generally recommended for Transformer-based models and PEFT.\n",
        "# It will only update parameters for which requires_grad is True.\n",
        "optimizer = optim.AdamW(ldl_prediction_model.parameters(), lr=LEARNING_RATE)\n",
        "print(f\"Optimizer: AdamW with learning rate {LEARNING_RATE}\")\n",
        "\n",
        "# --- 3. Learning Rate Scheduler (Linear with Warmup) ---\n",
        "NUM_EPOCHS = 3\n",
        "if train_dataloader is not None and hasattr(train_dataloader, '__len__') and len(train_dataloader) > 0 :\n",
        "    # Calculate total training steps\n",
        "    total_training_steps = len(train_dataloader) * NUM_EPOCHS\n",
        "\n",
        "    # Calculate warmup steps (e.g., 5-10% of total training steps)\n",
        "    # Let's use 6% as an example, or a fixed small number if total steps is very low\n",
        "    num_warmup_steps = int(0.06 * total_training_steps) if total_training_steps > 50 else max(1, int(0.1 * total_training_steps))\n",
        "\n",
        "    print(f\"Number of training epochs: {NUM_EPOCHS}\")\n",
        "    print(f\"Number of batches per epoch (train_dataloader size): {len(train_dataloader)}\")\n",
        "    print(f\"Total training steps: {total_training_steps}\")\n",
        "    print(f\"Number of warmup steps: {num_warmup_steps}\")\n",
        "\n",
        "    # Create the scheduler\n",
        "    lr_scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=num_warmup_steps,\n",
        "        num_training_steps=total_training_steps\n",
        "    )\n",
        "    print(f\"Learning rate scheduler: Linear schedule with {num_warmup_steps} warmup steps.\")\n",
        "else:\n",
        "    print(\"WARNING: train_dataloader not available or empty. Cannot calculate total training steps for LR scheduler.\")\n",
        "    print(\"LR scheduler will not be created. Training will proceed with a fixed learning rate if optimizer is defined.\")\n",
        "    lr_scheduler = None # No scheduler if dataloader info is missing\n",
        "\n",
        "\n",
        "print(\"\\n--- Cell 10: Training components defined. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFTfTaUVs45S",
        "outputId": "8974dfac-0c2c-4fa0-c61a-b11bc8e6c997"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Cell 10: Defining Loss Function, Optimizer, and Learning Rate Scheduler ---\n",
            "Loss function: MSELoss()\n",
            "Optimizer: AdamW with learning rate 0.0001\n",
            "Number of training epochs: 3\n",
            "Number of batches per epoch (train_dataloader size): 170\n",
            "Total training steps: 510\n",
            "Number of warmup steps: 30\n",
            "Learning rate scheduler: Linear schedule with 30 warmup steps.\n",
            "\n",
            "--- Cell 10: Training components defined. ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 11: Training and Validation Loop\n",
        "# -----------------------------------------------------------------------------\n",
        "print(\"\\n--- Cell 11: Training and Validation Loop ---\")\n",
        "\n",
        "import time # To measure epoch time\n",
        "from tqdm.notebook import tqdm # For progress bars in notebooks\n",
        "import os # For path creation\n",
        "\n",
        "# Ensure all necessary variables are defined from previous cells\n",
        "# (ldl_prediction_model, loss_function, optimizer, lr_scheduler,\n",
        "#  train_dataloader, val_dataloader, NUM_EPOCHS, device)\n",
        "\n",
        "# Check for required variables to prevent errors if cells are run out of order\n",
        "required_vars_cell11 = [\n",
        "    'ldl_prediction_model', 'loss_function', 'optimizer', 'train_dataloader',\n",
        "    'val_dataloader', 'NUM_EPOCHS', 'device'\n",
        "    # lr_scheduler is optional, code will handle if it's None\n",
        "]\n",
        "for var_name in required_vars_cell11:\n",
        "    if var_name not in locals() or locals()[var_name] is None:\n",
        "        print(f\"ERROR: Variable '{var_name}' is not defined or is None. Please run previous cells.\")\n",
        "        # In a real script, you might raise an error here or exit.\n",
        "        # For this interactive environment, we'll let it proceed but it will likely fail.\n",
        "        # (Adding a simple break for now to stop further execution in this cell if critical var is missing)\n",
        "        if var_name in ['ldl_prediction_model', 'train_dataloader']: # Critical ones\n",
        "            raise NameError(f\"Critical variable {var_name} missing. Cannot proceed with training.\")\n",
        "\n",
        "\n",
        "# --- Model Saving Configuration ---\n",
        "# Define a path to save the best model checkpoint\n",
        "# Using Google Drive is recommended for persistence if Colab session disconnects\n",
        "# Ensure your Drive is mounted.\n",
        "DRIVE_MODEL_SAVE_DIR = \"/content/drive/MyDrive/MedGemma_LDL_Checkpoints\" # Example path\n",
        "if not os.path.exists(DRIVE_MODEL_SAVE_DIR):\n",
        "    try:\n",
        "        os.makedirs(DRIVE_MODEL_SAVE_DIR)\n",
        "        print(f\"Created model save directory: {DRIVE_MODEL_SAVE_DIR}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not create directory {DRIVE_MODEL_SAVE_DIR}. Saving to local Colab runtime: {e}\")\n",
        "        DRIVE_MODEL_SAVE_DIR = \"/content/MedGemma_LDL_Checkpoints\" # Fallback to local\n",
        "        os.makedirs(DRIVE_MODEL_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "BEST_MODEL_PATH = os.path.join(DRIVE_MODEL_SAVE_DIR, \"best_ldl_prediction_model.pth\")\n",
        "print(f\"Best model will be saved to: {BEST_MODEL_PATH}\")\n",
        "\n",
        "\n",
        "# --- Training Loop ---\n",
        "best_val_loss = float('inf') # Initialize with a very high value\n",
        "history = {'train_loss': [], 'val_loss': [], 'lr': []} # To store metrics\n",
        "\n",
        "print(f\"\\nStarting training for {NUM_EPOCHS} epochs...\")\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_start_time = time.time()\n",
        "    print(f\"\\n--- Epoch {epoch+1}/{NUM_EPOCHS} ---\")\n",
        "\n",
        "    # --- Training Phase ---\n",
        "    ldl_prediction_model.train() # Set model to training mode\n",
        "    running_train_loss = 0.0\n",
        "    train_progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1} [Train]\", unit=\"batch\")\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_progress_bar):\n",
        "        pixel_values = batch['pixel_values'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad() # Zero gradients\n",
        "\n",
        "        # Forward pass\n",
        "        predictions = ldl_prediction_model(pixel_values)\n",
        "\n",
        "        # Calculate loss\n",
        "        # Ensure predictions and labels have compatible shapes for MSELoss\n",
        "        # If predictions is [batch_size, 1] and labels is [batch_size], squeeze predictions.\n",
        "        loss = loss_function(predictions.squeeze(-1), labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Scheduler step (if scheduler exists)\n",
        "        if lr_scheduler is not None:\n",
        "            lr_scheduler.step()\n",
        "            history['lr'].append(lr_scheduler.get_last_lr()[0]) # Log learning rate\n",
        "        elif batch_idx == 0 : # Log initial LR once if no scheduler\n",
        "             history['lr'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "\n",
        "        running_train_loss += loss.item()\n",
        "        train_progress_bar.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    avg_train_loss = running_train_loss / len(train_dataloader)\n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "    print(f\"Epoch {epoch+1} [Train] Avg. Loss: {avg_train_loss:.4f}, Current LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "\n",
        "    # --- Validation Phase ---\n",
        "    ldl_prediction_model.eval() # Set model to evaluation mode\n",
        "    running_val_loss = 0.0\n",
        "    val_progress_bar = tqdm(val_dataloader, desc=f\"Epoch {epoch+1} [Val]\", unit=\"batch\")\n",
        "\n",
        "    with torch.no_grad(): # Disable gradient calculations for validation\n",
        "        for batch in val_progress_bar:\n",
        "            pixel_values = batch['pixel_values'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            predictions = ldl_prediction_model(pixel_values)\n",
        "            val_loss = loss_function(predictions.squeeze(-1), labels)\n",
        "            running_val_loss += val_loss.item()\n",
        "            val_progress_bar.set_postfix(loss=val_loss.item())\n",
        "\n",
        "    avg_val_loss = running_val_loss / len(val_dataloader)\n",
        "    history['val_loss'].append(avg_val_loss)\n",
        "    print(f\"Epoch {epoch+1} [Val] Avg. Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    epoch_end_time = time.time()\n",
        "    print(f\"Epoch {epoch+1} completed in {epoch_end_time - epoch_start_time:.2f} seconds.\")\n",
        "\n",
        "    # --- Save Best Model ---\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        print(f\"New best validation loss: {best_val_loss:.4f}. Saving model to {BEST_MODEL_PATH}...\")\n",
        "        # For PEFT models, saving the adapters is often preferred.\n",
        "        # model.save_pretrained(\"path\") saves adapters and config for PEFT.\n",
        "        # However, our `ldl_prediction_model` also has a custom regression head.\n",
        "        # A simple way is to save the whole state_dict, but this includes frozen parts.\n",
        "        # A more robust way for PEFT + custom head:\n",
        "        try:\n",
        "            # Save PEFT adapters of the vision_encoder part\n",
        "            peft_vision_save_path = os.path.join(DRIVE_MODEL_SAVE_DIR, \"peft_vision_adapters\")\n",
        "            ldl_prediction_model.vision_encoder.save_pretrained(peft_vision_save_path)\n",
        "\n",
        "            # Save the regression head's state_dict\n",
        "            regression_head_save_path = os.path.join(DRIVE_MODEL_SAVE_DIR, \"regression_head.pth\")\n",
        "            torch.save(ldl_prediction_model.regression_head.state_dict(), regression_head_save_path)\n",
        "\n",
        "            print(f\"PEFT vision adapters saved to: {peft_vision_save_path}\")\n",
        "            print(f\"Regression head saved to: {regression_head_save_path}\")\n",
        "            # Store path info for easy loading later\n",
        "            with open(os.path.join(DRIVE_MODEL_SAVE_DIR, \"best_model_config.txt\"), \"w\") as f:\n",
        "                f.write(f\"epoch: {epoch+1}\\n\")\n",
        "                f.write(f\"best_val_loss: {best_val_loss}\\n\")\n",
        "                f.write(f\"peft_vision_adapters_path: {peft_vision_save_path}\\n\")\n",
        "                f.write(f\"regression_head_path: {regression_head_save_path}\\n\")\n",
        "\n",
        "        except Exception as e_save:\n",
        "            print(f\"Error saving PEFT adapters and regression head separately: {e_save}\")\n",
        "            print(\"Attempting to save full model state_dict as fallback...\")\n",
        "            try:\n",
        "                 torch.save(ldl_prediction_model.state_dict(), BEST_MODEL_PATH)\n",
        "                 print(f\"Full model state_dict saved to {BEST_MODEL_PATH} (fallback).\")\n",
        "            except Exception as e_save_full:\n",
        "                print(f\"Error saving full model state_dict: {e_save_full}\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Training complete ---\")\n",
        "print(f\"Best validation loss achieved: {best_val_loss:.4f}\")\n",
        "\n",
        "# --- Optionally, load the best model weights back if needed for immediate further use ---\n",
        "# This part would require logic to load PEFT adapters and regression head separately.\n",
        "# For now, we assume the model in memory is the one from the last epoch.\n",
        "# If you want to ensure it's the *best* one:\n",
        "# 1. Re-instantiate ldl_prediction_model from scratch (Cells 8 & 9 essentially)\n",
        "# 2. Load peft adapters: PeftModel.from_pretrained(model.vision_encoder, peft_vision_save_path)\n",
        "# 3. Load regression head: model.regression_head.load_state_dict(torch.load(regression_head_save_path))\n",
        "# This is more involved, so we'll defer this specific reloading unless necessary right now.\n",
        "\n",
        "# --- Plot training history (optional) ---\n",
        "if len(history['train_loss']) > 0 and len(history['val_loss']) > 0:\n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(history['train_loss'], label='Train Loss')\n",
        "        plt.plot(history['val_loss'], label='Validation Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        if len(history['lr']) > 0 :\n",
        "            plt.subplot(1, 2, 2)\n",
        "            # Plot LR against steps. If only one LR per epoch was logged, plot against epochs.\n",
        "            # For per-step LR logging with scheduler:\n",
        "            if len(history['lr']) > NUM_EPOCHS: # Likely per-step\n",
        "                 plt.plot(history['lr'], label='Learning Rate')\n",
        "                 plt.xlabel('Training Step')\n",
        "            else: # Likely per-epoch (or only initial)\n",
        "                 plt.plot(range(1, len(history['lr'])+1), history['lr'], label='Learning Rate', marker='o')\n",
        "                 plt.xlabel('Epoch (or initial log point)')\n",
        "\n",
        "            plt.ylabel('Learning Rate')\n",
        "            plt.title('Learning Rate Schedule')\n",
        "            plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    except ImportError:\n",
        "        print(\"Matplotlib not available. Skipping history plot.\")\n",
        "    except Exception as e_plot:\n",
        "        print(f\"Error plotting history: {e_plot}\")\n",
        "\n",
        "print(\"\\n--- Cell 11: Training and Validation Loop execution complete. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547,
          "referenced_widgets": [
            "4df6fe7f177c4375ac65f6695661a1a0",
            "02c68d1fc2ba46849142a56840ff06bf",
            "cfd5ef5c399a4375a349dc5f7cf2de31",
            "b1ab5823e404491292019a862d9bb942",
            "676bd0d04db74f558210f515aba3244b",
            "2fe46117c7474bcab1caee7d0996c912",
            "5254a53525bf4eb8aee65949400b04fc",
            "da2d93bd67244bbe83ad838bc79f6a73",
            "600cfcd9dc3544d189da15039f9fb200",
            "28d3067ebcc54b6f893f9d63eb3f6011",
            "6247d8faae7743bea8fac00425835f4c"
          ]
        },
        "id": "U9k9L022twGg",
        "outputId": "53768df9-d99e-4a54-86bb-81ee63479609"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Cell 11: Training and Validation Loop ---\n",
            "Created model save directory: /content/drive/MyDrive/MedGemma_LDL_Checkpoints\n",
            "Best model will be saved to: /content/drive/MyDrive/MedGemma_LDL_Checkpoints/best_ldl_prediction_model.pth\n",
            "\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "--- Epoch 1/3 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1 [Train]:   0%|          | 0/170 [00:00<?, ?batch/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4df6fe7f177c4375ac65f6695661a1a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "SiglipVisionModel.forward() got an unexpected keyword argument 'input_ids'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-34fc6e8697d4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mldl_prediction_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ca9865ad0798>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pixel_values)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mvision_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0mimage_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvision_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'image_embeds'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvision_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   2757\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2758\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2759\u001b[0;31m                 return self.base_model(\n\u001b[0m\u001b[1;32m   2760\u001b[0m                     \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2761\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_injection_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: SiglipVisionModel.forward() got an unexpected keyword argument 'input_ids'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add this temporarily after Cell 7 to inspect\n",
        "if train_dataset_pytorch:\n",
        "    print(\"\\nInspecting first few samples from train_dataset_pytorch:\")\n",
        "    for i in range(min(5, len(train_dataset_pytorch))):\n",
        "        try:\n",
        "            sample = train_dataset_pytorch[i]\n",
        "            img_tensor = sample['pixel_values']\n",
        "            lbl_tensor = sample['labels']\n",
        "            print(f\"Sample {i}: img_shape={img_tensor.shape}, img_min={img_tensor.min().item():.2f}, img_max={img_tensor.max().item():.2f}, scaled_label={lbl_tensor.item():.2f}\")\n",
        "            if img_tensor.min().item() == 0.0 and img_tensor.max().item() == 0.0 and lbl_tensor.item() == 0.0:\n",
        "                # Try to get the original path to see which image is causing issues\n",
        "                original_row = train_df.iloc[i]\n",
        "                print(f\"  ^-- Might be a placeholder. Original path: {original_row['image_path']}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error inspecting sample {i}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htJSpOeeBSAr",
        "outputId": "5bb56ec9-0fd9-4b0d-d165-8acacc63e17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Inspecting first few samples from train_dataset_pytorch:\n",
            "Sample 0: img_shape=torch.Size([3, 896, 896]), img_min=0.00, img_max=0.00, scaled_label=0.00\n",
            "  ^-- Might be a placeholder. Original path: /content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_l_1.2.826.0.1.3680043.8.641.1.20230809.2436.96446.dcm\n",
            "Sample 1: img_shape=torch.Size([3, 896, 896]), img_min=0.00, img_max=0.00, scaled_label=0.00\n",
            "  ^-- Might be a placeholder. Original path: /content/medgemma_extracted_images/1000/1004/1004_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230809.2448.36605.dcm\n",
            "Sample 2: img_shape=torch.Size([3, 896, 896]), img_min=0.00, img_max=0.00, scaled_label=0.00\n",
            "  ^-- Might be a placeholder. Original path: /content/medgemma_extracted_images/1000/1007/1007_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230824.20355.67485.dcm\n",
            "Sample 3: img_shape=torch.Size([3, 896, 896]), img_min=0.00, img_max=0.00, scaled_label=0.00\n",
            "  ^-- Might be a placeholder. Original path: /content/medgemma_extracted_images/1000/1011/1011_eidon_mosaic_cfp_l_1.2.826.0.1.3680043.8.641.1.20230824.20119.99904.dcm\n",
            "Sample 4: img_shape=torch.Size([3, 896, 896]), img_min=0.00, img_max=0.00, scaled_label=0.00\n",
            "  ^-- Might be a placeholder. Original path: /content/medgemma_extracted_images/1000/1011/1011_eidon_mosaic_cfp_r_1.2.826.0.1.3680043.8.641.1.20230824.20131.92049.dcm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1dphRbGC0BU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(LOCAL_CSV_PATH)\n",
        "#Drop everything column other than person id and LDL\n",
        "\n",
        "print(df.columns[20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIHjiw5VsAS_",
        "outputId": "0ff2729b-f184-4ae0-a04b-ae18dc06889a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDL Cholesterol Calculation (mg/dL)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"LDL Cholesterol Calculation (mg/dL)\"]\n",
        "print(df[\"LDL Cholesterol Calculation (mg/dL)\"].isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUgTulnLsGfI",
        "outputId": "ca0b6150-5d96-4e4b-faf3-46c5aeb05522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = df.dropna(subset=[\"LDL Cholesterol Calculation (mg/dL)\"])\n",
        "print(df_clean.shape)  # Should be 41 rows fewer\n",
        "\n",
        "print(df_clean[\"LDL Cholesterol Calculation (mg/dL)\"].isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdQRqv_VsKj0",
        "outputId": "604ad0ac-9b81-4fe3-8e6b-4f7001bac83d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1026, 111)\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#write code to find number of folders inside /content/extracted_images/1000\n",
        "import os\n",
        "folder_count = len(os.listdir(LOCAL_IMAGES_ROOT))\n",
        "print(f\"Number of folders in {LOCAL_IMAGES_ROOT}: {folder_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ntEBAS_sONb",
        "outputId": "76a0a902-1b8e-4c29-ff50-33241da9c0ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of folders in /content/extracted_images/1000: 541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------\n",
        "# Cell 3: Load and Filter Clinical Data (STEP 1)\n",
        "# --------------------------------------------------\n",
        "\n",
        "if not os.path.exists(clinical_csv_path):\n",
        "    print(f\"FATAL ERROR: Clinical CSV file not found at the expected local path: {clinical_csv_path}\")\n",
        "    # You might need to re-run Cell 2 or check paths\n",
        "else:\n",
        "    df = pd.read_csv(clinical_csv_path)\n",
        "    print(f\"Initial number of rows in clinical data: {len(df)}\")\n",
        "\n",
        "    ldl_column_name = \"LDL Cholesterol Calculation (mg/dL)\" # Make sure this matches your CSV header\n",
        "\n",
        "    # Data Cleaning\n",
        "    if ldl_column_name not in df.columns:\n",
        "        print(f\"ERROR: LDL column '{ldl_column_name}' not found in CSV. Available columns: {df.columns.tolist()}\")\n",
        "    else:\n",
        "        print(f\"Original LDL dtype: {df[ldl_column_name].dtype}\")\n",
        "        df[ldl_column_name] = pd.to_numeric(df[ldl_column_name], errors='coerce')\n",
        "        print(f\"Number of NaNs in '{ldl_column_name}' before explicit drop: {df[ldl_column_name].isnull().sum()}\")\n",
        "        df.dropna(subset=[ldl_column_name], inplace=True)\n",
        "        print(f\"Number of rows after dropping NaNs in '{ldl_column_name}': {len(df)}\")\n",
        "        if df[ldl_column_name].isnull().sum() > 0:\n",
        "            print(f\"WARNING: NaNs still present in '{ldl_column_name}' after dropna.\")\n",
        "        else:\n",
        "            print(f\"Successfully removed/handled NaNs from '{ldl_column_name}'.\")\n",
        "\n",
        "        # Ensure person_id is string for matching with folder names\n",
        "        if 'person_id' not in df.columns:\n",
        "            print(f\"ERROR: 'person_id' column not found in CSV. Available columns: {df.columns.tolist()}\")\n",
        "        else:\n",
        "            df['person_id'] = df['person_id'].astype(str)\n",
        "            ldl_lookup = df.set_index('person_id')[ldl_column_name].to_dict()\n",
        "\n",
        "            # Filter valid person_ids based on available image folders\n",
        "            if not os.path.exists(images_root_path) or not os.path.isdir(images_root_path):\n",
        "                print(f\"FATAL ERROR: Images root path '{images_root_path}' does not exist or is not a directory.\")\n",
        "            else:\n",
        "                available_folders = set(os.listdir(images_root_path))\n",
        "                print(f\"Found {len(available_folders)} folders in images_root_path: {list(available_folders)[:5]}...\") # Print a few\n",
        "\n",
        "                valid_ids_clinical = set(ldl_lookup.keys())\n",
        "                print(f\"Found {len(valid_ids_clinical)} unique person_ids with LDL data in CSV.\")\n",
        "\n",
        "                valid_ids = sorted(list(valid_ids_clinical & available_folders))\n",
        "                print(f\"Found {len(valid_ids)} common person_ids between CSV and image folders.\")\n",
        "\n",
        "                if not valid_ids:\n",
        "                    print(\"ERROR: No common person_ids found. Check 'person_id' format in CSV and folder names, and paths.\")\n",
        "                else:\n",
        "                    image_records = []\n",
        "                    for idx, person_id in enumerate(valid_ids, 1):\n",
        "                        folder_path = os.path.join(images_root_path, person_id)\n",
        "                        ldl_value = ldl_lookup[person_id]\n",
        "                        if pd.isna(ldl_value): continue # Should be caught already\n",
        "\n",
        "                        if os.path.isdir(folder_path): # Ensure it's a directory\n",
        "                            for filename in os.listdir(folder_path):\n",
        "                                if filename.lower().endswith(\".dcm\"):\n",
        "                                    image_path = os.path.join(folder_path, filename)\n",
        "                                    image_records.append({\n",
        "                                        \"person_id\": person_id,\n",
        "                                        \"image_path\": image_path,\n",
        "                                        \"LDL\": ldl_value\n",
        "                                    })\n",
        "                        if idx % (len(valid_ids)//10 if len(valid_ids) > 10 else 1) == 0 or idx == len(valid_ids): # Progress print\n",
        "                             print(f\"[{idx}/{len(valid_ids)}] Processed patient ID: {person_id}\")\n",
        "\n",
        "\n",
        "                    image_df = pd.DataFrame(image_records)\n",
        "                    print(f\"Total image samples mapped: {len(image_df)}\")\n",
        "                    if not image_df.empty:\n",
        "                        print(f\"Number of NaNs in final image_df['LDL']: {image_df['LDL'].isnull().sum()}\")\n",
        "                        if image_df['LDL'].isnull().sum() > 0:\n",
        "                            image_df.dropna(subset=['LDL'], inplace=True)\n",
        "                            print(f\"Total image samples after final LDL NaN drop: {len(image_df)}\")\n",
        "                        print(\"Sample of image_df:\")\n",
        "                        print(image_df.head())\n",
        "                    else:\n",
        "                        print(\"ERROR: image_df is empty. No DICOM images found or linked.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IobevGdHsQEC",
        "outputId": "1ada9fcd-f23e-46f8-ca74-be8b446c9a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial number of rows in clinical data: 1067\n",
            "Original LDL dtype: float64\n",
            "Number of NaNs in 'LDL Cholesterol Calculation (mg/dL)' before explicit drop: 41\n",
            "Number of rows after dropping NaNs in 'LDL Cholesterol Calculation (mg/dL)': 1026\n",
            "Successfully removed/handled NaNs from 'LDL Cholesterol Calculation (mg/dL)'.\n",
            "Found 541 folders in images_root_path: ['7162', '7398', '1157', '7192', '1072']...\n",
            "Found 1026 unique person_ids with LDL data in CSV.\n",
            "Found 528 common person_ids between CSV and image folders.\n",
            "[52/528] Processed patient ID: 1129\n",
            "[104/528] Processed patient ID: 1222\n",
            "[156/528] Processed patient ID: 1313\n",
            "[208/528] Processed patient ID: 4009\n",
            "[260/528] Processed patient ID: 4180\n",
            "[312/528] Processed patient ID: 4298\n",
            "[364/528] Processed patient ID: 7093\n",
            "[416/528] Processed patient ID: 7185\n",
            "[468/528] Processed patient ID: 7286\n",
            "[520/528] Processed patient ID: 7398\n",
            "[528/528] Processed patient ID: 7409\n",
            "Total image samples mapped: 974\n",
            "Number of NaNs in final image_df['LDL']: 0\n",
            "Sample of image_df:\n",
            "  person_id                                         image_path         LDL\n",
            "0      1002  /content/extracted_images/1000/1002/1002_eidon...  133.485054\n",
            "1      1004  /content/extracted_images/1000/1004/1004_eidon...   59.674544\n",
            "2      1004  /content/extracted_images/1000/1004/1004_eidon...   59.674544\n",
            "3      1005  /content/extracted_images/1000/1005/1005_eidon...   74.956702\n",
            "4      1007  /content/extracted_images/1000/1007/1007_eidon...   92.278412\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_df.info()\n",
        "image_df.head(5)\n",
        "\n",
        "#print(image_df[image_df[\"LDL\"]<=0])\n",
        "\n",
        "#remove the negative ldl row and update the image_df\n",
        "#drop the row\n",
        "#give code\n",
        "\n",
        "image_df = image_df[image_df[\"LDL\"] > 0]\n",
        "print(image_df[image_df[\"LDL\"]<=0])\n",
        "print(image_df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3ugsdLQsXQW",
        "outputId": "0846266b-c40e-41f5-bc1a-679837f679de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 973 entries, 0 to 973\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   person_id   973 non-null    object \n",
            " 1   image_path  973 non-null    object \n",
            " 2   LDL         973 non-null    float64\n",
            "dtypes: float64(1), object(2)\n",
            "memory usage: 30.4+ KB\n",
            "Empty DataFrame\n",
            "Columns: [person_id, image_path, LDL]\n",
            "Index: []\n",
            "Empty DataFrame\n",
            "Columns: [person_id, image_path, LDL]\n",
            "Index: []\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 973 entries, 0 to 973\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   person_id   973 non-null    object \n",
            " 1   image_path  973 non-null    object \n",
            " 2   LDL         973 non-null    float64\n",
            "dtypes: float64(1), object(2)\n",
            "memory usage: 30.4+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zIV-66xzsbJj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}